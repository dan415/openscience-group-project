<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_6tJvbAA">A compression algorithm for the combination of PDF sets</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2015-10-05">5 October 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,51.04,141.30,74.40,8.78"><forename type="first">Stefano</forename><surname>Carrazza</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dipartimento di Fisica</orgName>
								<orgName type="institution" key="instit1">Università di Milano</orgName>
								<orgName type="institution" key="instit2">INFN</orgName>
								<orgName type="institution" key="instit3">Sezione di Milano</orgName>
								<address>
									<addrLine>Via Celoria 16</addrLine>
									<postCode>20133</postCode>
									<settlement>Milan</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,133.93,141.30,62.45,8.78"><forename type="first">José</forename><forename type="middle">I</forename><surname>Latorre</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Departament d&apos;Estructura i Constituents de la Matèria</orgName>
								<orgName type="institution">Universitat de Barcelona</orgName>
								<address>
									<postBox>Diagonal 647</postBox>
									<postCode>08028</postCode>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,205.67,141.30,43.85,8.78"><forename type="first">Juan</forename><surname>Rojo</surname></persName>
							<email>juan.rojo@cern.ch</email>
							<affiliation key="aff2">
								<orgName type="department">Rudolf Peierls Centre for Theoretical Physics</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<addrLine>1 Keble Road</addrLine>
									<postCode>OX1 3NP</postCode>
									<settlement>Oxford</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,264.54,141.30,57.73,8.78"><forename type="first">Graeme</forename><surname>Watt</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Institute for Particle Physics Phenomenology</orgName>
								<orgName type="institution">Durham University</orgName>
								<address>
									<postCode>DH1 3LE</postCode>
									<settlement>Durham</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" xml:id="_WHnBC8Z">A compression algorithm for the combination of PDF sets</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2015-10-05">5 October 2015</date>
						</imprint>
					</monogr>
					<idno type="MD5">0FFBF7749E69FA489B15B89143D616E1</idno>
					<idno type="DOI">10.1140/epjc/s10052-015-3703-3</idno>
					<note type="submission">Received: 13 May 2015 / Accepted: 25 September 2015 /</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-05-07T13:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_wMkSCbx"><p xml:id="_PzvERSa">The current PDF4LHC recommendation to estimate uncertainties due to parton distribution functions (PDFs) in theoretical predictions for LHC processes involves the combination of separate predictions computed using PDF sets from different groups, each of which comprises a relatively large number of either Hessian eigenvectors or Monte Carlo (MC) replicas. While many fixed-order and parton shower programs allow the evaluation of PDF uncertainties for a single PDF set at no additional CPU cost, this feature is not universal, and, moreover, the a posteriori combination of the predictions using at least three different PDF sets is still required. In this work, we present a strategy for the statistical combination of individual PDF sets, based on the MC representation of Hessian sets, followed by a compression algorithm for the reduction of the number of MC replicas. We illustrate our strategy with the combination and compression of the recent NNPDF3.0, CT14 and MMHT14 NNLO PDF sets. The resulting compressed Monte Carlo PDF sets are validated at the level of parton luminosities and LHC inclusive cross sections and differential distributions. We determine that around 100 replicas provide an adequate representation of the probability distribution for the original combined PDF set, suitable for general applications to LHC phenomenology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_X4GVy7J">Contents</head></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="23" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="24" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="25" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="26" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="27" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="28" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="29" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="30" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="31" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="32" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1" xml:id="_RB4GZXg">Introduction</head><p xml:id="_qeMtXKn">Parton distribution functions (PDFs) are an essential ingredient for LHC phenomenology <ref type="bibr" coords="1,435.62,545.35,8.02,8.76" target="#b0">[1]</ref><ref type="bibr" coords="1,443.64,545.35,4.01,8.76" target="#b1">[2]</ref><ref type="bibr" coords="1,443.64,545.35,4.01,8.76" target="#b2">[3]</ref><ref type="bibr" coords="1,443.64,545.35,4.01,8.76" target="#b3">[4]</ref><ref type="bibr" coords="1,443.64,545.35,4.01,8.76" target="#b4">[5]</ref><ref type="bibr" coords="1,443.64,545.35,4.01,8.76" target="#b5">[6]</ref><ref type="bibr" coords="1,447.65,545.35,8.02,8.76">[7]</ref>. They are one of the limiting theory factors for the extraction of Higgs couplings from LHC data <ref type="bibr" coords="1,373.90,570.25,10.58,8.76" target="#b7">[8]</ref>, they reduce the reach of many BSM searches, particularly in the high-mass region <ref type="bibr" coords="1,497.10,582.71,8.29,8.76" target="#b8">[9]</ref><ref type="bibr" coords="1,505.39,582.71,4.15,8.76" target="#b9">[10]</ref><ref type="bibr" coords="1,509.54,582.71,12.44,8.76" target="#b10">[11]</ref>, and they are the dominant source of systematic uncertainty in precision electroweak measurements such as the W mass at the LHC <ref type="bibr" coords="1,354.29,620.07,12.76,8.76" target="#b11">[12]</ref><ref type="bibr" coords="1,367.06,620.07,4.25,8.76" target="#b12">[13]</ref><ref type="bibr" coords="1,371.31,620.07,12.76,8.76" target="#b13">[14]</ref>. A crucial question is therefore how to estimate the total PDF uncertainty that affects the various processes listed above.</p><p xml:id="_RvnMhQ4">While modern PDF sets <ref type="bibr" coords="1,417.81,657.43,13.52,8.76" target="#b14">[15]</ref><ref type="bibr" coords="1,431.32,657.43,4.51,8.76" target="#b15">[16]</ref><ref type="bibr" coords="1,431.32,657.43,4.51,8.76" target="#b16">[17]</ref><ref type="bibr" coords="1,431.32,657.43,4.51,8.76" target="#b17">[18]</ref><ref type="bibr" coords="1,431.32,657.43,4.51,8.76" target="#b18">[19]</ref><ref type="bibr" coords="1,431.32,657.43,4.51,8.76" target="#b19">[20]</ref><ref type="bibr" coords="1,431.32,657.43,4.51,8.76" target="#b20">[21]</ref><ref type="bibr" coords="1,435.83,657.43,13.52,8.76" target="#b21">[22]</ref> provide their own estimates of the associated PDF error, using a single set might not lead to a robust enough estimate of the total uncertainty arising from our imperfect knowledge of the PDFs in LHC computations. For instance, different global PDF sets, based on similar input datasets and theory assumptions, while in reasonable agreement, can still differ for some PDF flavors and (x, Q 2 ) regions by a non-negligible amount <ref type="bibr" coords="2,253.57,84.38,11.86,8.76" target="#b3">[4,</ref><ref type="bibr" coords="2,265.43,84.38,7.91,8.76" target="#b4">5,</ref><ref type="bibr" coords="2,273.34,84.38,11.86,8.76" target="#b22">23]</ref>. These differences are likely to arise from the different fitting methodologies or from sources of theoretical uncertainty that are not yet accounted for, such as missing higher orders or parametric uncertainties. For these reasons, while an improved understanding of the origin of these differences is achieved, from the practical point of view it is necessary to combine different PDF sets to obtain a more reliable estimate of the total PDF uncertainty in LHC applications.</p><p xml:id="_6MdPcnb">That was the motivation underlying the original 2010 recommendation from the PDF4LHC Working Group to compute the total PDF uncertainty in LHC processes <ref type="bibr" coords="2,256.84,221.36,16.15,8.76" target="#b23">[24,</ref><ref type="bibr" coords="2,273.00,221.36,12.12,8.76" target="#b24">25]</ref>. The prescription was to take the envelope and midpoint of the three global sets available at the time (CTEQ6.6 <ref type="bibr" coords="2,270.04,246.27,15.29,8.76" target="#b25">[26]</ref>, MSTW08 <ref type="bibr" coords="2,94.45,258.73,16.59,8.76" target="#b26">[27]</ref> and NNPDF2.0 <ref type="bibr" coords="2,181.23,258.73,14.93,8.76" target="#b27">[28]</ref>), each at their default value of α s (M Z ), and where each set included the combined PDF+α s uncertainty using the corresponding prescription <ref type="bibr" coords="2,70.95,296.08,12.76,8.76" target="#b28">[29]</ref><ref type="bibr" coords="2,83.71,296.08,4.25,8.76" target="#b29">[30]</ref><ref type="bibr" coords="2,87.97,296.08,12.76,8.76" target="#b30">[31]</ref>. This prescription has been updated <ref type="bibr" coords="2,260.38,296.08,16.61,8.76">[32]</ref> to the most recent sets from each group, and currently these are CT14 <ref type="bibr" coords="2,92.51,320.99,15.27,8.76" target="#b21">[22]</ref>, MMHT14 <ref type="bibr" coords="2,159.16,320.99,16.60,8.76" target="#b18">[19]</ref> and NNPDF3.0 <ref type="bibr" coords="2,245.16,320.99,15.29,8.76" target="#b15">[16]</ref>. More recently, PDF4LHC has simplified the prescription for the combination of PDF+α s uncertainties: the current recommendation <ref type="bibr" coords="2,95.41,358.35,16.59,8.76" target="#b31">[33]</ref> is now to take the three global sets at a common value of α s (M Z ) = 0.118, close enough to the most recent PDG average <ref type="bibr" coords="2,137.82,383.26,15.27,8.76" target="#b32">[34]</ref>, and then add in quadrature the additional uncertainty due to α s . This procedure has been shown to be exact within the Gaussian approximation in the case of CT <ref type="bibr" coords="2,101.36,420.62,15.26,8.76" target="#b28">[29]</ref>, and close enough to the exact prescription for practical applications in the cases of MMHT and NNPDF <ref type="bibr" coords="2,86.19,445.52,16.16,8.76" target="#b29">[30,</ref><ref type="bibr" coords="2,102.35,445.52,12.12,8.76" target="#b30">31]</ref>.</p><p xml:id="_UHGwdMD">One criticism that has been raised to this PDF4LHC recommendation is that defining the total PDF uncertainty by the envelope of the predictions from different sets does not have a well-defined statistical interpretation. However, as originally proposed by Forte in <ref type="bibr" coords="2,135.17,507.79,10.58,8.76" target="#b0">[1]</ref>, and developed in some more detail later by Forte and Watt in <ref type="bibr" coords="2,154.98,520.24,12.17,8.76" target="#b1">[2,</ref><ref type="bibr" coords="2,167.15,520.24,12.17,8.76" target="#b33">35,</ref><ref type="bibr" coords="2,179.32,520.24,12.17,8.76" target="#b34">36]</ref>, it is possible to modify the PDF4LHC prescription to give the combination of PDF sets a robust statistical meaning as follows. The first step consists in transforming the Hessian PDF sets into Monte Carlo (MC) PDF sets using the Watt and Thorne method <ref type="bibr" coords="2,247.79,570.06,15.28,8.76" target="#b33">[35]</ref>. Then one can consider that each of the replicas from each set is a different instance of a common probability distribution, thus the combination of the different sets can be achieved by simply adding together their Monte Carlo replicas. Assuming that each PDF set that enters the combination has the same a priori probability, the same number of replicas should be chosen from each set. The predictions from this combined Monte Carlo PDF set, which now clearly have a well-defined statistical meaning, turn out to be in reasonable agreement from those of the original envelope and midpoint method proposed by PDF4LHC. However, the resulting PDF uncer-tainties will generally be slightly smaller, since the envelope method gives more weight to the outliers than the MC combination method.</p><p xml:id="_49GBwcJ">In general, any method for the combination of PDF sets from different groups presents practical difficulties at the implementation level. The first one is purely computational: theoretical predictions have to be computed from all the eigenvectors/replicas of the various PDF sets, which in total require the same calculation to be redone around O (200) times for the PDF4LHC envelope or around O (900) times for the Monte Carlo combination, a very CPU-intensive task. Fortunately, some of the most widely used Monte Carlo event generators, such as MadGraph5_aMC@NLO <ref type="bibr" coords="2,502.19,208.92,17.04,8.76" target="#b35">[37,</ref><ref type="bibr" coords="2,519.23,208.92,12.78,8.76" target="#b36">38]</ref> or POWHEG <ref type="bibr" coords="2,352.98,221.37,15.26,8.76" target="#b37">[39]</ref>, and NNLO codes like FEWZ <ref type="bibr" coords="2,504.05,221.37,15.27,8.76" target="#b38">[40]</ref>, now allow computation of PDF uncertainties at no extra cost. However, this is not the case for all the theory tools used for the LHC experiments, and even when this feature is available, in the case of the envelope method the a posteriori combination of the results obtained with the three sets still needs to be performed, which can be quite cumbersome (as well as error-prone) especially in the case of exclusive calculations that require very large event files.</p><p xml:id="_H4cCv44">The above discussion provides the motivation to develop new strategies for the combination of individual PDF sets, and the subsequent reduction to a small number of eigenvectors or replicas. One possible approach in this direction, the Meta-PDFs method, has been proposed in <ref type="bibr" coords="2,482.12,383.27,15.26,8.76" target="#b39">[41]</ref>. The basic idea is to fit a common meta-parameterization to the PDFs from different groups at some common scale Q 0 , and then use the Monte Carlo combination of the different input sets to define the 68 % confidence-level intervals of these fit parameters. A Meta-PDF set combining MSTW08 <ref type="bibr" coords="2,481.97,445.52,15.28,8.76" target="#b26">[27]</ref>, CT10 <ref type="bibr" coords="2,527.67,445.52,16.60,8.76" target="#b17">[18]</ref> and NNPDF2.3 <ref type="bibr" coords="2,371.79,457.98,16.60,8.76" target="#b40">[42]</ref> at NNLO was produced in <ref type="bibr" coords="2,501.92,457.98,16.59,8.76" target="#b39">[41]</ref> based on N eig = 50 asymmetric eigenvectors. In addition, using the dataset diagonalization method proposed in <ref type="bibr" coords="2,505.14,482.88,15.28,8.76" target="#b41">[43]</ref>, it is possible to further reduce the number of eigenvectors in the Meta-PDF sets for specific physical applications, such as for Higgs production processes.</p><p xml:id="_XAyURsz">The main limitation of the Meta-PDF method is the possible dependence on the choice of input meta-parametrization. Indeed, the statement that the common parameterization that is used to refit all PDF sets is flexible enough depends on which input sets enter in the combination, thus it needs to be checked and adjusted every time the procedure is repeated. In addition, at least for NNPDF, the Meta-PDF parameterization is bound to be insufficient, particularly in extrapolation regions like large-x, which are crucial for New Physics searches.</p><p xml:id="_xEPQSMf">Recently, an alternative Hessian reduction approach, the MC2H method, has been developed <ref type="bibr" coords="2,445.39,669.69,15.27,8.76" target="#b42">[44]</ref>. This method adopts the MC replicas themselves as expansion basis, thus avoiding the need to choose a specific functional form. It uses Singular Value Decomposition methods with Principal Component Analysis to construct a representation of the PDF covariance matrix as a linear combination of MC replicas. The main advantage of the MC2H method is that the construction is exact, meaning that the accuracy of the new Hessian representation is only limited by machine precision. In practice, eigenvectors which carry little information are discarded, but even so with N eig = 100 eigenvectors central values and covariances of the prior combination can be reproduced with O (0.1 %) accuracy or better.</p><p xml:id="_vyMg6b5">However, a central limitation of any Hessian reduction method is the impossibility of reproducing non-Gaussian features present in the input combination. It should be noted that even in the case where all the input sets in the combination are approximately Gaussian, their combination in general will be non-Gaussian. This is particularly relevant in extrapolation regions where PDF uncertainties are large and the underlying probability distributions for the PDFs are far from Gaussian. Failing to reproduce non-Gaussianities implies that the assumption of equal prior likelihood of the individual sets that enter the combination is artificially modified: for instance, if two sets peak at some value and another one at some other value (so we have a double hump structure), a Gaussian reduction effectively will be adding more weight to the second set as compared to the first two. To overcome this limitation is the main motivation for this work, where we propose an alternative reduction strategy based on the compression of the original Monte Carlo combined set into a smaller subset of replicas, which, however, reproduces the main statistical features of the input distribution.</p><p xml:id="_SdT97ed">The starting point of our method is, as in the case of the Meta-PDF and MC2H methods, the Monte Carlo combination of individual PDF sets, and then a compression algorithm follows in order to select a reduced number of replicas while reproducing the basic statistical properties of the original probability distribution, such as means, variances, correlations, and higher moments. This compression is based on the genetic algorithms (GA) exploration of the space of minima of suitably defined error functions, a similar strategy as that used for the neural network training in the NNPDF fits <ref type="bibr" coords="3,65.11,545.16,16.16,8.76" target="#b43">[45,</ref><ref type="bibr" coords="3,81.27,545.16,12.12,8.76" target="#b44">46]</ref>. The resulting compressed Monte Carlo PDFs, or CMC-PDFs for short, are then validated for a wide variety of LHC observables, both at the level of inclusive cross sections, differential distributions, and correlations, finding that using around N rep = 100 replicas are enough to reproduce the original results for all the processes we have considered.</p><p xml:id="_bqK52mA">Another important application of the compression algorithm is to native Monte Carlo PDF sets. For instance, in the NNPDF framework, a large number of replicas, around N rep = 1000, are required to reproduce fine details of the underlying probability distribution such as small correlations. Therefore, we can apply the same compression algorithm also to native MC PDF sets, and end up with a much smaller number of replicas conveying the same infor-mation as the original probability distribution. Therefore, in this work we will also present results of this compression of the NNPDF3.0 NLO N rep = 1000 set. Note that despite the availability of the compressed sets, PDF sets with N rep = 1000 replicas are still needed for other applications, for instance for Bayesian reweighting <ref type="bibr" coords="3,458.37,121.74,16.15,8.76" target="#b45">[47,</ref><ref type="bibr" coords="3,474.52,121.74,12.11,8.76" target="#b46">48]</ref>.</p><p xml:id="_cpGGfke">The outline of this paper is as follows. First of all in Sect. 2 we review the Monte Carlo method for the combination of individual PDF sets, and we present results for the combination of the NNPDF3.0, MMHT14, and CT14 NNLO, both at the level of PDFs and for selected benchmark LHC cross sections. Then in Sect. 3 we describe the compression algorithm used to reduce the number of replicas of a MC PDF set. Following this, in Sect. 4 we present our main results for the CMC-PDFs, and validate our approach for the PDF central values, variances and correlations, together with selected parton luminosities. We also validate the compression of native MC sets, in particular using NNPDF3.0 NLO with N rep = 1000 replicas. Then in Sect. 5 we perform the validation of the CMC-PDFs at the level of LHC cross sections and differential distributions. Finally, in Sect. 6 we summarize and discuss the delivery of our results, both for the CMC-PDFs to be made available in LHAPDF6 <ref type="bibr" coords="3,510.89,333.44,16.60,8.76" target="#b47">[49]</ref> and for the compression code, which is also made publicly available <ref type="bibr" coords="3,325.64,358.35,15.26,8.76" target="#b48">[50]</ref>. Appendix contains a concise user manual for the compression code, which allows construction of CMC-PDFs starting from an arbitrary input combination of PDF sets.</p><p xml:id="_8yFS76a">The detailed comparison of the CMC-PDFs with those of the Meta-PDF and MC2H methods will be presented in the upcoming PDF4LHC report with the recommendations about PDF usage at Run II.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2" xml:id="_2JTATfF">Combining PDF sets using the Monte Carlo method</head><p xml:id="_KTR93tb">In this section we review the Monte Carlo method for combination of different PDF sets, and we provide results for the combination of the recent NNPDF3.0, CT14, and MMHT14 NNLO PDF sets. We then compare this combined PDF set with the predictions from the three individual sets for a number of benchmark LHC inclusive cross sections and their correlations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1" xml:id="_2rGJdzw">Combination strategy</head><p xml:id="_5tdyB8c">Our starting point is the same as that originally suggested by Forte in Ref. <ref type="bibr" coords="3,359.91,632.53,10.58,8.76" target="#b0">[1]</ref>. First of all we decide which sets enter the combination, then transform the Hessian sets into a Monte Carlo representation using the Watt and Thorne method <ref type="bibr" coords="3,527.65,657.43,16.62,8.76" target="#b33">[35]</ref> and finally combine the desired number of replicas from each set to construct the joint probability distribution of the combination. This strategy was already used in <ref type="bibr" coords="3,474.23,694.79,12.69,8.76" target="#b1">[2,</ref><ref type="bibr" coords="3,486.92,694.79,12.69,8.76" target="#b33">35,</ref><ref type="bibr" coords="3,499.61,694.79,12.69,8.76" target="#b34">36]</ref> to compare the predictions of the Monte Carlo combination of PDF sets with those of the original PDF4LHC envelope recommendation <ref type="bibr" coords="4,95.60,71.92,16.16,8.76" target="#b23">[24,</ref><ref type="bibr" coords="4,111.75,71.92,12.12,8.76" target="#b24">25]</ref>.</p><p xml:id="_5J7BMxs">Let us recall that a Monte Carlo representation for a Hessian set can be constructed <ref type="bibr" coords="4,178.88,96.82,16.61,8.76" target="#b33">[35]</ref> by generating a multi-Gaussian distribution in the space of fit parameters, with mean value corresponding to the best-fit result, and with width determined by the Hessian matrix. This is most efficiently done in the basis where the Hessian matrix is diagonal, and in this case Monte Carlo replicas can be generated using</p><formula xml:id="formula_0" coords="4,51.69,198.77,237.45,44.70">F k = F(q 0 )+ 1 2 N eig j=1 F(q + j )− F(q − j ) R k j , k = 1, . . . , N rep ,<label>(1)</label></formula><p xml:id="_UGtHdU5">where q 0 and q ± j are, respectively, the best-fit and the asymmetric jth eigenvector PDF member, and R k j are univariate Gaussian random numbers. For most practical applications, N rep = 100 are enough to provide an accurate representation of the original Hessian set <ref type="bibr" coords="4,270.07,313.23,15.26,8.76" target="#b33">[35]</ref>. In this work we use the LHAPDF6 <ref type="bibr" coords="4,216.28,325.69,16.60,8.76" target="#b47">[49]</ref> implementation<ref type="foot" coords="4,66.53,336.11,3.79,6.66" target="#foot_0">1</ref> of Eq. ( <ref type="formula" coords="4,107.13,338.13,3.53,8.76" target="#formula_0">1</ref>). In particular, we use the LHAPDF6 program examples/hessian2replicas.cc to convert an entire Hessian set into its corresponding MC representation. In Eq. ( <ref type="formula" coords="4,112.95,375.50,3.87,8.76" target="#formula_0">1</ref>) the quantity F represents the value of a particular PDF at (x, Q) and flavors corresponding to the original LHAPDF6 grids.</p><p xml:id="_K2SDKRQ">Once Hessian PDF sets have been converted into their Monte Carlo representations, one needs to decide how many replicas N (i) rep of each PDF set i will be included in the combination. The combined probability distribution is simply P = n i=1 w i P i , where P i (i = 1, . . . , n) are the probability distributions for each of the n individual PDF sets and the weights</p><formula xml:id="formula_1" coords="4,61.40,483.51,227.75,29.49">w i = N (i) rep / N rep (i = 1, . . . , n), where n i=1 w i = 1 and N rep = n i=1 N (i)</formula><p xml:id="_kbUseDy">rep is the total number of replicas. The simplest case, corresponding to an equal degree of belief in the predictions from each of the PDF sets in the combination, is to use the same number of replicas, say N (i) rep = 300, from each set. This approach is justified in the case of fits based on a similar global dataset and comparable theory inputs, as will be the case in this work. Choosing the correct value of N (i) rep for sets based on a reduced dataset, or with very different theory inputs, is a more complex problem which is not discussed here. Note that taking the average over a large number of Monte Carlo replicas generated using Eq. (1) will recover the best-fit PDF member F(q 0 ) only up to statistical fluctuations.</p><p xml:id="_fv3Th9u">Using this Monte Carlo combination method, we have produced a combined set with N rep = 900 replicas from adding together N (i) rep = 300 replicas of the NNPDF3.0, CT14 and MMHT14 NNLO sets. Study of the properties of the prior with respect N rep shows that at least 900 replicas are required to eliminate the statistical fluctuations from Eq. ( <ref type="formula" coords="4,536.52,123.60,3.87,8.76" target="#formula_0">1</ref>) down to an acceptable level. For the three groups we use a common value of α s (M Z ) = 0.118. One requirement for the validation of this procedure is that the combination of the same number of instances of n different probability distributions should have mean μ ≈ 1 n n i=1 μ i and variance</p><formula xml:id="formula_2" coords="4,306.16,195.42,136.18,14.28">σ 2 ≈ n i=1 μ 2 i + σ 2 i /n − μ 2 .</formula><p xml:id="_Hbsq2MR">The equality only holds when the three input distributions are Gaussian, which in the case of NNPDF is approximately true in the experimental data region.</p><p xml:id="_GwkT2af">In this MC combination strategy, which is a common ingredient of the CMC-PDF, Meta-PDF, and MC2H methods, the theoretical inputs from each PDF group, like the method of solution of the DGLAP evolution equations, or the values of the heavy-quark masses, are not modified. Given that the current MC combination is based on PDF sets with different choices of the heavy-quark masses m c and m b , and different heavy-quark schemes, for applications which depend sizably on the values of the heavy-quark masses and/or of the PDFs close to the heavy-quark thresholds, one should use the individual PDF sets rather than their combination. This might, however, change in future combinations if these are based on PDF sets with common settings for the treatment of heavy quarks.</p><p xml:id="_6jg6fqD">While the starting point is common, the differences between the three reduction methods arises in the strategies adopted to decrease the number of error PDF sets in the combination, which is achieved by compressing the MC representation (CMC-PDFs) or by constructing a Hessian representation, based either on a meta-parametrization (Meta-PDFs) or in a linear expansion over the MC replicas themselves (MC2H). In the Meta-PDF approach <ref type="bibr" coords="4,502.05,509.66,15.27,8.76" target="#b39">[41]</ref>, common theory settings are used to evolve upwards the metaparameterization starting from Q 0 = 8 GeV using HOP-PET <ref type="bibr" coords="4,325.79,547.01,15.27,8.76" target="#b49">[51]</ref>, while CMC-PDF and MC2H maintain the original theory settings of each individual PDF set. It has been concluded, following a careful benchmarking between the two groups, that both options provide an adequate enough representation of the MC prior for Q &gt; m b , and in any case the current combined PDFs should not be used for Q m b .</p><p xml:id="_dJ64TN9">In Fig. <ref type="figure" coords="4,347.13,621.73,4.98,8.76" target="#fig_0">1</ref> we show the comparison of the individual PDF sets, NNPDF3.0, CT14, and MMHT14, with their Monte Carlo combination with N rep = 900. In the following, we will denote by MC900 this prior combination. The comparison is performed at a typical LHC scale of Q = 100 GeV, and the PDFs are normalized to the central value of the combined set. As can be seen there is reasonable agreement between the three individual sets, and the resulting combined set is a good measure of their common overlap. Note that at large-x differences between the three sets are rather marked, and we expect the resulting combined probability distribution to be rather non-Gaussian.</p><p xml:id="_MqcC78s">In Fig. <ref type="figure" coords="5,91.83,561.20,4.98,8.76" target="#fig_1">2</ref> we show the histograms representing the distribution of Monte Carlo replicas in the individual PDF sets and in the combined set, for different flavors and values of (x, Q). From top to bottom and from left to right we show the gluon at x = 0.01 (relevant for Higgs production in gluon fusion), the up quark at x = 5 • 10 −5 (at the lower edge of the region covered by HERA data), the down antiquark for x = 0.2 (relevant for high-mass searches) and the strange PDF for x = 0.05 (accessible at the LHC through W +charm production). All PDFs have been evaluated at Q = 100 GeV.</p><p xml:id="_jyMzATs">The histograms for the MC900 prior allow us to determine in each case how close the combined distribution is to a nor-mal distribution, by comparison with a Gaussian computed using the same mean and variance of the MC900 set. From this comparison in Fig. <ref type="figure" coords="5,403.29,523.84,3.73,8.76" target="#fig_1">2</ref>, we see that while in some cases the underlying distribution of the MC900 PDFs is reasonably Gaussian, like for g(x = 0.01) and u(x = 5 • 10 −5 ), in others, for d(x = 0.2) and s(x = 0.05), the Gaussian approximation is not satisfactory. Deviations from a Gaussian distribution are in general more important for PDFs in extrapolation regions with limited experimental information.</p><p xml:id="_5mpZwEF">Concerning the treatment of the PDF+α s uncertainties, the updated PDF4LHC recommendation <ref type="bibr" coords="5,458.98,623.46,16.60,8.76" target="#b31">[33]</ref> proposes a simplified prescription based on the addition in quadrature of the separated δσ PDF and δσ α s uncertainties, based on the realization that this always gives approximately the same answer as more sophisticated methods, and in some procedures exactly the same answer. In the case of the Monte Carlo combination, this prescription can be implemented by  Half of the spread of the predictions computed with the central values of the CMC-PDFs with α s (M Z ) = 0.1165 and α s (M Z ) = 0.1195 defines then the one-sigma δσ α s uncertainty. This assumes α s (M Z ) = 0.118 ± 0.0015 as an external input, but a different value of δα s can be implemented by a simple rescaling. Note also that for the MC900 sets with α s (M Z ) = 0.118, only the central values are required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2" xml:id="_VX3pmC4">PDF dependence of benchmark LHC cross sections</head><p xml:id="_yMJkWKr">As stated in the introduction, the goal of this work is to compress the MC900 prior by roughly an order of magnitude, from the starting N rep = 900 to at least N rep 100, and to validate the results of this compression for a number of LHC observables. In Sect. 4 we will show the results of applying the compression strategy of Sect. 3 to the combined MC set. But first let us explore how the predictions from MC900 prior compare with the individual PDF sets for a variety of LHC cross sections. We also compare the correlations between physical observables for the individual PDF sets to their combination.</p><p xml:id="_7maAPxa">In the following we consider a number of NNLO inclusive cross sections: Higgs production in gluon fusion, computed using ggHiggs <ref type="bibr" coords="6,394.27,640.96,15.27,8.76" target="#b50">[52]</ref>, top-quark pair production, using top++ <ref type="bibr" coords="6,337.96,653.41,15.27,8.76" target="#b51">[53]</ref>, and inclusive W and Z production, using VRAP <ref type="bibr" coords="6,335.64,665.87,15.27,8.76" target="#b52">[54]</ref>. In all cases we use the default settings in each of these codes, since our goal is to study similarities and differences between the predictions of each of the PDF sets, for fixed theory settings. The results for these inclusive cross sections are shown in Fig. <ref type="figure" coords="7,81.33,653.21,3.73,8.76" target="#fig_2">3</ref>. We also show with dashed lines the envelope of the one-sigma range obtained from the three individual sets, which would correspond to the total PDF uncertainty for this process if obtained following the present PDF4LHC recommendation. We see that in general the two methods, the MC combination and the envelope, give similar results, the former leading to a smaller estimate of the total PDF uncertainty since the envelope assigns more weight to outliers than what would be required on a statistical basis.</p><p xml:id="_juyGMMW">It is also useful to compare the correlations between LHC cross sections computed with the individual PDF sets and with the MC900 combined set. A representative set of these correlations is shown in Fig. <ref type="figure" coords="8,163.89,638.46,3.73,8.76" target="#fig_3">4</ref>, computed using the same settings as above. In addition to the processes shown in Fig. <ref type="figure" coords="8,281.68,650.92,3.73,8.76" target="#fig_2">3</ref>, here we also show correlations for the W W and W h production NLO total cross sections computed with MFCM. For MMHT14 and CT14, correlations are computed from their Monte Carlo representation.</p><p xml:id="_tQwwEm5">From the comparison of the correlation coefficients shown in Fig. <ref type="figure" coords="8,336.72,638.46,4.98,8.76" target="#fig_3">4</ref> we note that the correlation coefficients between LHC cross sections for the three global sets, NNPDF3.0, CT14, and MMHT14, can differ substantially more than for central values and variances. This effect was also noticed in the Higgs Cross-Section Working Group study of PDF-induced correlations between Higgs production chan-nels <ref type="bibr" coords="9,69.42,59.46,15.27,8.76" target="#b53">[55]</ref>. By construction, the correlation coefficient for the combined MC prior produces the correct weighted average of the correlations from the individual sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3" xml:id="_G3QE4ar">The compression algorithm</head><p xml:id="_c6ckjnX">In the previous section we have described and validated the combination of different PDF sets, based on the Monte Carlo method. We have shown that the probability distribution of such a combined PDF set can be represented by N rep Monte Carlo replicas. Now in this section we introduce a compression algorithm that aims to determine, for a fixed (smaller) number of MC replicas N rep &lt; N rep , the optimal subset of the original representation that most faithfully reproduces the statistical properties of the combined PDF prior distribution.</p><p xml:id="_g3Hxu9y">First of all, we begin with a presentation of the mathematical problem, followed by a description of the technical aspects of the compression strategy, where we describe the choice of error function and related parameters that have been chosen in this work. Then we apply the compression method to the combined Monte Carlo PDFs, producing what will be dubbed as CMC-PDFs in the rest of this paper. We also show how the compression strategy can be applied to native Monte Carlo PDF sets, using the NNPDF3.0 NLO set with N rep = 1000 as an illustration. The validation of the compression at the level of parton distributions and physical observables is then performed in Sects. 4 and 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1" xml:id="_My6eUBA">Compression: mathematical framework</head><p xml:id="_eU5AtzP">Let us begin by presenting an overview of the mathematical framework for the problem that we aim to address, namely the compression of a given probability distribution function. The starting point is to consider a representation of a probability distribution p = ( p 1 , . . . , p n ), using a finite number n of instances. In the case at hand, the number of instances is given by the number of Monte Carlo replicas N rep . Any smaller number set of replicas, N rep &lt; N rep , produces a corresponding probability distribution q, which entails a loss of information with respect to the original distribution p. The problem of optimal compression can be mathematically stated as follows. We would like to find the specific subset of the original set of replicas such that the statistical distance between the original and the compressed probability distributions is minimal. In other words, we look for a subset of replicas that delivers a probability distribution as indistinguishable from the prior set as possible.</p><p xml:id="_G5CKDwv">A number of different figures of merit to quantify the distinguishability of probability distribution were proposed many decades ago. Some of the first efforts are accounted in the book of Hardy et al. <ref type="bibr" coords="9,144.59,682.33,15.27,8.76" target="#b54">[56]</ref>, where ideas about strong ordering (majorization) were introduced. Later on, the problem of distinguishability was quantified using the concept of statis-tical distance among probability distributions. In particular, the Kolgomorov distance</p><formula xml:id="formula_3" coords="9,306.77,97.59,237.50,21.34">K ( p, q) = i | p i − q i |, i = 1, . . . , n,<label>(2)</label></formula><p xml:id="_fRafvHH">where the index i runs over the number of instances of p, is a simple and powerful example of a figure of merit that quantifies how different a probability distribution is from another one.</p><p xml:id="_T9xpmpb">With the advent of Information Theory, Shannon introduced the concept of surprise of a probability distribution as its distance to the even prior. This can be characterized using Shannon entropy S( p) = − i p i log p i . It is, then, natural to quantify distinguishability between two probability distributions p and q using entropy concepts <ref type="bibr" coords="9,470.04,245.20,15.27,8.76" target="#b55">[57]</ref>. This leads to the construction of the Kullback-Leibler divergence</p><formula xml:id="formula_4" coords="9,306.92,278.35,233.48,27.36">D( p|| q) = i=1,...,n q i log q i p i , (<label>3</label></formula><formula xml:id="formula_5" coords="9,540.40,285.25,3.87,8.76">)</formula><p xml:id="_4bwpxhF">which differs from the Kolmogorov distance in the sense that it weights more the largest probabilities. Later refinements produced the ideas of symmetric statistical distances, like the symmetrized Kullback and the Chernhoff distances, used in Quantum Information nowadays. As a consequence of these trend of ideas, it is clear there are very many well-studied options to define a distance in probability space. Since their variations are not large, any of them should be suitable for the problem of Monte Carlo PDF compression, and we present our specific choice in Sect. 3.2.</p><p xml:id="_xYSbhq9">Let us now be more precise on the way we shall proceed. If we define { p} as the original representation of the probability distribution (with N rep replicas) and { q} its compressed version (with N rep replicas), then given the concept of a distance d between two probability distributions there is an optimal choice of the subset with N rep replicas defined as</p><formula xml:id="formula_6" coords="9,306.16,531.56,234.23,11.17">{ q} opt ≡ Min { q} d ({ q}, { p}) . (<label>4</label></formula><formula xml:id="formula_7" coords="9,540.39,532.43,3.88,8.76">)</formula><p xml:id="_UHcg5Mm">Therefore, the mathematical problem at stake is reduced to finding the optimal subset { q} opt , by a suitable exploration of the space of minima of the distance d ({ q}, { p}). In this work, this exploration is performed using genetic algorithms, though many other choices would also be suitable. Fortunately, many choices of subset are equally good minimizations. From the practical point of view, the specific choice of the minimization strategy is not critical. It is clear that the relevant point is the definition of a distance between the original and compressed replica sets. In this paper we shall take the following approach. Many valid definitions of statistical distance differ in the way different moments are weighted. Since we are inter-ested in reproducing real physics, which is dominated by low moments, we shall explicitly include in our figure of merit all the distances between means and standard deviations, but also kurtosis, skewness and correlations, as well as higher moments. As a consequence, all of them will be minimized, favoring the role of smaller moments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2" xml:id="_DfRajSJ">A compression algorithm for Monte Carlo PDF sets</head><p xml:id="_cwVRCnG">As we have discussed above, the most important ingredient for the compression strategy is the choice of a suitable distance between the prior and the compressed distributions, Eq. ( <ref type="formula" coords="10,70.29,208.91,3.53,8.76" target="#formula_6">4</ref>), or in other words, the definition of the error function (ERF in the following) for the minimization problem. We have explored different possibilities, and the precise definition of the ERF that will be used in this work can be written generically as follows:</p><formula xml:id="formula_8" coords="10,51.04,275.67,234.24,33.81">ERF = k 1 N k i C (k) i − O (k) i O (k) i 2 , (<label>5</label></formula><formula xml:id="formula_9" coords="10,285.27,288.79,3.87,8.76">)</formula><p xml:id="_s5f9rYh">where k runs over the number of statistical estimators used to quantify the distance between the original and compressed distributions,</p><formula xml:id="formula_10" coords="10,105.39,342.03,128.57,13.71">N k is a normalization factor, O (k)</formula><p xml:id="_Ef8Dqsf">i is the value of the estimator k (for example, the mean or the variance) computed at the generic point i (which could be a given value of (x, Q) in the PDFs, for instance), and C (k) i is the corresponding value of the same estimator in the compressed set. The choice of a normalized ERF is important for the accuracy of the minimization because some statistical estimators, in particular higher moments, can span various orders of magnitude in different regions of x and Q 2 .</p><p xml:id="_S4f42EZ">An schematic diagram for our compression strategy is shown in Fig. <ref type="figure" coords="10,111.00,470.63,3.73,8.76" target="#fig_4">5</ref>. The prior set of Monte Carlo PDF replicas, the desired number of compressed replicas, N rep , and the value of the factorization scale Q at which the PDFs are evaluated, Q 0 , are the required parameters for the compression algorithm. Note that it is enough to sample the PDFs in a range of values of Bjorken-x at a fixed value of Q 0 , since the DGLAP equation uniquely determines the evolution for higher scales Q ≥ Q 0 . The minimization of the error function is performed using genetic algorithms (GAs), similarly as in the neural network training of the NNPDF fits. GAs work as usual by finding candidates for subsets of N rep leading to smaller values of the error function Eq. ( <ref type="formula" coords="10,237.44,607.61,3.88,8.76" target="#formula_8">5</ref>) until some suitable convergence criterion is satisfied. The output of this algorithm is thus the list of the N rep replicas from the prior set of N rep that minimize the error function. These replicas define the CMC-PDFs for each specific value of N rep . The final step of the process is a series of validation tests where the CMC-PDFs are compared to the prior set in terms of parton distributions at different scales, luminosities, and LHC cross sections, in a fully automated way. It is important to emphasize that the compression algorithm only selects replicas from a prior set, and no attempt is made to use common theoretical settings, i.e., the method for the solution of the DGLAP evolution equations, or the values of the heavy-quark masses, which are those of the corresponding original PDF sets. This important fact automatically ensures that the compressed set conserves all basic physical requirements of the original combined set such as the positivity of physical cross sections, sum rules, and the original correlations between PDFs. To avoid problems related to the different treatment of the heavy-quark thresholds between the different groups, we choose in this work to compress the combined MC PDF set at a common scale of Q 0 = 2 GeV, while we use Q 0 = 1 GeV when compressing the native NNPDF3.0 NLO set.</p><p xml:id="_ZCMXHT3">The compression strategy seems conceptually simple: reducing the size of a Monte Carlo PDF set requiring no substantial loss of information. In order to achieve its goal, the compression algorithm must preserve as much as possible the underlying statistical properties of the prior PDF set. However, this conceptual simplicity is followed by a series of non-trivial issues that have to be addressed in the practical implementation. Some of these issues are the sampling of the PDFs in Bjorken-x, the exact definition of the error function, Eq. ( <ref type="formula" coords="10,325.42,586.97,3.53,8.76" target="#formula_8">5</ref>), the treatment of PDF correlations and the settings of the GA minimization. We now discuss these various issues in turn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1" xml:id="_88CJNYJ">Definition of the error function for the compression</head><p xml:id="_zja9ufj">In this work we include in the ERF, Eq. ( <ref type="formula" coords="10,478.11,682.33,3.53,8.76" target="#formula_8">5</ref>), the distances between the prior and the compressed sets of PDFs for the following estimators:</p><p xml:id="_TWdR47D">• The first four moments of the distribution, which are sampled in a grid of x points for n f flavors in terms of central value, standard deviation, skewness, and kurtosis, at a fixed value of Q = Q 0 . It is important to notice that these estimators are necessary in order to obtain a realistic and optimized compressed MC set, but are not sufficient to avoid eventual bias of continuity and loss of structure. • The output of the Kolmogorov-Smirnov test. This is the simplest distance between empirical probability distributions. This distance complements the terms in the ERF which contain the first four moments, by ensuring that also higher moments are automatically adjusted. However, if this estimator is used alone possible ambiguities arise when defining the regions where the distance is computed, leading to large errors when working with few replicas. • The correlation between multiple PDF flavors at different</p><p xml:id="_waHWhua">x points. This information is important for ensuring that PDF-induced correlations in physical cross sections are successfully maintained.</p><p xml:id="_zdqMWRe">The final figure of merit used in the compression fit is then the sum over all these six estimators opportunely weighted by the corresponding normalization factors N k in Eq. ( <ref type="formula" coords="11,278.57,359.83,3.53,8.76" target="#formula_8">5</ref>). This normalization is required due to the fact that the absolute value of the various estimators can vary among them by several orders of magnitude.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2" xml:id="_ZyMpPSJ">Central values, variances, and higher moments</head><p xml:id="_kefkzj8">Let's denote by g (k)  i (x j , Q 0 ) and f (r ) i (x j , Q 0 ), respectively, the prior and the compressed sets of replicas for a flavor i at the position j of the x-grid containing N x points. N rep is the number of required compressed replicas. We then define the contribution to the ERF from the distances between central values of the prior and compressed distributions as follows:</p><formula xml:id="formula_11" coords="11,51.04,548.72,234.24,46.35">ERF CV = 1 N CV n f i=−n f N x j=1 f CV i (x j , Q 0 ) − g CV i (x j , Q 0 ) g CV i (x j , Q 0 ) 2 , (<label>6</label></formula><formula xml:id="formula_12" coords="11,285.27,586.32,3.87,8.76">)</formula><p xml:id="_gVXmGfQ">where N CV is the normalization factor for this estimator. We only include in the sum those points for which the denominator satisfies g CV i (x j , Q 0 ) = 0. As usual, central values are computed as the average over the MC replicas, for the compressed set</p><formula xml:id="formula_13" coords="11,53.22,686.44,235.92,33.15">f CV i (x j , Q 0 ) = 1 N rep N rep r =1 f (r ) i (x j , Q 0 ),<label>(7)</label></formula><p xml:id="_g5m6Knx">while for the prior set we have</p><formula xml:id="formula_14" coords="11,306.37,84.33,234.02,32.87">g CV i (x j , Q 0 ) = 1 N rep N rep k=1 g (k) i (x j , Q 0 ). (<label>8</label></formula><formula xml:id="formula_15" coords="11,540.40,96.73,3.87,8.76">)</formula><p xml:id="_Hs9RCBr">Let us also define r t i (x j , Q 0 ) as a random set of replicas extracted from the prior set, where t identifies an ensemble of random extractions. The number of random extraction of random sets is denoted by N rand . Now, the normalization factors are extracted for all estimators as the lower 68 % confidence-level value obtained after N rand realizations of random sets. In particular for this estimator we have</p><formula xml:id="formula_16" coords="11,306.82,240.50,233.58,84.26">N CV = 1 N rand N rand d=1 n f i=−n f N x j=1 × r d,CV i (x j , Q 0 ) − g CV i (x j , Q 0 ) g CV i (x j , Q 0 ) 2 68 % lower band . (<label>9</label></formula><formula xml:id="formula_17" coords="11,540.40,316.00,3.87,8.76">)</formula><p xml:id="_S2Gassx">For the contribution to the ERF from the distance between standard deviation, skewness, and kurtosis, we can build expressions analogous to that of Eq. ( <ref type="formula" coords="11,452.63,364.37,3.87,8.76" target="#formula_11">6</ref>) by replacing the central value estimator with the suitable expression for the other statistical estimators, which in a Monte Carlo representation can be computed as</p><formula xml:id="formula_18" coords="11,308.34,424.02,231.77,64.92">f STD i (x j , Q 0 ) = 1 N rep − 1 N rep r =1 f (r ) i (x j , Q 0 ) − f CV i (x j , Q 0 ) 2 , (<label>10</label></formula><formula xml:id="formula_19" coords="11,540.10,480.18,4.16,8.76">)</formula><formula xml:id="formula_20" coords="11,308.34,504.54,238.06,71.24">f SKE i (x j , Q 0 ) = 1 N rep N rep r =1 × f (r ) i (x j , Q 0 ) − f CV i (x j , Q 0 ) 3 f STD i (x j , Q 0 ) 3 , (<label>11</label></formula><formula xml:id="formula_21" coords="11,540.11,567.02,4.15,8.76">)</formula><formula xml:id="formula_22" coords="11,308.34,582.57,238.10,71.25">f KUR i (x j , Q 0 ) = 1 N rep N rep r =1 × f (r ) i (x j , Q 0 ) − f CV i (x j , Q 0 ) 4 f STD i (x j , Q 0 ) 4 , (<label>12</label></formula><formula xml:id="formula_23" coords="11,540.13,645.06,4.17,8.76">)</formula><p xml:id="_JmnzKh9">for the compressed set, with analogous expressions for the original prior set.</p><p xml:id="_tfZPAfp">The normalization factors for these estimators are extracted using the same strategy presented in Eq. ( <ref type="formula" coords="11,481.22,707.24,3.53,8.76" target="#formula_16">9</ref>), by averaging over random extractions of N rep replicas, exchanging CV by STD, SKE, and KUR, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3" xml:id="_8R7dyy9">The Kolmogorov-Smirnov distance</head><p xml:id="_yuw5vBQ">As we have mentioned above, the minimization of the Kolmogorov-Smirnov distance ensures that both lower and higher moments of the prior distribution are successfully reproduced. In our case, we define the contribution to the total ERF from the Kolmogorov-Smirnov (KS) distance as follows:</p><formula xml:id="formula_24" coords="12,51.04,208.93,235.99,46.35">ERF KS = 1 N KS n f i=−n f N x j=1 (r ) k=1 F k i (x j , Q 0 ) − G k i (x j , Q 0 ) G k i (x j , Q 0 ) 2 . (<label>13</label></formula><formula xml:id="formula_25" coords="12,285.00,246.52,4.15,8.76">)</formula><p xml:id="_JAVaQry">where</p><formula xml:id="formula_26" coords="12,78.03,269.25,111.42,13.52">F k i (x j , Q 0 ) and G k i (x j , Q 0 )</formula><p xml:id="_ZzGBbPr">are the outputs of the test for the compressed and the prior set of replicas, respectively. The output of the test consists in counting the number of replicas contained in the k regions where the test is performed. We count the number of replicas which fall in each region and then we normalize by the total number of replicas of the respective set. Here we have considered six regions defined as multiples of the standard deviation of the distribution for each flavor i and x j -point. As an example for the compressed set, the regions are</p><formula xml:id="formula_27" coords="12,56.87,406.74,228.13,28.89">− ∞, −2 f STD i (x j , Q 0 ), − f STD i (x j , Q 0 ), 0, f STD i (x j , Q 0 ), 2 f STD i (x j , Q 0 ), +∞ , (<label>14</label></formula><formula xml:id="formula_28" coords="12,285.00,424.90,4.15,8.76">)</formula><p xml:id="_wKNtp7D">where the values of the PDFs have been subtracted from the corresponding central value.</p><p xml:id="_BKUndkZ">In this case, the normalization factor is determined from the output of the KS test for random sets of replicas extracted from the prior, denoted R k i (x j , Q 0 ) as follows:</p><formula xml:id="formula_29" coords="12,51.71,522.95,233.28,71.12">N KS = 1 N rand N rand d=1 n f i=−n f N x j=1 6 k=1 × R k i (x j , Q 0 ) − G k i (x j , Q 0 ) G k i (x j , Q 0 ) 2 , (<label>15</label></formula><formula xml:id="formula_30" coords="12,285.00,574.71,4.15,8.76">)</formula><p xml:id="_ux2znsr">and we only include in the sum those points for which the denominator satisfies G k i (x j , Q 0 ) = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4" xml:id="_6Q9yM3T">PDF correlations</head><p xml:id="_ySSdnxk">In addition to all the moments of the prior distribution, a sensible compression should also maintain the correlations between values of x and between flavors of the PDFs. In order to achieve this, correlations are taken into account in the ERF by means of the trace method. We define a correlation matrix C for any PDF set as follows:</p><formula xml:id="formula_31" coords="12,306.12,93.51,233.99,24.67">C i j = N rep N rep − 1 • i j − i j σ i • σ j , (<label>16</label></formula><formula xml:id="formula_32" coords="12,540.11,101.37,4.15,8.76">)</formula><p xml:id="_b7exqyB">where we have defined</p><formula xml:id="formula_33" coords="12,305.42,147.04,234.69,70.75">i = 1 N rep N rep r =1 f (r ) i (x i , Q 0 ), i j = 1 N rep N rep r =1 f (r ) i (x i , Q 0 ) f (r ) j (x j , Q 0 ), (<label>17</label></formula><formula xml:id="formula_34" coords="12,540.11,177.30,4.15,8.76">)</formula><p xml:id="_DFgDWXK">and σ is the usual expression for the standard deviation</p><formula xml:id="formula_35" coords="12,306.16,250.52,233.95,33.15">σ i = 1 N rep − 1 N rep r =1 f (r ) i (x i , Q 0 ) − i 2 . (<label>18</label></formula><formula xml:id="formula_36" coords="12,540.11,262.93,4.15,8.76">)</formula><p xml:id="_KSCgtSU">Now, for each flavor n f we define N corr x points distributed in x where the correlations are computed. The trace method consists in computing the correlation matrix P based on Eq. ( <ref type="formula" coords="12,326.45,334.15,8.29,8.76" target="#formula_31">16</ref>) for the prior set and then store its inverse P −1 . For n f flavors and N corr x points we obtain</p><formula xml:id="formula_37" coords="12,306.38,368.24,233.74,14.03">g = Tr(P • P −1 ) = N corr x • (2 • n f + 1). (<label>19</label></formula><formula xml:id="formula_38" coords="12,540.11,371.45,4.15,8.76">)</formula><p xml:id="_fwJthau">After computing the correlation matrix for prior set, for each compressed set a matrix C is computed and the trace is determined by</p><formula xml:id="formula_39" coords="12,308.34,442.83,231.77,12.28">f = Tr(C • P −1 ). (<label>20</label></formula><formula xml:id="formula_40" coords="12,540.10,446.02,4.16,8.76">)</formula><p xml:id="_rB5ZJJt">The compression algorithm then includes the correlation ERF by minimizing the quantity:</p><formula xml:id="formula_41" coords="12,306.16,505.46,233.95,26.74">ERF Corr = 1 N Corr f − g g 2 (<label>21</label></formula><formula xml:id="formula_42" coords="12,540.11,515.40,4.15,8.76">)</formula><p xml:id="_cU9vvdw">where N Corr is computed as usual from the random sets, in the same way as Eq. ( <ref type="formula" coords="12,393.15,557.37,3.53,8.76" target="#formula_16">9</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_cMTtUr6">3.2.5</head><p xml:id="_xrtSnK8">Choice of GA parameters in compressor v1.0.0</p><p xml:id="_ySpBPwf">The general strategy that has been presented in this section has been implemented in compressor v1.0.0, the name of the public code <ref type="bibr" coords="12,381.82,644.97,16.60,8.76" target="#b48">[50]</ref> released together with this paper. A more detailed description of the code usage is provided in the appendix. The availability of this code ensures that it will be possible to easily redo the compression for any further combination of PDF sets that might be considered in the future. x max 0.9</p><formula xml:id="formula_43" coords="13,51.04,184.38,220.73,140.70">n f 7 Q 0 User-defined N corr x 5 N rand 1000 (b) N mut rep P mut (%) 1 3 0 2 3 0 3 1 0 4 3 0</formula><p xml:id="_krQnx4w">This said, there is a certain flexibility in the choice of settings for the compression, for example in the choice of parameters for the genetic algorithms, the sampling of the PDFs in x or the choice of common scale for the compression Q 0 . The compression setup used in this paper is presented in Table <ref type="table" coords="13,75.57,420.82,4.98,8.76">1</ref> together with the optimal set of GA parameters and mutation probability rates, determined by trial and error.</p><p xml:id="_sShsyH2">As mentioned before, in the present work the compression of CMC-PDFs is performed at a scale of Q 0 = 2 GeV while in the next section we use Q 0 = 1 GeV for the native NNPDF3.0 NLO set. The ERF includes only the contribution of the n f = 7 light partons: u, ū, d, d, s, s, and g. Concerning the sampling of the PDFs in x, we have limited the range of x points to the region where data is available, i.e. x ∼ [10 −5 , 0.9], by selecting 35 points logarithmically spaced between [10 −5 , 0.1] and 35 points linearly spaced from [0.1, 0.9]. Note that this is different from the Meta-PDF approach, where for each PDF a different range [x min , x max ] is used for the fit with the meta-parametrization, restricted to the regions where experimental constraints are available for each flavor.</p><p xml:id="_nQE2xxf">The correlation matrix is then computed for the n f input PDFs in N corr x = 5 points in x, generating a correlation matrix of 35 entries. Increasing the number of points for the calculation of the correlation matrix would be troublesome since numerical instabilities due to the presence of large correlations between neighboring points in x would be introduced.</p><p xml:id="_Zj7NKzk">The genetic algorithm minimization is performed for a fixed length of 15k generations. Note that as opposed to the Fig. <ref type="figure" coords="13,323.39,243.91,4.23,7.46">6</ref> The value of the total error function, Eq. ( <ref type="formula" coords="13,468.39,244.03,3.00,7.44" target="#formula_8">5</ref>), for the compression of the 1000 replica set of NNPDF3.0 NLO, as a function of the number of GA generations, for different values of the number of replicas in the compressed set N rep . After 15k iterations, the error function saturates and no further improvement of the error function would be achieved for longer training neural network learning in the NNPDF fits, in the compression problem there is no risk of over-learning, since the absolute minimum of the error function always exists. On the other hand, we find that after a few thousand generations the ERF saturates and no further improvements are achieving by running the code longer, hence the maximum number of GA generations N max gen = 15k used in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3" xml:id="_ATynvwe">Results of the compression for native MC PDF sets</head><p xml:id="_5NN9QQK">In order to illustrate the performance of the compression algorithm, we consider here the compression of a native Monte Carlo set of PDFs at Q 0 = 1 GeV, based on the prior set with N rep = 1000 replicas of NNPDF3.0 NLO. In Fig. <ref type="figure" coords="13,351.51,507.99,4.98,8.76">6</ref> we show the dependence of the total ERF as a function of the number of iterations of the GA for N rep = 10, 20, 30, 40, 50, 60, 70, 80, and 90. We observe that the first 1k iterations are extremely important during the minimization, while after 15k iterations the total error function is essentially flat for any required number of compressed replicas. For each compression, the final value of the error function is different, with deeper minima being achieved as we increase the number of compressed replicas, as expected. The flatness of the ERF as a function of the number of iterations confirms that the current parameters provide a suitably efficient minimization strategy.</p><p xml:id="_vQezcMQ">In order to quantify the performance of the compression algorithm, and to compare it with that of a random selection of the reduced set of replicas, Fig. <ref type="figure" coords="13,464.90,682.33,4.98,8.76">7</ref> shows the various contributions to the ERF, Eq. ( <ref type="formula" coords="13,427.29,694.79,3.53,8.76" target="#formula_8">5</ref>), for the compression of the NNPDF3.0 NLO set with N rep = 1000 replicas. For each  <ref type="figure" coords="14,68.28,655.11,4.23,7.46">7</ref> The various contributions to the ERF, Eq. ( <ref type="formula" coords="14,222.58,655.23,3.00,7.44" target="#formula_8">5</ref>), for the compression of the NNPDF3.0 NLO set with N rep = 1000 replicas. For each value of N rep , we show the value of each contribution to the ERF for the best-fit result of the compression algorithm (red points). We compare the results of the compression with the values of the ERF averaged over N rand = 1000 random partitions of N rep replicas (blue points), as well as the 50, 68, and 90 % confidence-level intervals computed over these random partitions. The dashed horizontal line is the 68 % lower band of the ERF for the average of the random partitions with N rep = 100, and is inserted for illustration purposes only value of N rep , we show the value of each contribution to the ERF for the best-fit result of the compression algorithm (red points). We compare the results of the compression with the values of the ERF averaged over N rand = 1000 random partitions of N rep replicas (blue points), as well as the 50, 68, and 90 % confidence-level intervals computed over these random partitions.</p><p xml:id="_DT5uJWE">Various observations can be made from the inspection of Fig. <ref type="figure" coords="15,69.26,159.10,3.73,8.76">7</ref>. First of all, the various contributions to the ERF tend to zero when the number of compressed or random replicas tends to the size of the prior set, as expected for consistency. For the random partitions of N rep replicas the mean value and the median values averaged over N rand trials are not identical, emphasizing the importance of taking confidence levels. From Fig. <ref type="figure" coords="15,125.17,233.81,4.98,8.76">7</ref> we also confirm that the compression algorithm is able to provide sets of PDFs with smaller ERF values for all estimators that outperform random selections with a much larger number of replicas. To emphasize this point, the dashed horizontal line in Fig. <ref type="figure" coords="15,209.09,283.63,4.98,8.76">7</ref> corresponds to the lower limit of the 68 % confidence level of the ERF computed over N rand = 1000 random partitions with N rep = 100, and is inserted for illustration purposes only. It indicates that the NNPDF3.0 NLO PDF set with N rep = 1000 can now be compressed down to N rep = 50 replicas in a way that reproduces better the original distribution that most of the random partitions of N rep = 100 replicas.</p><p xml:id="_kWtwjUs">The results of Fig. <ref type="figure" coords="15,140.07,383.26,4.98,8.76">7</ref> confirm that the compression algorithm outperforms essentially any random selection of replicas for the construction of a reduced set, and provides an adequate representation of the prior probability distribution with a largely reduced number of replicas. Similar results are obtained when compressing the CMC-PDFs, as we will discuss in Sect. 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4" xml:id="_puaVwyd">The compressed Monte Carlo PDF sets</head><p xml:id="_8qES3Dr">In this section we present the results for the CMC-PDFs, first discussing the compression of a native Monte Carlo PDF set, in this case NNPDF3.0 with N rep = 1000, and then the compression of the MC combination for NNPDF3.0, CT14, and MMHT14 with N rep = 900. In both cases, we compare the PDFs from the prior and compressed sets, for different values of the number of replicas N rep of the latter. We also verify that correlations between PDFs are successfully reproduced by the compression. The phenomenological validation of the CMC-PDF sets at the level of LHC observables is addressed in Sect. 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1" xml:id="_6XQ3s45">Compression of native MC PDF sets</head><p xml:id="_GTVTzeD">First of all, we show the results for the compression of a native MC PDF set, for the case of the NNPDF3.0 NLO set with N rep = 1000 replicas. In Fig. <ref type="figure" coords="15,194.49,707.24,4.98,8.76">8</ref> we compare the orig-inal and the compressed gluon and down quark at Q 2 = 2 GeV 2 , using N rep = 50 in the compressed set. Excellent agreement can be seen at the level of central values and variances. The comparison is also shown at a typical LHC scale of Q = 100 GeV, finding similar agreement. The plots in this section have been obtained using the APFEL-Web online PDF plotter <ref type="bibr" coords="15,355.24,134.19,16.15,8.76" target="#b56">[58,</ref><ref type="bibr" coords="15,371.39,134.19,12.12,8.76" target="#b57">59]</ref>. The result that the central values of the original set are perfectly reproduced by the compressed set can also be seen from Fig. <ref type="figure" coords="15,411.30,159.10,3.73,8.76">9</ref>, where we show the distribution of χ 2 for all the experiments included in the NNPDF3.0 fit, comparing the original and the compressed PDF set, and find that they are indistinguishable.</p><p xml:id="_gxgAvvf">Next, we compare in Fig. <ref type="figure" coords="15,424.17,208.91,9.96,8.76" target="#fig_9">10</ref> the various PDF luminosities between the original and the compressed set at the LHC with center-of-mass energy of √ s = 13 TeV. We show the gluon-gluon, quark-antiquark, quark-gluon, and quarkquark luminosities. As in the case of the individual PDF flavors, good agreement is found in all the range of possible final state invariant masses M X . Note that the agreement is also good in regions, like small M X and large M X , where the underlying PDF distribution is known to be non-Gaussian.</p><p xml:id="_Asgc25e">It is also important to verify that not only central values and variances are reproduced, but also that higher moments and correlations are well reproduced by the compression. Indeed, one of the main advantages of the N rep = 1000 replica sets of NNPDF as compared to the N rep = 100 sets is that correlations should be reproduced more accurately in the former case. In Fig. <ref type="figure" coords="15,376.78,395.71,9.96,8.76" target="#fig_10">11</ref> we show the results for the correlation coefficient between different PDFs, as a function of Bjorkenx, for Q = 1 GeV. We compare the results of the original N rep = 1000 replica set, together with the results of the compressed sets for a number of N rep values. From top to bottom and from left to right we show the correlations between up and down quarks, between up and strange antiquarks, between down quarks and down antiquarks, and between up quarks and down antiquarks. The correlations between PDF flavors have been computed using the suitable expression for Monte Carlo sets <ref type="bibr" coords="15,349.43,520.24,15.27,8.76" target="#b30">[31]</ref>. As we can see, correlations are reasonably well reproduced, already with N rep = 50 the results of the compressed set and of the prior are very close to each other.</p><p xml:id="_rGNWkd7">Another illustration of the fact that PDF correlations are maintained in the compression is provided by Fig. <ref type="figure" coords="15,505.36,570.05,8.30,8.76" target="#fig_11">12</ref>, where we show the correlation matrix of the NNPDF3.0 set at a scale of Q = 100 GeV, comparing the prior with N rep = 1000 with the compressed set with N rep = 50 replicas. The correlation matrices presented here are defined in a grid of N x = 50 points in x, logarithmic distributed between [10 −5 , 1] for each flavor <ref type="figure" coords="15,352.24,641.81,68.99,12.05">(s, ū, d, g, d, u, s</ref>). To facilitate the comparison, in the bottom plot we show the differences between the correlation coefficients in the two cases. It is clear from this comparison that the agreement of the PDF correlations reported in Fig. <ref type="figure" coords="15,334.09,694.59,9.96,8.76" target="#fig_10">11</ref> holds for the complete set of possible PDF combinations, in all the relevant range of Bjorken-x. Having validated the compression results for a native MC set, we now turn to a discussion of the results of the compression for a combined MC PDF set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2" xml:id="_PeX6jZX">Compression of the CMC-PDFs</head><p xml:id="_4DHwfmX">Now we turn to a similar validation study but this time for the CMC-PDFs. As we have discussed in Sect. 2, the combined MC set has been constructed by adding together N rep = 300 replicas of NNPDF3.0, MMHT14, and CT14 each, for a total of N rep = 900 replicas. Starting from this prior set, the compression algorithm has been applied as discussed in Sect. 3, and we have produced CMC-PDF sets for a number of values of N rep from 5 to 250 replicas, using the settings from Sect. 3.2.5.</p><p xml:id="_PfJAh8A">We have verified that the performance of the compression algorithm is similar regardless of the prior. To illustrate this point, in Fig. <ref type="figure" coords="16,357.94,618.85,9.96,8.76" target="#fig_5">13</ref> we show the corresponding version of Fig. <ref type="figure" coords="16,536.79,618.85,3.73,8.76">7</ref>, namely the various contributions to the error function, for the case of compression of the CMC-PDF sets. We see that also in the case of the CMC-PDF sets the compression improves the ERF as compared to random selections by an order of magnitude or even more.</p><p xml:id="_nMJUT3q">It is interesting to determine, for a given compression, how many replicas are selected from each of the three PDF sets that enter the combination. Given that originally we assign equal weight to the three sets, that is, the same number of replicas, we expect that if the compression algorithm is unbiased the number of replicas from each set after the compression should also be approximately the same. We have verified that this is indeed the case, for instance, in Fig. <ref type="figure" coords="17,240.06,520.32,9.96,8.76" target="#fig_5">14</ref> we show, for a compression with N rep = 100 replicas, how the replicas of the original distribution are selected: we see that a similar number has been selected from NNPDF3.0, CT14, and MMHT14: 32, 36, and 32 replicas, respectively, in agreement with our expectations.</p><p xml:id="_2CcCTXV">We now address the comparison between the MC900 prior and the new CMC-PDFs. For illustration, we will show results for N rep = 100, with the understanding that using a larger number of replicas would improve even further the agreement with the prior. In Fig. <ref type="figure" coords="17,180.00,644.85,9.96,8.76" target="#fig_5">15</ref> we show the comparison of the PDFs between the original Monte Carlo combination of NNPDF3.0, CT14 and MMHT14, with N rep = 900 replicas, with the corresponding compressed set with N rep = 100 replicas. We show the gluon, up quark, down antiquark, and strange quark, as ratios to the prior set at a typical LHC scale of Q = 100 GeV. We see that in all cases the agreement is sufficiently good.</p><p xml:id="_6zcWRHw">In Fig. <ref type="figure" coords="17,349.39,482.96,9.96,8.76" target="#fig_5">16</ref> we show the same as in Fig. <ref type="figure" coords="17,487.48,482.96,3.73,8.76" target="#fig_1">2</ref>, namely the histograms representing the distribution of the values of the PDFs over the Monte Carlo replicas for different flavors and values of (x, Q), now comparing the original and compressed CMC-PDFs with N rep = 900 and N rep = 100, respectively. As was done in Figs. <ref type="figure" coords="17,390.33,545.22,33.70,8.76" target="#fig_5">2 and 16</ref> we also show a Gaussian with mean and variance determined from the prior N rep = 900 CMC-PDF.</p><p xml:id="_aVb5WMJ">To gauge the dependence of the agreement between the prior and the compressed Monte Carlo sets, it is illustrative to compare central values and variances for the different values of N rep in the compression. This comparison is shown for the gluon and the down antiquark in Fig. <ref type="figure" coords="17,489.11,632.40,8.30,8.76" target="#fig_15">17</ref>. In the left plots, we compare the central value of the PDF for different values of N rep , normalized to the prior result. We also show the one-sigma PDF band, which is useful to compare the deviations found in the compressed set with the typical statistical fluctuations. We see that starting from N rep 25 replicas, the central values of the compressed sets fluctuate we show the correlations between up and down quarks, between up and strange antiquarks, between down quarks and down antiquarks, and between up quarks and down antiquarks much less than the size of the PDF uncertainties. In the right plot of Fig. <ref type="figure" coords="18,96.96,512.43,9.96,8.76" target="#fig_15">17</ref> we show the corresponding comparison at the level of standard deviations, again normalized to the standard deviation of the prior set. Here for reference the green band shows the variance of the variance itself, which is typically of the order of 20-30 % in a Monte Carlo PDF set <ref type="bibr" coords="18,248.63,562.24,15.27,8.76" target="#b30">[31]</ref>. Here we see that with N rep 100 replicas or more, the variance of the compressed set varies by a few percent at most, much less than the statistical fluctuations of the PDF uncertainty itself.</p><p xml:id="_3etzzPJ">As in the case of the native Monte Carlo sets, it is also useful here for the CMC-PDFs to compare the parton luminosities between the original and the compressed sets. This comparison is shown in Fig. <ref type="figure" coords="18,161.53,661.86,8.30,8.76" target="#fig_16">18</ref>, which is the analog of Fig. <ref type="figure" coords="18,279.09,661.86,9.96,8.76" target="#fig_9">10</ref> in the case of CMC-PDFs. As in the case of the native sets, we find also here good agreement at the level of PDF luminosities. As we will see in the next section, this agreement will also translate to all LHC cross sections and differential distributions that we have explored.</p><p xml:id="_mkKkpU5">Having verified in a number of ways that central values and variances of the PDFs are successfully preserved by the compression, we turn to a study of the PDF correlations. We have verified that a similar level of agreement as in the case of the native MC sets, Fig. <ref type="figure" coords="18,399.33,574.69,8.30,8.76" target="#fig_10">11</ref>, is achieved also here. To illustrate this point, in Fig. <ref type="figure" coords="18,374.44,587.15,9.96,8.76" target="#fig_17">19</ref> we show a comparison of the correlation coefficients as a function of x, for Q = 100 GeV, for different PDF combinations, between the original CMC-PDF set with N rep = 900 replicas and the compressed sets for different values of N rep . From left to right and from top to bottom we show the correlation between gluon and up quark, between up and strange quarks, between gluon and charm quark, and between the down and up quarks. We see that already with N rep = 100 replicas the result for the correlation is close enough to the prior with N rep = 900 replicas. The analogous version of Fig. <ref type="figure" coords="19,179.62,506.73,9.96,8.76" target="#fig_11">12</ref> for the correlation matrix of the CMC-PDFs is shown in Fig. <ref type="figure" coords="19,192.84,519.18,8.30,8.76" target="#fig_1">20</ref>. As in the case of the native MC sets, also for the CMC-PDFs the broad pattern of the correlation matrix of the original combination with N rep = 900 replicas is maintained by the compression to N rep = 100 replicas, as is quantified by the bottom plot, representing the differences between the correlation coefficients in the two cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5" xml:id="_tmdrjRv">CMC-PDFs and LHC phenomenology</head><p xml:id="_trNWncG">Now we present the validation of the compression algorithm applied to the combination of Monte Carlo PDF sets for a variety of LHC cross sections. We will compare the results of the original combined Monte Carlo set MC900 with those of the CMC-PDFs with N rep = 100 replicas (CMC-PDF100). This validation has been performed both at the level of inclusive cross sections and of differential distributions with realistic kinematical cuts. All cross sections will be computed with the NNLO sets, even when the hard cross sections are computed at NLO, which is suitable for the present illustration purposes.</p><p xml:id="_gvxvC9x">First of all, we compare the MC900 prior and the CMC-PDFs for benchmark inclusive LHC cross sections, and then we perform the validation for LHC differential distributions including realistic kinematical cuts. In the latter case we use fast NLO interfaces for the calculation of these LHC observables: this allows us to straightforwardly repeat the validation when different PDF sets are used for the compression without the need to repeat any calculation. Finally, we verify that the correlations between physical observables are also maintained by the compression algorithm, both for inclusive cross sections and for differential distributions.  We begin with the validation of the CMC-PDF predictions at the level of inclusive cross sections. The following results have been computed for the LHC at a centre-of-mass energy of 13 TeV. In Fig. <ref type="figure" coords="21,381.01,121.74,9.96,8.76" target="#fig_5">21</ref> we compare the results obtained with the prior Monte Carlo combined set and with the CMC-PDFs with N rep = 100 replicas, everything normalized to the central value of the prior set. The processes that have been included in Fig. <ref type="figure" coords="21,396.48,171.55,9.96,8.76" target="#fig_5">21</ref> are the same as those considered in the benchmark comparisons of Sect. 2.2. As we can see from Fig. <ref type="figure" coords="21,346.70,196.45,8.30,8.76" target="#fig_5">21</ref>, in all cases the agreement at the central-value level is always at the permille level, and also the size of the PDF uncertainties is very similar between the original and compressed set. Taking into account the fluctuations of the PDF uncertainty itself, shown in Fig. <ref type="figure" coords="21,458.52,246.27,8.30,8.76" target="#fig_15">17</ref>, it is clear that the predictions from the original and the compressed sets are statistically equivalent. Having established that the compression works for total cross sections, one might question if perhaps the accuracy degrades when we move to differential distributions, especially if one considers extreme regions of the phase space and the effects of realistic final state kinematical cuts. To verify that this is not the case, now we consider a number of differential processes computed using MCFM <ref type="bibr" coords="22,226.68,540.65,16.59,8.76" target="#b58">[60]</ref> and NLO-jet++ <ref type="bibr" coords="22,78.42,553.10,16.60,8.76" target="#b59">[61]</ref> interfaced to APPLgrid <ref type="bibr" coords="22,199.58,553.10,16.59,8.76" target="#b60">[62]</ref> as well as Mad-Graph5_aMC@NLO <ref type="bibr" coords="22,142.53,565.55,16.60,8.76" target="#b35">[37]</ref> interfaced to aMCfast <ref type="bibr" coords="22,256.00,565.55,16.60,8.76" target="#b61">[63]</ref> and APPLgrid. All processes are computed for √ s = 7 TeV, and the matrix-element calculations have been performed at fixed NLO perturbative order. The advantage of using fast NLO grids is that it is straightforward to repeat the validation without having to redo the full NLO computation when a different set of input PDFs is used for the combination. Note that while for simplicity we only show the results for selected bins, we have verified that the agreement also holds for the complete differential distribution.</p><p xml:id="_YgcZWxH">The corresponding version of Fig. <ref type="figure" coords="22,466.47,465.93,9.96,8.76" target="#fig_5">21</ref> for the case of LHC 7 TeV differential distributions is shown in Fig. <ref type="figure" coords="22,531.81,478.38,8.30,8.76" target="#fig_18">22</ref>. The theoretical calculations are provided for the following processes:</p><p xml:id="_8WxPp6t">• The ATLAS high-mass Drell-Yan measurement <ref type="bibr" coords="22,525.20,528.20,15.25,8.76" target="#b62">[64]</ref>, integrated over rapidity |y ll | ≤ 2.1, and binned as a function of the di-lepton invariant mass pair M ll . Here we show the prediction for the highest mass bin, M ll ∈ [1.0, 1.5] TeV. • The CMS double differential Drell-Yan measurement <ref type="bibr" coords="22,321.10,602.91,16.60,8.76" target="#b64">[65]</ref> in the low-mass region, 20 GeV ≤ M ll ≤ 30 GeV, as a function of the di-lepton rapidity y ll . The prediction is shown for the lowest rapidity bin, y ll ∈ [0.0, 0.1]. • The CMS W + lepton rapidity distribution <ref type="bibr" coords="22,504.81,640.27,15.27,8.76" target="#b65">[66]</ref>. The prediction is shown for the lowest rapidity bin, y l ∈ [0.0, 0.1]. • The CMS measurement of W + production in association with charm quarks <ref type="bibr" coords="22,396.21,690.09,15.27,8.76" target="#b66">[67]</ref>, as a function of the lepton rapid- More details as regards the selection cuts applied to these processes can be found in the original references and in the NNPDF3.0 paper <ref type="bibr" coords="23,122.88,657.43,15.26,8.76" target="#b15">[16]</ref>, though note that here no comparison with experimental data is attempted. The various observables of Fig. <ref type="figure" coords="23,81.79,682.33,9.96,8.76" target="#fig_18">22</ref> probe a wide range of PDF combinations, from light quarks and antiquarks (low-and high-mass Drell-Yan) and strangeness (W +charm) to the gluon (central and forward jets) in a wide range of Bjorken-x and momentum transfers Q 2 .</p><p xml:id="_5DNMetB">As we can see from Fig. <ref type="figure" coords="23,421.96,517.88,8.30,8.76" target="#fig_18">22</ref>, the level of the agreement between the MC900 prior and the CMC-PDFs with N rep = 100 is similar to that of the inclusive cross sections. This is also true for other related processes that we have also studied, but that are not shown explicitly here. This agreement is of course understood from the fact that the compression is performed at the level of parton distributions, as shown in Sect. 4. Note also that the agreement found for the processes in Fig. <ref type="figure" coords="23,438.43,617.50,9.96,8.76" target="#fig_18">22</ref> is particularly remarkable since in some cases, like forward Drell-Yan or forward jet production, the underlying PDFs are probed at large-x, where deviations from the Gaussian behavior are sizable: even in this case, the compression algorithm is successful in reproducing the mean and variance of the prior probability distribution. Another illustrative way of checking that the compression algorithm really preserves the non-Gaussian features of the prior is provided by the probability distribution of specific LHC cross sections in which such features are clearly observed. To better visualize the probability density P(σ ) estimated from the Monte Carlo sample we use the Kernel Density Estimation (KDE) method. In this technique, the probability distribution is obtained by averaging a kernel function K centered at the predictions {σ i } obtained for each individual PDF replica:</p><formula xml:id="formula_44" coords="24,51.91,610.55,233.09,32.88">P(σ ) = 1 N rep N rep i=1 K (σ − σ i ). (<label>22</label></formula><formula xml:id="formula_45" coords="24,285.00,622.95,4.17,8.76">)</formula><p xml:id="_PNuvh7N">Here we choose the function K to be a normal distribution, that is,</p><formula xml:id="formula_46" coords="24,51.65,694.72,233.35,25.02">K (σ − σ i ) = 1 h √ 2π e −(σ −σ i ) 2 h , (<label>23</label></formula><formula xml:id="formula_47" coords="24,285.00,702.68,4.15,8.76">)</formula><p xml:id="_KmjEDPT">where we set the parameter h, known as bandwidth, so that it is the optimal choice if the underlying data was Gaussian. This choice is known as the Silverman rule. 2  In Fig. <ref type="figure" coords="24,352.66,510.28,9.96,8.76" target="#fig_2">23</ref> we compare the probability distributions, obtained using the KDE method, for two LHC cross sections: the CMS W +charm production in the most forward bin (left plot) and the LHCb Z → e + e − rapidity distribution for η Z = 4 (right plot). We compare the original prior MC900 with the CMC-PDF100 and MCH100 reduced sets. In the case of the W +charm cross section, which is directly sensitive to the poorly known strange PDF, the prior shows a double-hump structure, which is reasonably well reproduced by the CMC-PDF100 set, but that disappears if a Gaussian 2 It can be shown that this choice amounts to using a bandwidth of</p><formula xml:id="formula_48" coords="24,306.20,667.69,233.91,26.97">h = 4s 5 3N rep 1 5 , (<label>24</label></formula><formula xml:id="formula_49" coords="24,540.11,679.38,4.15,8.76">)</formula><p xml:id="_dBtHefz">where s is the standard deviation of the sample. result. From left to right and from top to bottom we show the correlation between gluon and up quark, between up and strange quarks, between gluon and charm quark, and between the down and up quarks reduction, in this case MCH100, is used. For the LHCb forward Z production, both the prior and CMC-PDF100 are significantly skewed, a feature which is lost in the Gaussian reduction of MCH100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2" xml:id="_5M7tCb5">Correlations between LHC cross sections</head><p xml:id="_UnY5Hj4">Any reasonable algorithm for the combination of PDF sets should reproduce not only the central values and the variances of the prior distribution, but also the correlations between physical observables. This is relevant for phenomenological applications at the LHC, where PDF-induced correlations are used for instance to determine the degree of correlation of the systematic uncertainties between different processes. Using the PDF4LHC recommendations, the PDF-induced correlations between different Higgs production channels were estimated in Ref. <ref type="bibr" coords="25,108.62,694.79,15.27,8.76" target="#b53">[55]</ref>, and this information is now extensively used in the Higgs analyses of ATLAS and CMS.</p><p xml:id="_8psQSqP">To validate that the compression algorithm presented here also maintains the correlations of the original set, we have computed the correlations between all processes used in the previous section, both for the MC900 prior and for the CMC-PDF100 set. The results are shown in Fig. <ref type="figure" coords="25,478.91,532.82,8.30,8.76" target="#fig_3">24</ref>, for the NLO and NNLO inclusive cross sections shown in Figs. <ref type="figure" coords="25,516.54,545.28,27.72,8.76;25,306.16,557.73,8.30,8.76" target="#fig_5">21 and  25</ref>, for the case of differential distributions shown in Fig. <ref type="figure" coords="25,531.81,557.73,8.30,8.76" target="#fig_18">22</ref>. We have also verified that from N rep 50 replicas onwards the correlations are very well reproduced by the compressed set.</p><p xml:id="_W6vuCpD">To gauge the effectiveness of the compression algorithm, in Figs. <ref type="figure" coords="25,342.84,619.99,43.58,8.76" target="#fig_4">24 and 25</ref> we also show the 68 % confidencelevel interval for the correlation coefficients computed from N rand = 1000 random partitions of rep = 100 replicas: we see the compression in general outperforms the results from a random of N rep = 100 replica set. The agreement of the correlations at the level of LHC observables is a direct consequence of course that correlations are maintained by the compression at the PDF level, as discussed in detail in Fig. <ref type="figure" coords="26,68.27,457.11,8.47,7.46" target="#fig_1">20</ref> Same as Fig. <ref type="figure" coords="26,128.69,457.23,8.46,7.44" target="#fig_11">12</ref> for the correlation matrix of the CMC-PDFs at Q = 100 GeV, comparing the prior combination MC900 (left plot) and the CMC-PDF100 set (right plot). In the bottom plot we show the difference between the correlation coefficients in the two cases Sect. 4.2. Only for very few cases the correlation coefficient of the CMC-PDF set is outside the 68 % confidence-level range of the random selections, and this happens only when correlations are very small to begin with, so this fact is not relevant for phenomenology.</p><p xml:id="_C8UtCjc">To summarize, the results of this section show that at the level of LHC phenomenology, CMC-PDFs with N rep = 100 replicas can be reliably used instead of the original Monte Carlo combination of PDF sets, thereby allowing a substantial reduction of the CPU-time burden associated with the calculation of the theory predictions for the original N rep = 900 replicas by almost a full order of magnitude.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6" xml:id="_8chpnna">Summary and delivery</head><p xml:id="_Gg5qjFX">In this work we have presented a novel strategy for the combination of individual PDF sets, based on the Monte Carlo method followed by a compression algorithm. The resulting Compressed Monte Carlo PDFs, or CMC-PDFs for short, are suitable to be used to estimate PDF uncertainties in theoretical predictions of generic LHC processes. As compared to the original PDF4LHC recommendation, the new approach we advocate here is both more straightforward to use, based on a single combined PDF set, and less computationally expensive: N rep 100 replicas are enough to preserve the statistical features of the prior combination with sufficient accuracy for most relevant applications. Using as an illustration the combination of the recent NNPDF3.0, CT14, and MMHT14 NNLO sets, we have verified that the compression algorithm successfully reproduces the predictions of the prior combined MC set for a wide variety of LHC processes and their correlations.</p><p xml:id="_bf5eHnX">The compressed PDF sets at NLO and NNLO, with N rep = 100 replicas each, and α s (M Z ) = 0.118, will be made available in LHAPDF6 <ref type="bibr" coords="26,431.73,706.55,16.59,8.76" target="#b47">[49]</ref> as part of the upcom-  ing PDF4LHC 2015 recommendations. Additional members to estimate the combined PDF+α s uncertainty will also be included in the same grid files, and new functions will be provided in LHAPDF 6.1.6 to facilitate the computation of this combined PDF+α s uncertainty. In addition, we have also made publicly available the compression algorithm used in this work: https://github.com/scarrazza/compressor This compressor code <ref type="bibr" coords="27,418.27,59.47,16.64,8.76" target="#b48">[50]</ref> includes a script to combine Monte Carlo sets from different groups into a single MC set, the compression algorithm and the validation suite. A concise user manual for this code can be found in the appendix: the code produces CMC-PDF sets directly in the LHAPDF6 format ready to be used for phenomenological applications.</p><p xml:id="_KhY8PWx">We would like to emphasize that it is beyond the scope of this paper to determine which specific PDF sets should be used in the present or future PDF4LHC combination: this is an issue in which only the PDF4LHC Steering Committee has the mandate to decide. We have used the most updated NNLO sets from NNPDF, CT, and MMHT for consistency with the current prescription, but using the publicly available code it is possible to construct CMC-PDFs from any other choice of sets. We note, however, that for the combination of PDF sets that are based on very different input datasets or theory assumptions as compared to the three global sets, the determination of the number of replicas from each set that should be included in the combination is a complex problem which is still to be understood.</p><p xml:id="_eMbD9zW">Examples of applications where combined PDF sets, as implemented by the CMC-PDFs, should be used include the computation of PDF uncertainties for acceptances and efficiencies, due to extrapolations or interpolations, to estimate the PDF uncertainties in the extraction of Higgs couplings or other fundamental SM parameters such as M W from LHC data, and to obtain limits in searches for BSM physics. Even in these cases, whenever possible, providing results obtained using individual PDF sets should be encouraged, since such comparisons shed light on the origin of the total PDF uncertainties for each particular application, and provide guidance about how they might reduce this PDF uncertainty. Needless to say, in all PDF-sensitive Standard Model comparisons between experimental data and theory models, only the individual PDF sets should be used, rather than only a combined PDF set. The latter might be suitable only if PDF uncertainties are much smaller than all other theoretical and experimental uncertainties.</p><p xml:id="_zRg2hjY">It is also important to emphasize that the CMC-PDFs, as well as any other method for the combination of PDF sets, do not replace the individual PDF sets: CMC-PDFs are simply a user-convenient method to easily obtain the results of the combination of the individual PDF sets. For this reason, it should be clear that whenever the CMC-PDF sets are used, not only the present publication should be cited, but also the original publications corresponding to the individual PDF sets used as input to the combination.</p><p xml:id="_vGt8zHt">Let us conclude by stating the obvious fact that the availability of a method for the combination of different sets does not reduce, but if anything strengthens, the need to keep working in reducing the PDF uncertainties in the individual sets, both in terms of improved theory, more constraining data and refined methodology, as well as to continue the benchmark- ing exercises between groups that have been performed in the past <ref type="bibr" coords="29,70.03,431.41,12.69,8.76" target="#b3">[4,</ref><ref type="bibr" coords="29,82.72,431.41,12.69,8.76" target="#b68">69,</ref><ref type="bibr" coords="29,95.41,431.41,12.69,8.76" target="#b69">70]</ref> and that are instrumental to understand (and eventually reduce) the differences between different groups. between the CMC-PDF and the Meta-PDF approaches. We also are grateful to all the members of the NNPDF Collaboration for fruitful discussions during the development of this project. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_NEzeDJR">A: The compression code</head><p xml:id="_6vCjePM">The numerical implementation of the compression algorithm used in this work is available in the compressor v1.0.0 package. Here we provide instructions about how to download, install, and run the code. The code was designed for Unix systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_mV7eVPz">Download</head><p xml:id="_WXRP4gh">Open a terminal and download the latest release available from https://github.com/scarrazza/compressor/releases or clone the master development branch from the GitHub repository:</p><p xml:id="_t7SuR4m">$ git clone https://github.com/scarrazza/compressor.git</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_54NDdce">Installation</head><p xml:id="_vkH2EUf">Compressor requires three external public libraries in order to work properly: LHAPDF6<ref type="foot" coords="29,424.89,643.05,3.79,6.66" target="#foot_1">3</ref>  <ref type="bibr" coords="29,433.27,645.08,15.27,8.76" target="#b47">[49]</ref>, ROOT<ref type="foot" coords="29,480.34,643.05,3.79,6.66" target="#foot_2">4</ref> and GSL. <ref type="foot" coords="29,527.60,643.05,3.79,6.66" target="#foot_3">5</ref> In</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,51.04,458.11,493.18,7.56;5,51.04,467.44,487.35,8.47"><head>Fig. 1</head><label>1</label><figDesc xml:id="_jKRjhKf">Fig. 1 Comparison of the individual NNPDF3.0, CT14 and MMHT14 NNLO sets with the corresponding Monte Carlo combination MC900. The comparison is performed at a typical LHC scale of Q = 100 GeV, and the PDFs are normalized to the central value of the combined set MC900</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,51.04,433.11,238.11,7.56;6,51.04,443.19,238.09,7.44;6,51.04,452.41,238.10,8.47;6,51.04,460.82,238.12,10.01"><head>Fig. 2</head><label>2</label><figDesc xml:id="_C9xmkYA">Fig. 2 Histograms representing the probability distribution of Monte Carlo replicas for both the individual PDF sets and for the combined set, for different flavors and values of (x, Q). From top to bottom and from left to right we show the gluon at x = 0.01, the up quark at x = 5•10 −5 ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,51.04,574.11,238.10,7.56;7,51.04,584.19,238.11,7.44;7,51.04,594.15,238.09,7.44;7,51.04,604.12,238.07,7.44;7,51.04,614.08,238.11,7.44"><head>αFig. 3</head><label>3</label><figDesc xml:id="_UUYRt9V">Fig.<ref type="bibr" coords="7,68.28,574.11,4.23,7.46" target="#b2">3</ref> Comparison of the predictions from the NNPDF3.0, MMHT14 and CT14 NNLO sets, with those of their Monte Carlo combination MC900, for a number of inclusive benchmark LHC cross sections. For illustration, we also indicate the envelope of the predictions of the three different PDF sets, which would determine the total PDF uncertainty in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="8,51.04,565.11,238.07,7.56;8,51.04,575.19,238.09,7.44;8,51.04,585.15,238.09,7.44"><head>Fig. 4</head><label>4</label><figDesc xml:id="_fBp8cGj">Fig.<ref type="bibr" coords="8,68.28,565.11,4.23,7.46" target="#b3">4</ref> Comparison of the correlation coefficients between a number of representative NLO and NNLO LHC inclusive cross sections computed from the three individual sets, NNPDF3.0, CT14, and MMHT14</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="10,306.16,224.91,238.10,7.56;10,306.16,234.99,238.10,7.44;10,306.16,244.95,238.08,7.44;10,306.16,254.92,207.21,7.44"><head>Fig. 5</head><label>5</label><figDesc xml:id="_xKhaSp4">Fig.<ref type="bibr" coords="10,323.39,224.91,4.23,7.46" target="#b4">5</ref> Schematic representation of the compression strategy used in this work: a prior PDF set and the number of compressed replicas is the input of a GA algorithm which selects the best subset of replicas which minimizes the ERF between the prior and the compressed set</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="13,51.04,60.34,238.10,7.56;13,51.04,70.42,196.90,7.44;13,51.04,87.42,86.40,6.09;13,51.04,105.50,63.37,7.44;13,58.21,116.72,17.71,9.07;13,64.00,122.07,9.29,5.66;13,228.21,118.45,23.27,7.44;13,58.21,132.16,15.80,8.20;13,228.21,132.09,4.23,7.44;13,58.21,145.11,8.81,8.12;13,228.21,145.04,8.46,7.44;13,57.86,158.56,14.02,8.20;13,228.21,156.19,16.75,9.73"><head>Table 1 (</head><label>1</label><figDesc xml:id="_u4NY4RT">(a) Setting of the compression algorithm used in this work. (b) Mutation rates used in the genetic algorithm minimization compressor v1.0.0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="14,51.04,655.11,238.11,7.56;14,51.04,664.45,238.11,9.02;14,51.04,675.15,238.09,8.27;14,51.04,685.12,238.10,7.44;14,51.04,695.08,238.11,7.44"><head></head><label></label><figDesc xml:id="_B8EYKMK">Fig.7  The various contributions to the ERF, Eq. (5), for the compression of the NNPDF3.0 NLO set with N rep = 1000 replicas. For each value of N rep , we show the value of each contribution to the ERF for the best-fit result of the compression algorithm (red points). We compare the results of the compression with the values of the ERF averaged over</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="16,51.04,402.11,238.11,7.56;16,51.61,411.45,237.53,9.02;16,51.04,421.46,238.11,9.46"><head>Fig. 8 Fig. 9</head><label>89</label><figDesc xml:id="_s9dD5gX">Fig. 8 Upper plots comparison of the prior NNPDF3.0 NLO set with N rep = 1000 and the compressed set with N rep = 50 replicas, for the gluon and the down quark at the scale Q 2 = 2 GeV 2 . Lower plots the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9" coords="17,51.04,409.11,238.08,7.56;17,51.04,419.19,238.09,7.44;17,51.04,429.16,238.11,8.19"><head>Fig. 10</head><label>10</label><figDesc xml:id="_ZQcc7NE">Fig. 10 Comparison of PDF luminosities between the original and compressed NNPDF3.0 set, for the LHC 13 TeV as a function of the invariant mass of the final state M X . From top to bottom and left to</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10" coords="18,51.04,429.11,238.08,7.56;18,51.04,438.45,238.11,8.47;18,51.04,448.41,238.11,9.02;18,51.04,459.12,238.11,8.27"><head>Fig. 11</head><label>11</label><figDesc xml:id="_6d3qcKM">Fig. 11 Comparison between the PDF correlations among different PDF flavors, as a function of Bjorken-x, for Q = 1 GeV, for the original NNPDF3.0 set with N rep = 1000 replicas and the compressed sets for various values of N rep . From top to bottom and from left to right,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11" coords="19,51.04,456.48,493.20,9.02;19,51.04,466.45,452.90,9.02;19,202.33,277.91,177.88,158.68"><head>Fig. 12</head><label>12</label><figDesc xml:id="_uNruJqM">Fig. 12 The correlation matrix of the NNPDF3.0 set with N rep = 1000 at Q = 100 GeV. On the right, the same matrix for the NNPDF3.0 compressed set with N rep = 50 replicas. The bottom plot represents the difference between the two matrices. See text for more details</figDesc><graphic coords="19,202.33,277.91,177.88,158.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12" coords="20,165.21,253.64,30.99,7.48"><head>Replicas</head><label></label><figDesc xml:id="_xqGqW6E"></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13" coords="20,51.04,705.49,314.43,9.02"><head>10 ERFFig. 13 Fig. 14</head><label>101314</label><figDesc xml:id="_6cEYKCr">Fig.<ref type="bibr" coords="20,68.27,706.11,8.47,7.46" target="#b12">13</ref> Same as Fig.7for the CMC-PDFs, starting from the prior with N rep = 900 replicas</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14" coords="21,51.04,696.31,493.15,7.56;21,51.04,706.39,31.52,7.44;21,107.74,704.66,377.40,9.46"><head>Fig. 15 xFig. 16</head><label>1516</label><figDesc xml:id="_meB4sPy">Fig.<ref type="bibr" coords="21,68.27,696.31,8.47,7.46" target="#b14">15</ref> Comparison of the PDFs between the original Monte Carlo combination of NNPDF3.0, CT14, and MMHT14, MC900, with the compressed CMC100 We show the gluon, up quark, down antiquark, and total quark singlet, as ratios to the prior for Q 2 = 10 4 GeV 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15" coords="23,51.04,422.11,238.10,7.56;23,51.04,432.19,237.61,8.27;23,51.04,442.15,238.10,7.44;23,51.04,452.12,238.11,7.44"><head>Fig. 17</head><label>17</label><figDesc xml:id="_yRE9Uu4">Fig. 17 Comparison of the central values (left plots) and one-sigma intervals (right plots) for the CMC-PDFs with different values of N rep (5, 25, 50, 100, and 250, respectively), for the gluon (upper plots) and the down antiquark (lower plots). Results are shown normalized to the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16" coords="24,51.04,432.11,366.51,7.56"><head>Fig. 18</head><label>18</label><figDesc xml:id="_jrXRcVB">Fig.<ref type="bibr" coords="24,68.27,432.11,8.47,7.46" target="#b17">18</ref> Same as Fig.10for the comparison between the prior set MC900 and the compressed set CMC100</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17" coords="25,51.04,422.11,238.09,7.56;25,51.04,431.44,238.11,9.02;25,51.04,442.15,238.09,7.44"><head>Fig. 19</head><label>19</label><figDesc xml:id="_ePEqTuD">Fig.<ref type="bibr" coords="25,68.27,422.11,8.47,7.46" target="#b18">19</ref> Same as Fig.11for correlation coefficients of the CMC-PDFs, evaluated at Q = 100 GeV, for a range of values of N rep in the compressed set, from 5 to 100 replicas, compared with the prior MC900</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18" coords="27,51.04,535.28,238.09,7.56;27,51.04,545.36,238.10,7.44;27,51.04,555.33,33.89,7.44;27,86.81,548.44,7.16,8.47;27,93.98,554.58,195.16,8.47;27,51.04,565.29,51.74,7.44"><head>Fig. 22</head><label>22</label><figDesc xml:id="_JakqwYM">Fig. 22 Same as Fig. 21, for a variety of NLO differential distributions computed with MCFM and NLOjet++ interfaced to APPLgrid for the LHC with √ s = 7 TeV. See text for the details of the choice of binning in each process</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19" coords="28,51.04,220.11,238.11,7.56;28,51.04,230.19,238.11,7.44;28,51.04,237.86,238.10,10.49;28,53.65,56.75,487.69,151.36"><head>Fig. 23 Fig. 24 Fig. 25</head><label>232425</label><figDesc xml:id="_cBqnj3W">Fig.<ref type="bibr" coords="28,68.27,220.11,8.47,7.46" target="#b22">23</ref> The probability distribution for two LHC cross sections: the CMS W +charm production in the most forward bin (left plot) and the LHCb Z → e + e − rapidity distribution for η Z = 4 (right plot). We com-</figDesc><graphic coords="28,53.65,56.75,487.69,151.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="27,51.04,57.83,238.12,464.73"><head></head><label></label><figDesc xml:id="_m7PSedF">Comparison of the predictions of the Monte Carlo combined prior MC900 with those of the CMC-PDFs with N rep = 100 replicas, normalized to the central value of the former, for a number of benchmark inclusive NNLO cross sections at the LHC with √ s = 13 TeV. The error bands correspond to the PDF uncertainty bands for each of the sets. See text for more details</figDesc><table coords="27,51.04,57.83,235.19,464.73"><row><cell></cell><cell></cell><cell cols="4">LHC 13 TeV, NNLO,</cell><cell>α</cell><cell>s</cell><cell cols="2">=0.118</cell></row><row><cell></cell><cell></cell><cell>rep N</cell><cell>= 100</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>gg-&gt;h</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>W</cell><cell>+</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>W</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Z</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>tT</cell></row><row><cell>0.96</cell><cell>0.97</cell><cell>0.98</cell><cell>0.99</cell><cell>1</cell><cell>1.01</cell><cell></cell><cell cols="2">1.02</cell><cell>1.03</cell><cell>1.04</cell><cell>1.05</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="6">Ratio to MC900</cell><cell></cell></row><row><cell cols="11">0.8 Fig. 21 Ratio to original Monte Carlo combined PDFs 0.85 0.9 0.95 1 1.05 1.1 1.15 Low-Mass DY High-Mass DY Forw DY W+charm Cent Jets Forw Jets = 100 rep N =0.118, NLO s α LHC 7 TeV,</cell><cell>1.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="29,51.04,506.92,238.13,136.71"><head></head><label></label><figDesc xml:id="_7tEMZfh">This work of S. C. is partially supported by an Italian PRIN2010 grant and by a European Investment Bank EIBURS grant. The work of J. I. L. is funded by a FIS2010-16185 grant from the Spanish MINNECO. The work of J. R. is supported by an STFC Rutherford Fellowship ST/K005227/1 and by the European Research Council Starting Grant "PDF4BSM". Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecomm ons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. Funded by SCOAP 3 .</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">Note that Eq. (6.5) of Ref.<ref type="bibr" coords="4,148.44,678.34,14.10,7.44" target="#b33">[35]</ref> and the current LHAPDF 6.1.5 code contain a mistake which has been corrected in the Mercurial repository and the correction will be included in the upcoming LHAPDF 6.1.6 release; see Eq. (22) of Ref.<ref type="bibr" coords="4,166.50,708.23,12.98,7.44" target="#b47">[49]</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1">http://lhapdf.hepforge.org/.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2">http://root.cern.ch/.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3">http://www.gnu.org/software/gsl/.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_Y66VxUb">Acknowledgments</head><p xml:id="_9nHCgkw">We are grateful to Joey Huston, Jun Gao and Pavel Nadolsky for many illuminating discussions of the comparison</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_54SX6js"><p xml:id="_K6SGb3r">order to install the package compile with the configure script:</p><p xml:id="_CZE7DA4">$ cd compressor $ ./configure --prefix=/path/to/install/location $ make &amp;&amp; make install This operation will copy the bin/compressor binary to /usr/local/bin (or the location given by -prefix).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_UHzF9eT">Running the code</head><p xml:id="_ETd37Aq">After installing this package, the compressor program is available for the user.</p><p xml:id="_rx4Sd9t">The first two arguments are required:</p><p xml:id="_pYh2Hkt">• REP: the number of required compressed replicas • PDF prior name: the name of the prior LHAPDF6 grid • energy Q: the input energy scale used by the compression algorithm (default = 1 GeV) • seed: the random number seed (default = 0) • compress: switches on/off the minimization step (default = true).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_DVy38BZ">Output</head><p xml:id="_fXGQcGw">After running compressor a folder with the prior set name is created. Finally, in order to generate the ERF plots place the /bin/compressor_validate.C script in the output folder and run: $ root -l compressor_validate.C</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="30,313.44,82.87,230.82,7.44;30,321.60,92.72,168.88,7.56" xml:id="b0">
	<analytic>
		<title level="a" type="main" xml:id="_H5vksd6">Parton distributions at the dawn of the LHC</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Forte</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1011.5247</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_3NhSfE2">Acta Phys. Polon. B</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="2859" to="2920" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,313.44,102.80,230.81,7.44;30,321.60,112.64,222.63,7.56;30,321.60,122.72,84.18,7.44" xml:id="b1">
	<analytic>
		<title level="a" type="main" xml:id="_YV6X9F2">Progress in the determination of the partonic structure of the proton</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Forte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Watt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.6754</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_2AFh7sN">Ann. Rev. Nucl. Part. Sci</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="291" to="328" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,313.44,132.69,230.78,7.44;30,321.60,142.53,183.18,7.56" xml:id="b2">
	<analytic>
		<title level="a" type="main" xml:id="_XyrgJwm">The quark and gluon structure of the proton</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Rizvi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1208.1178</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_WWBddD2">Rep. Prog. Phys</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page">46201</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,313.44,152.61,230.82,7.44;30,321.60,162.46,222.60,7.56;30,321.60,172.54,57.38,7.44" xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_43E8fyP">Parton distribution benchmarking with LHC data</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">D</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Carrazza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Del Debbio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Forte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1211.5142</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_x7b49vJ">JHEP</title>
		<imprint>
			<biblScope unit="volume">1304</biblScope>
			<biblScope unit="page">125</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,313.44,182.50,230.79,7.44;30,321.60,192.35,222.64,7.56;30,321.60,202.43,98.99,7.44" xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_m7dwxwm">Parton distribution function dependence of benchmark standard model total cross sections at the 7 TeV LHC</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Watt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1106.5788</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_qjjFGGj">JHEP</title>
		<imprint>
			<biblScope unit="volume">1109</biblScope>
			<biblScope unit="page">69</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,313.44,212.38,230.81,7.44;30,321.60,222.23,149.31,7.56" xml:id="b5">
	<analytic>
		<title level="a" type="main" xml:id="_xQ29QaX">Structure functions</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>De Roeck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">S</forename><surname>Thorne</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1103.0555</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_y5WuPt2">Prog. Part. Nucl. Phys</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="727" to="781" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,313.44,232.31,230.84,7.44;30,321.60,242.27,194.47,7.44" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rojo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1507.00556</idno>
		<title level="m" xml:id="_fyZ9V49">The PDF4LHC report on PDFs and LHC data: Results from Run I and preparation for Run II</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="30,313.44,252.23,230.75,7.44;30,321.60,262.20,222.62,7.44;30,321.60,272.16,222.65,7.44;30,321.60,282.12,81.36,7.44" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Heinemeyer</surname></persName>
			<affiliation>
				<orgName type="collaboration">LHC Higgs Cross Section Working Group</orgName>
			</affiliation>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Mariotti</surname></persName>
			<affiliation>
				<orgName type="collaboration">LHC Higgs Cross Section Working Group</orgName>
			</affiliation>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename></persName>
			<affiliation>
				<orgName type="collaboration">LHC Higgs Cross Section Working Group</orgName>
			</affiliation>
		</author>
		<idno type="arXiv">arXiv:1307.1347</idno>
		<title level="m" xml:id="_UKXJrxc">Handbook of LHC Higgs Cross Sections: 3. Higgs Properties</title>
				<editor>
			<persName><forename type="first">R</forename><surname>Passarino</surname></persName>
		</editor>
		<editor>
			<persName><surname>Tanaka</surname></persName>
		</editor>
		<meeting><address><addrLine>Geneva</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
		<respStmt>
			<orgName>CERN</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="30,313.44,292.08,230.82,7.44;30,321.60,302.05,222.66,7.44;30,321.60,311.89,222.65,7.56;30,321.60,321.97,111.70,7.44" xml:id="b8">
	<analytic>
		<title level="a" type="main" xml:id="_hs72VAu">A Large Hadron Electron Collider at CERN: Report on the Physics and Design Concepts for Machine and Detector</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">Abelleira</forename><surname>Fernandez</surname></persName>
			<affiliation>
				<orgName type="collaboration">LHeC Study Group Collaboration</orgName>
			</affiliation>
		</author>
		<idno type="arXiv">arXiv:1206.2913</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_j9ADTXx">J. Phys. G</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page">75001</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,313.08,331.94,231.15,7.44;30,321.60,341.90,222.66,7.44;30,321.60,351.86,6.12,7.44;30,330.84,344.98,7.16,8.47;30,338.01,351.12,206.24,8.47;30,321.60,361.83,84.18,7.44" xml:id="b9">
	<analytic>
		<title level="a" type="main" xml:id="_gRm59RC">Squark and gluino production cross sections in pp collisions at √ s = 13, 14, 33 and 100 TeV</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Borschensky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Krmer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mangano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Padhi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1407.5066</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_4P6FZaa">Eur. Phys. J. C</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">3174</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,313.09,371.79,231.17,7.44;30,321.60,381.75,222.66,7.44;30,321.60,391.72,57.38,7.44" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Van Der Leeuw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mangano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Padhi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1206.2892</idno>
		<title level="m" xml:id="_sbhJvCX">Supersymmetry production cross sections in pp TeV</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="30,313.09,401.68,231.12,7.44;30,321.60,411.64,222.66,7.44;30,321.60,421.49,170.42,7.56" xml:id="b11">
	<analytic>
		<title level="a" type="main" xml:id="_dj78HXX">The impact of PDF uncertainties on the measurement of the W boson mass at the Tevatron and the LHC</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Bozzi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rojo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vicini</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1104.2056</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_FuqvKHa">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page">113008</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,313.09,431.57,231.14,7.44;30,321.60,441.53,222.66,7.44;30,321.60,451.49,214.17,7.44" xml:id="b12">
	<monogr>
		<title level="m" type="main" xml:id="_n7vrufj">Studies of theoretical uncertainties on the measurement of the mass of the W boson at the LHC</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Aad</surname></persName>
			<affiliation>
				<orgName type="collaboration">ATLAS Collaboration</orgName>
			</affiliation>
		</author>
		<idno>ATL-PHYS-PUB-2014-015</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
			<pubPlace>Geneva</pubPlace>
		</imprint>
		<respStmt>
			<orgName>CERN</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct coords="30,313.09,461.45,231.15,7.44;30,321.60,471.41,222.65,7.44;30,321.60,481.25,214.46,7.56" xml:id="b13">
	<analytic>
		<title level="a" type="main" xml:id="_pJ2knRD">PDF uncertainties on the W boson mass measurement from the lepton transverse momentum distribution</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Bozzi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Citelli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vicini</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1501.05587</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_55mQCXb">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">113005</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,313.09,491.34,231.13,7.44;30,321.60,501.30,167.22,7.44" xml:id="b14">
	<analytic>
		<title level="a" type="main" xml:id="_n5CmbvM">A. Cooper-Sarkar, PDF Fits at HERA</title>
		<idno type="arXiv">arXiv:1112.2107</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_W8hfKV6">PoS</title>
		<imprint>
			<biblScope unit="volume">2011</biblScope>
			<biblScope unit="page">320</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,313.09,511.26,231.14,7.44;30,321.60,521.11,199.35,7.56" xml:id="b15">
	<analytic>
		<title level="a" type="main" xml:id="_c8tvJyT">Parton distributions for the LHC Run II</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">D</forename><surname>Ball</surname></persName>
			<affiliation>
				<orgName type="collaboration">NNPDF Collaboration</orgName>
			</affiliation>
		</author>
		<idno type="arXiv">arXiv:1410.8849</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_8vNJu78">JHEP</title>
		<imprint>
			<biblScope unit="volume">1504</biblScope>
			<biblScope unit="page">40</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,313.09,531.19,231.17,7.44;30,321.60,541.03,222.64,7.56;30,321.60,551.11,57.38,7.44" xml:id="b16">
	<analytic>
		<title level="a" type="main" xml:id="_hD6buD2">The ABM parton distributions tuned to LHC data</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Alekhin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bluemlein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Moch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1310.3059</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_zC9rtnH">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page">54028</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,313.09,561.08,231.15,7.44;30,321.60,570.92,222.64,7.56;30,321.60,581.00,111.70,7.44" xml:id="b17">
	<analytic>
		<title level="a" type="main" xml:id="_fUxYB72">CT10 next-tonext-to-leading order global analysis of QCD</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Guzzi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Huston</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H.-L</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1302.6246</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_J9G5FzK">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">33009</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,313.09,590.96,231.19,7.44;30,321.60,600.93,222.66,7.44;30,321.60,610.77,129.34,7.56" xml:id="b18">
	<analytic>
		<title level="a" type="main" xml:id="_bGkDnBv">Parton distributions in the LHC era: MMHT 2014 PDFs</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Harland-Lang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">D</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Motylinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">S</forename><surname>Thorne</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.3989</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_T5SbfTw">Eur. Phys. J. C</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">204</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,313.09,620.85,231.16,7.44;30,321.60,630.82,222.65,7.44;30,321.60,640.66,149.76,7.56" xml:id="b19">
	<analytic>
		<title level="a" type="main" xml:id="_TCCvw9X">Uncertainties in determining parton distributions at large x</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Accardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Melnitchouk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Owens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Christy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Keppel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1102.3686</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_UMbvuxe">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page">14008</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,313.09,650.74,231.16,7.44;30,321.60,660.59,222.65,7.56;30,321.60,670.67,57.37,7.44" xml:id="b20">
	<analytic>
		<title level="a" type="main" xml:id="_bzMGHDs">Delineating parton distributions and the strong coupling</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Jimenez-Delgado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Reya</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1403.1852</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_qc4TZz7">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">74049</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,313.09,680.63,231.16,7.44;30,321.60,690.59,222.66,7.44;30,321.60,700.56,180.38,7.44" xml:id="b21">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dulat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">J</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Guzzi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Huston</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nadolsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pumplin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Stump</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">P</forename><surname>Yuan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.07443</idno>
		<title level="m" xml:id="_QwSqD48">The CT14 global analysis of quantum chromodynamics</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.97,60.45,231.17,7.44;31,66.48,70.42,222.63,7.44;31,66.48,80.26,222.64,7.56;31,66.48,90.34,57.38,7.44" xml:id="b22">
	<analytic>
		<title level="a" type="main" xml:id="_mHdQwrf">NNLO benchmarks for Gauge and Higgs boson production at TeV hadron colliders</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Alekhin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Blümlein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Jimenez-Delgado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Moch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Reya</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1011.6259</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_eY3ng58">Phys. Lett. B</title>
		<imprint>
			<biblScope unit="volume">697</biblScope>
			<biblScope unit="page" from="127" to="135" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.96,100.31,231.17,7.44;31,66.48,110.27,100.66,7.44" xml:id="b23">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Botje</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1101.0538</idno>
		<title level="m" xml:id="_6grW9ZK">The PDF4LHC Working Group Interim Recommendations</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.97,120.23,231.17,7.44;31,66.48,130.19,205.83,7.44" xml:id="b24">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Alekhin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Alioli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">D</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bertone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Blümlein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1101.0536</idno>
		<title level="m" xml:id="_9PWqyP5">The PDF4LHC Working Group Interim Report</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.96,140.16,231.17,7.44;31,66.48,150.00,222.64,7.56;31,66.48,160.08,57.38,7.44" xml:id="b25">
	<analytic>
		<title level="a" type="main" xml:id="_UEPYtmf">Implications of CTEQ global analysis for collider observables</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">M</forename><surname>Nadolsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0802.0007</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_qHs3FgB">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page">13004</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.96,170.04,231.17,7.44;31,66.48,179.89,222.64,7.56;31,66.48,189.97,57.38,7.44" xml:id="b26">
	<analytic>
		<title level="a" type="main" xml:id="_SphMSwe">Parton distributions for the LHC</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">D</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Stirling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">S</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Watt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0901.0002</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_VujwcRK">Eur. Phys. J. C</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="189" to="285" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.96,199.93,231.16,7.44;31,66.48,209.90,222.67,7.44;31,66.48,219.74,182.01,7.56" xml:id="b27">
	<analytic>
		<title level="a" type="main" xml:id="_2Gevp9R">A first unbiased global NLO determination of parton distributions and their uncertainties</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">D</forename><surname>Ball</surname></persName>
			<affiliation>
				<orgName type="collaboration">NNPDF Collaboration</orgName>
			</affiliation>
		</author>
		<idno type="arXiv">arXiv:1002.4407</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_v8ay3AJ">Nucl. Phys. B</title>
		<imprint>
			<biblScope unit="volume">838</biblScope>
			<biblScope unit="page" from="136" to="206" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.96,229.82,231.14,7.44;31,66.48,239.67,222.64,7.56;31,66.48,249.75,84.18,7.44" xml:id="b28">
	<analytic>
		<title level="a" type="main" xml:id="_aM9qwvU">Uncertainty induced by QCD coupling in the CTEQ global analysis of parton distributions</title>
		<author>
			<persName coords=""><forename type="first">H.-L</forename><surname>Lai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1004.4624</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_sshZFrR">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page">54021</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.96,259.71,231.15,7.44;31,66.48,268.93,222.64,8.94;31,66.48,279.63,57.38,7.44" xml:id="b29">
	<analytic>
		<title level="a" type="main" xml:id="_WkRFJGr">Uncertainties on α S in global PDF analyses</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">D</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Stirling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">S</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Watt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0905.3531</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_9H7aGsk">Eur. Phys. J. C</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="653" to="680" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.97,289.59,231.15,7.44;31,66.48,298.81,222.67,8.94;31,66.48,309.40,222.57,7.56" xml:id="b30">
	<analytic>
		<title level="a" type="main" xml:id="_cs4w5nS">The impact of PDF and α s uncertainties on Higgs Production in gluon fusion at hadron colliders</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Demartin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Forte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Mariani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rojo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vicini</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1004.0962</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_SxVYmDz">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page">14002</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.96,339.41,231.15,7.44;31,66.48,348.63,222.63,8.94;31,66.48,359.33,11.28,7.44" xml:id="b31">
	<monogr>
		<ptr target="http://www.hep.ucl.ac.uk/pdf4lhc/alphasprop.pdf" />
		<title level="m" xml:id="_wb5qdQs">Procedure for Adding PDF and α s Uncertainties</title>
				<meeting>edure for Adding PDF and α s Uncertainties</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.97,369.30,231.18,7.44;31,66.48,379.14,158.21,7.56" xml:id="b32">
	<analytic>
		<title level="a" type="main" xml:id="_mumf44Z">Review of particle physics</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Olive</surname></persName>
			<affiliation>
				<orgName type="collaboration">Particle Data Group Collaboration</orgName>
			</affiliation>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_HSPrXxw">Chin. Phys. C</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page">90001</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.96,389.22,231.16,7.44;31,66.48,399.19,222.66,7.44;31,66.48,409.03,222.35,7.56;31,66.48,419.11,167.81,7.44" xml:id="b33">
	<analytic>
		<title level="a" type="main" xml:id="_qCNpsct">Study of Monte Carlo approach to experimental uncertainty propagation with MSTW 2008 PDFs</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Watt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">S</forename><surname>Thorne</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1205.4024</idno>
		<ptr target="http://mstwpdf.hepforge.org/random/" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_ecTg9FT">JHEP</title>
		<imprint>
			<biblScope unit="volume">1208</biblScope>
			<biblScope unit="page">52</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.97,429.07,231.16,7.44;31,66.48,439.04,194.96,7.44" xml:id="b34">
	<monogr>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Watt</surname></persName>
		</author>
		<ptr target="http://indico.cern.ch/event/244768/contribution/5" />
		<title level="m" xml:id="_xT9zrg3">Talk presented at PDF4LHC meeting</title>
				<meeting><address><addrLine>Geneva</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
		<respStmt>
			<orgName>CERN</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.97,449.00,231.16,7.44;31,66.48,458.96,222.67,7.44;31,66.48,468.93,222.65,7.44;31,66.48,478.77,185.02,7.56" xml:id="b35">
	<analytic>
		<title level="a" type="main" xml:id="_rqCC8Fk">The automated computation of tree-level and next-to-leading order differential cross sections, and their matching to parton shower simulations</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Alwall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Frederix</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Frixione</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Hirschi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Maltoni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1405.0301</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_B7UDzUz">JHEP</title>
		<imprint>
			<biblScope unit="volume">1407</biblScope>
			<biblScope unit="page">79</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.96,488.85,231.17,7.44;31,66.48,498.81,222.61,7.44;31,66.48,508.66,222.58,7.56" xml:id="b36">
	<analytic>
		<title level="a" type="main" xml:id="_PwP7B6w">Fourlepton production at hadron colliders: aMC@NLO predictions with theoretical uncertainties</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Frederix</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Frixione</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Hirschi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Maltoni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Pittau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1110.4738</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_MH2avdW">JHEP</title>
		<imprint>
			<biblScope unit="volume">1202</biblScope>
			<biblScope unit="page">99</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.96,518.74,231.16,7.44;31,66.48,528.69,222.66,7.44;31,66.48,538.54,214.00,7.56" xml:id="b37">
	<analytic>
		<title level="a" type="main" xml:id="_2KJNudP">A general framework for implementing NLO calculations in shower Monte Carlo programs: the POWHEG BOX</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Alioli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nason</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Oleari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Re</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1002.2581</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ZNSnWuz">JHEP</title>
		<imprint>
			<biblScope unit="volume">1006</biblScope>
			<biblScope unit="page">43</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.96,548.62,231.17,7.44;31,66.48,558.46,222.64,7.56;31,66.48,568.55,57.38,7.44" xml:id="b38">
	<analytic>
		<title level="a" type="main" xml:id="_Xm64fcd">W physics at the LHC with FEWZ 2.1</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Gavin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Petriello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Quackenbush</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1201.5896</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_VECE8d4">Comput. Phys. Commun</title>
		<imprint>
			<biblScope unit="volume">184</biblScope>
			<biblScope unit="page" from="208" to="214" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.96,578.51,231.16,7.44;31,66.48,588.35,162.43,7.56" xml:id="b39">
	<analytic>
		<title level="a" type="main" xml:id="_GqzKkBS">A meta-analysis of parton distribution functions</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nadolsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1401.0013</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Yuhq5eb">JHEP</title>
		<imprint>
			<biblScope unit="volume">1407</biblScope>
			<biblScope unit="page">35</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.96,598.43,231.18,7.44;31,66.48,608.40,222.66,7.44;31,66.48,618.24,182.01,7.56" xml:id="b40">
	<analytic>
		<title level="a" type="main" xml:id="_PHAq6C7">Parton distributions with LHC data</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">D</forename><surname>Ball</surname></persName>
			<affiliation>
				<orgName type="collaboration">NNPDF Collaboration</orgName>
			</affiliation>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bertone</surname></persName>
			<affiliation>
				<orgName type="collaboration">NNPDF Collaboration</orgName>
			</affiliation>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Carrazza</surname></persName>
			<affiliation>
				<orgName type="collaboration">NNPDF Collaboration</orgName>
			</affiliation>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">S</forename><surname>Deans</surname></persName>
			<affiliation>
				<orgName type="collaboration">NNPDF Collaboration</orgName>
			</affiliation>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Del Debbio</surname></persName>
			<affiliation>
				<orgName type="collaboration">NNPDF Collaboration</orgName>
			</affiliation>
		</author>
		<idno type="arXiv">arXiv:1207.1303</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_z463sRr">Nucl. Phys. B</title>
		<imprint>
			<biblScope unit="volume">867</biblScope>
			<biblScope unit="page" from="244" to="289" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.96,626.60,231.18,9.44;31,66.48,638.17,218.49,7.56" xml:id="b41">
	<analytic>
		<title level="a" type="main" xml:id="_7Y6MGbr">Parametrization dependence and χ 2 in parton distribution fitting</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pumplin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0909.5176</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_fxRqMqQ">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page">114020</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.97,648.25,231.13,7.44;31,66.48,658.10,222.63,7.56;31,66.48,668.18,103.23,7.44" xml:id="b42">
	<analytic>
		<title level="a" type="main" xml:id="_P27RWmg">An unbiased Hessian representation for Monte Carlo PDFs</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Carrazza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Forte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Kassabov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">I</forename><surname>Latorre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rojo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.06736</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_VEJXuGq">Eur. Phys. J. C</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">369</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,57.97,678.14,231.19,7.44;31,66.48,688.10,222.65,7.44;31,66.48,697.95,215.09,7.56" xml:id="b43">
	<analytic>
		<title level="a" type="main" xml:id="_xfn2zaA">Neural network parametrization of spectral functions from hadronic tau decays and determination of qcd vacuum condensates</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rojo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">I</forename><surname>Latorre</surname></persName>
		</author>
		<idno type="arXiv">arXiv:hep-ph/0401047</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_aZ9wMeM">JHEP</title>
		<imprint>
			<biblScope unit="volume">01</biblScope>
			<biblScope unit="page">55</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,313.09,60.46,231.17,7.44;31,321.60,70.42,222.64,7.44;31,321.60,80.26,222.64,7.56;31,321.60,90.34,76.89,7.44" xml:id="b44">
	<analytic>
		<title level="a" type="main" xml:id="_zDNsGCA">Unbiased determination of the proton structure function f 2( p) with estimation</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Del Debbio</surname></persName>
			<affiliation>
				<orgName type="collaboration">NNPDF Collaboration</orgName>
			</affiliation>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Forte</surname></persName>
			<affiliation>
				<orgName type="collaboration">NNPDF Collaboration</orgName>
			</affiliation>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">I</forename><surname>Latorre</surname></persName>
			<affiliation>
				<orgName type="collaboration">NNPDF Collaboration</orgName>
			</affiliation>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Piccione</surname></persName>
			<affiliation>
				<orgName type="collaboration">NNPDF Collaboration</orgName>
			</affiliation>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rojo</surname></persName>
			<affiliation>
				<orgName type="collaboration">NNPDF Collaboration</orgName>
			</affiliation>
		</author>
		<idno type="arXiv">arXiv:hep-ph/0501067</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_mkTvQYf">JHEP</title>
		<imprint>
			<biblScope unit="volume">03</biblScope>
			<biblScope unit="page">80</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,313.09,100.31,231.16,7.44;31,321.60,110.15,222.64,7.56;31,321.60,120.23,57.38,7.44" xml:id="b45">
	<analytic>
		<title level="a" type="main" xml:id="_ch7vGmG">Reweighting NNPDFs: the W lepton asymmetry</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">D</forename><surname>Ball</surname></persName>
			<affiliation>
				<orgName type="collaboration">NNPDF Collaboration</orgName>
			</affiliation>
		</author>
		<idno type="arXiv">arXiv:1012.0836</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_8VNSXaC">Nucl. Phys. B</title>
		<imprint>
			<biblScope unit="volume">849</biblScope>
			<biblScope unit="page" from="112" to="143" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,313.09,130.20,231.18,7.44;31,321.60,140.16,222.65,7.44;31,321.82,150.00,222.42,7.56;31,321.60,160.08,57.38,7.44" xml:id="b46">
	<analytic>
		<title level="a" type="main" xml:id="_k2T52e5">Reweighting and unweighting of parton distributions and the LHC W lepton asymmetry data</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">D</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bertone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Cerutti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Del Debbio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Forte</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1108.1758</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_pNDR5XN">Nucl. Phys. B</title>
		<imprint>
			<biblScope unit="volume">855</biblScope>
			<biblScope unit="page" from="608" to="638" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,313.08,170.05,231.17,7.44;31,321.60,180.01,222.63,7.44;31,321.60,189.85,157.53,7.56" xml:id="b47">
	<analytic>
		<title level="a" type="main" xml:id="_7jeFcH7">LHAPDF6: parton density access in the LHC precision era</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ferrando</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Nordstrm</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Page</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.7420</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_maRgejG">Eur. Phys. J. C</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">132</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,313.08,199.94,230.86,7.44;31,321.60,209.90,113.89,7.44" xml:id="b48">
	<monogr>
		<title level="m" type="main" xml:id="_9mpmd6J">A compression tool for Monte Carlo PDF sets</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Carrazza</surname></persName>
		</author>
		<ptr target="https://github.com/scarrazza/compressor" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="31,313.08,219.86,231.16,7.44;31,321.60,229.71,222.64,7.56;31,321.60,239.79,57.38,7.44" xml:id="b49">
	<analytic>
		<title level="a" type="main" xml:id="_mYYcM5H">A higher order perturbative parton evolution toolkit (HOPPET)</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">P</forename><surname>Salam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rojo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0804.3755</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_7yNPscf">Comput. Phys. Commun</title>
		<imprint>
			<biblScope unit="volume">180</biblScope>
			<biblScope unit="page" from="120" to="156" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,313.08,249.75,231.15,7.44;31,321.60,259.59,222.65,7.56;31,321.60,269.68,115.94,7.44" xml:id="b50">
	<analytic>
		<title level="a" type="main" xml:id="_b3kg5T3">Higgs production in gluon fusion beyond NNLO</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">D</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bonvini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Forte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Marzani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ridolfi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1303.3590</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_5bDwqMD">Nucl. Phys. B</title>
		<imprint>
			<biblScope unit="volume">874</biblScope>
			<biblScope unit="page" from="746" to="772" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,313.08,279.63,231.18,7.44;31,321.60,289.59,222.61,7.44;31,321.60,299.44,120.17,7.56" xml:id="b51">
	<analytic>
		<title level="a" type="main" xml:id="_9GTXCYs">Top++: a program for the calculation of the top-pair cross-section at hadron colliders</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Czakon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mitov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1112.5675</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Nh8NwvC">Comput. Phys. Commun</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="page">2930</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,313.09,309.52,231.18,7.44;31,321.60,319.48,222.65,7.44;31,321.60,329.33,222.64,7.56;31,321.60,339.41,76.89,7.44" xml:id="b52">
	<analytic>
		<title level="a" type="main" xml:id="_Xmn5dGp">High precision QCD at hadron colliders: Electroweak gauge boson rapidity distributions at NNLO</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Anastasiou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">J</forename><surname>Dixon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Melnikov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Petriello</surname></persName>
		</author>
		<idno type="arXiv">arXiv:hep-ph/0312266</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ggK7SV8">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page">94008</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,313.08,349.37,231.16,7.44;31,321.60,359.33,222.62,7.44;31,321.60,369.30,222.67,7.44;31,321.60,379.26,111.03,7.44" xml:id="b53">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dittmaier</surname></persName>
			<affiliation>
				<orgName type="collaboration">LHC Higgs Cross Section Working Group</orgName>
			</affiliation>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Mariotti</surname></persName>
			<affiliation>
				<orgName type="collaboration">LHC Higgs Cross Section Working Group</orgName>
			</affiliation>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename></persName>
			<affiliation>
				<orgName type="collaboration">LHC Higgs Cross Section Working Group</orgName>
			</affiliation>
		</author>
		<idno type="arXiv">arXiv:1201.3084</idno>
		<title level="m" xml:id="_uFQrbWZ">Handbook of LHC Higgs Cross Sections: 2. Differential Distributions</title>
				<editor>
			<persName><forename type="first">R</forename><surname>Passarino</surname></persName>
		</editor>
		<editor>
			<persName><surname>Tanaka</surname></persName>
		</editor>
		<meeting><address><addrLine>Geneva</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
		<respStmt>
			<orgName>CERN</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="31,313.08,389.22,231.16,7.44;31,321.60,399.18,109.96,7.44" xml:id="b54">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">H</forename><surname>Hardy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">E</forename><surname>Littlewood</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Pólya</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Inequalities</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1978">1978</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,313.08,409.15,231.15,7.44" xml:id="b55">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<title level="m" xml:id="_Gksncjw">Elements of information theory</title>
				<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,313.08,419.11,231.16,7.44;31,321.60,428.95,222.63,7.56;31,321.60,439.03,84.18,7.44" xml:id="b56">
	<analytic>
		<title level="a" type="main" xml:id="_fBhRZmg">APFEL: a PDF evolution library with QED corrections</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bertone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Carrazza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rojo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1310.1394</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_CdK8HdZ">Comput. Phys. Commun</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="page" from="1647" to="1668" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,313.08,449.00,231.17,7.44;31,321.60,458.96,222.64,7.44;31,321.60,468.80,221.96,7.56" xml:id="b57">
	<analytic>
		<title level="a" type="main" xml:id="_Q8MNSjc">APFEL Web: a webbased application for the graphical visualization of parton distribution functions</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Carrazza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ferrara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Palazzo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rojo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.5456</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_y5qyS7t">J. Phys. G</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">57001</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,313.09,478.89,231.16,7.44;31,321.60,488.73,219.56,7.56" xml:id="b58">
	<analytic>
		<title level="a" type="main" xml:id="_JEwSKe7">Radiative corrections to Z b anti-b production</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">K</forename><surname>Ellis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:hep-ph/0006304</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_UsbVy7e">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page">114012</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,313.08,498.81,231.14,7.44;31,321.60,508.66,222.64,7.56;31,321.60,518.74,76.89,7.44" xml:id="b59">
	<analytic>
		<title level="a" type="main" xml:id="_MpA9m6b">Next-to-leading order calculation of three-jet observables in hadron hadron collision</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Nagy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:hep-ph/0307268</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_dQbwCmC">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page">94002</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,313.09,528.70,231.18,7.44;31,321.60,538.66,222.64,7.44;31,321.60,548.62,222.65,7.44;31,321.60,558.47,208.82,7.56" xml:id="b60">
	<analytic>
		<title level="a" type="main" xml:id="_EU8NpDJ">A posteriori inclusion of parton density functions in NLO QCD final-state calculations at hadron colliders: The APPLGRID Project</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Carli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Clements</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cooper-Sarkar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gwenlan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">P</forename><surname>Salam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0911.2985</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_wh8SWxM">Eur. Phys. J. C</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="503" to="524" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,313.09,568.55,231.18,7.44;31,321.60,578.39,222.64,7.56;31,321.60,588.47,98.99,7.44" xml:id="b61">
	<analytic>
		<title level="a" type="main" xml:id="_78UWcXd">aMCfast: automation of fast NLO computations for PDF fits</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bertone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Frederix</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Frixione</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rojo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sutton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.7693</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_v2ygyRz">JHEP</title>
		<imprint>
			<biblScope unit="volume">1408</biblScope>
			<biblScope unit="page">166</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,313.09,598.44,231.14,7.44;31,321.60,608.40,200.99,7.44;31,524.34,601.52,7.16,8.47;31,531.51,607.66,12.76,8.47" xml:id="b62">
	<monogr>
		<title level="m" type="main" xml:id="_aA2nneg">Measurement of the highmass Drell-Yan differential cross-section in pp collisions at √ s =</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Aad</surname></persName>
			<affiliation>
				<orgName type="collaboration">ATLAS Collaboration</orgName>
			</affiliation>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="31,327.12,618.25,217.03,7.56;31,321.60,628.33,57.38,7.44" xml:id="b63">
	<analytic>
		<title level="a" type="main" xml:id="_HWcAkGQ">TeV with the ATLAS detector</title>
		<idno type="arXiv">arXiv:1305.4192</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_wcrVMVy">Phys. Lett. B</title>
		<imprint>
			<biblScope unit="volume">725</biblScope>
			<biblScope unit="page" from="223" to="242" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,313.09,638.29,231.18,7.44;31,321.60,648.25,222.64,7.44;31,321.60,658.22,130.88,7.44;31,454.99,651.33,7.16,8.47;31,462.16,657.47,82.09,8.47;31,321.60,668.18,98.99,7.44" xml:id="b64">
	<analytic>
		<title level="a" type="main" xml:id="_FEyX6JS">Measurement of the differential and double-differential Drell-Yan cross sections in proton-proton collisions at √ s = 7 TeV</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chatrchyan</surname></persName>
			<affiliation>
				<orgName type="collaboration">CMS Collaboration Collaboration</orgName>
			</affiliation>
		</author>
		<idno type="arXiv">arXiv:1310.7291</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_bRwXK8U">JHEP</title>
		<imprint>
			<biblScope unit="volume">1312</biblScope>
			<biblScope unit="page">30</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,313.09,678.14,231.14,7.44;31,321.60,688.10,192.03,7.44;31,516.19,681.21,7.16,8.47;31,523.36,687.36,20.91,8.47;31,321.60,698.07,222.66,7.44;31,321.60,707.91,206.17,7.56" xml:id="b65">
	<analytic>
		<title level="a" type="main" xml:id="_qEpZNQw">Measurement of the muon charge asymmetry in inclusive pp to W X production at √ s = 7 TeV and an improved determination of light parton distribution functions</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chatrchyan</surname></persName>
			<affiliation>
				<orgName type="collaboration">CMS Collaboration</orgName>
			</affiliation>
		</author>
		<idno type="arXiv">arXiv:1312.6283</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_tAU9rDC">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page">32004</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="32,57.97,60.45,231.19,7.44;32,66.48,70.42,156.46,7.44;32,225.24,63.53,7.16,8.47;32,232.40,70.42,56.75,7.44;32,66.48,80.26,120.18,7.56" xml:id="b66">
	<analytic>
		<title level="a" type="main" xml:id="_KyEBFYs">Measurement of associated W + charm production in pp collisions at √ s = 7 TeV</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chatrchyan</surname></persName>
			<affiliation>
				<orgName type="collaboration">CMS Collaboration</orgName>
			</affiliation>
		</author>
		<idno type="arXiv">arXiv:1310.1138</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_AV5KhZx">JHEP</title>
		<imprint>
			<biblScope unit="volume">1402</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="32,57.97,90.34,231.17,7.44;32,66.48,100.31,124.78,7.44;32,192.46,93.42,7.16,8.47;32,199.65,100.31,89.47,7.44;32,66.48,110.15,201.47,7.56" xml:id="b67">
	<analytic>
		<title level="a" type="main" xml:id="_wShjA7N">Measurement of inclusive jet and dijet production in pp collisions at √ s = 7 TeV using the ATLAS detector</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Aad</surname></persName>
			<affiliation>
				<orgName type="collaboration">ATLAS Collaboration</orgName>
			</affiliation>
		</author>
		<idno type="arXiv">arXiv:1112.6297</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_jW7nH5p">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page">14022</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="32,313.09,60.45,231.14,7.44;32,321.60,70.42,222.65,7.44;32,321.60,80.38,139.96,7.44" xml:id="b68">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Butterworth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Dissertori</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dittmaier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>De Florian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Glover</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1405.1067</idno>
		<title level="m" xml:id="_gtPvfst">Physics at TeV Colliders: Standard Model Working Group Report</title>
				<meeting><address><addrLine>Les Houches</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="32,313.09,90.34,231.18,7.44;32,321.60,100.31,222.63,7.44" xml:id="b69">
	<analytic>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rojo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1003.1241</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_rwKCzDJ">The SM and NLO multileg working group: Summary report</title>
				<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
