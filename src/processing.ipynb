{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-13T07:49:39.746714162Z",
     "start_time": "2023-05-13T07:49:39.735756750Z"
    }
   },
   "outputs": [],
   "source": [
    "from grobid.client import GrobidClient\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import xml.etree.ElementTree as ET\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Obtener las clases y propiedades con grobid</h1>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from processor import PaperProcessor\n",
    "\n",
    "input_path = \"../res/datasets/space/raw/\"\n",
    "output_path = \"../res/datasets/space/grobid/\"\n",
    "\n",
    "processor = PaperProcessor(output_path=output_path)\n",
    "papers = processor.process_folder(input_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T20:43:43.777133926Z",
     "start_time": "2023-05-12T20:42:34.684660041Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from paper_space import PaperSet\n",
    "paper_space = PaperSet(papers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T20:43:43.994202838Z",
     "start_time": "2023-05-12T20:43:43.821193617Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Validation set </h1>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PaperProcessor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m input_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../res/datasets/validation/raw/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      2\u001B[0m output_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../res/datasets/validation/grobid/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 4\u001B[0m processor \u001B[38;5;241m=\u001B[39m \u001B[43mPaperProcessor\u001B[49m(output_path\u001B[38;5;241m=\u001B[39moutput_path)\n\u001B[1;32m      5\u001B[0m val_papers \u001B[38;5;241m=\u001B[39m processor\u001B[38;5;241m.\u001B[39mprocess_folder(input_path)\n\u001B[1;32m      7\u001B[0m val_space \u001B[38;5;241m=\u001B[39m PaperSet(val_papers)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'PaperProcessor' is not defined"
     ]
    }
   ],
   "source": [
    "input_path = \"../res/datasets/validation/raw/\"\n",
    "output_path = \"../res/datasets/validation/grobid/\"\n",
    "\n",
    "processor = PaperProcessor(output_path=output_path)\n",
    "val_papers = processor.process_folder(input_path)\n",
    "\n",
    "val_space = PaperSet(val_papers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T18:35:05.042408897Z",
     "start_time": "2023-05-14T18:35:04.733724634Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Obtener las clases y propiedades desde los xml ya procesados</h1>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/dani/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/dani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from processor import PaperProcessor\n",
    "from paper_space import PaperSet\n",
    "\n",
    "input_path = \"../res/datasets/space/raw/\"\n",
    "output_path = \"../res/datasets/space/grobid/\"\n",
    "\n",
    "processor = PaperProcessor(output_path=output_path)\n",
    "papers = processor.process_folder_from_xml(pdf_path=input_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T21:31:44.792251611Z",
     "start_time": "2023-05-14T21:31:42.693981638Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Obtener el Paper Space </h1>\n",
    "\n",
    "El paper Space es una representación pitónica de clases del grafo de conocimiento, permite realizar todas las operaciones necesarias para enriquecer el grafo de manera cómoda."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "paper_space = PaperSet(papers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Obtener Grafo de conocimiento a partir del Paper Space </h1>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from rdfparser import RDFParser\n",
    "\n",
    "kg = RDFParser(paper_space)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T22:13:17.197016207Z",
     "start_time": "2023-05-14T22:13:15.535607207Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Guardar KG </h1>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import rdflib\n",
    "import json\n",
    "json_ld = kg.g.serialize(format='json-ld', indent=4)\n",
    "with open('../res/datasets/json-ld/kg.jsonld', 'w') as outfile:\n",
    "    json.dump(json.loads(json_ld), outfile)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T22:13:30.737368934Z",
     "start_time": "2023-05-14T22:13:29.330970454Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Pruebas </h1>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectral clustering on large datasets: when does it work? theory from continuous clustering and density cheeger-buser\n",
      "Author name: Timothy, Chu\n",
      "Resource(http://instances.com/unknown)\n",
      "Affiliation: unknown\n",
      "Author name: Gary, Miller\n",
      "Resource(http://instances.com/unknown)\n",
      "Affiliation: unknown\n",
      "Author name: Noel, Walkington\n",
      "Resource(http://instances.com/unknown)\n",
      "Affiliation: unknown\n",
      "Acknowledgement: We would like to thank Emanuel Milman, Luca Trevisan, and Michel Ledoux for explaining the state of the art in Buser inequalities on probability densities, manifolds, and graphs. We would also like to thank Alex Wang for helpful discussions.\n",
      "Acknowledges people: Emanuel, Milman\n",
      "Acknowledges people: Luca, Trevisan\n",
      "Acknowledges people: Michel, Ledoux\n",
      "Acknowledges people: , Buser\n",
      "Acknowledges people: Alex, Wang\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Namespace, URIRef\n",
    "\n",
    "schema = Namespace('http://schema.org/')\n",
    "instances = Namespace('http://instances.com/')\n",
    "\n",
    "# Define the query string\n",
    "query = \"\"\"\n",
    "    PREFIX schema: <http://schema.org/>\n",
    "    PREFIX instances: <http://instances.com/>\n",
    "\n",
    "    SELECT ?paper WHERE {\n",
    "        ?paper a schema:paper ;\n",
    "               schema:title \"spectral clustering on large datasets: when does it work? theory from continuous clustering and density cheeger-buser\" .\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "for row in kg.g.query(query):\n",
    "    paper_uri = row['paper']\n",
    "    paper = kg.g.resource(paper_uri)\n",
    "    print(paper.value(schema.title))\n",
    "    author = paper.value(schema.author)\n",
    "\n",
    "    for author_uri in paper.objects(schema.author):\n",
    "        print(f\"Author name: {author_uri.value(schema.forename)}, {author_uri.value(schema.surname)}\")\n",
    "        for affiliation_uri in author_uri.objects(schema.affiliation):\n",
    "            print(affiliation_uri)\n",
    "            print(f\"Affiliation: {affiliation_uri.value(schema.name)}\")\n",
    "\n",
    "    for ack in paper.objects(schema.acknowledgement):\n",
    "        print(f\"Acknowledgement: {ack.value(schema.text)}\")\n",
    "        for ack_p in ack.objects(schema.acknowledges_people):\n",
    "            print(f\"Acknowledges people: {ack_p.value(schema.forename)}, {ack_p.value(schema.surname)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T14:19:43.438305937Z",
     "start_time": "2023-05-14T14:19:43.390124294Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1 Validation set</h1>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "input_path = \"../res/datasets/validation/raw/\"\n",
    "output_path = \"../res/datasets/validation/grobid/\"\n",
    "\n",
    "processor = PaperProcessor(output_path=output_path)\n",
    "val_papers = processor.process_folder_from_xml(input_path)\n",
    "\n",
    "val_space = PaperSet(val_papers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T10:21:35.381457598Z",
     "start_time": "2023-05-13T10:21:33.722575749Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Trabajo previo: modelos y preproceso </h1>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Modelo para tokenizar</h1>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evidentemente para esta tarea el conjunto de validación no es necesario pero aplicamos también clustering sobre él por comparar resultados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "encoded_papers = paper_space.encode_papers()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T10:21:42.783594979Z",
     "start_time": "2023-05-13T10:21:36.909775467Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "val_encoded_papers = val_space.encode_papers()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T10:21:47.018292571Z",
     "start_time": "2023-05-13T10:21:42.786730687Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                         0         1    \\\na note on the evaluation of generative models      -0.131301  0.002281   \nspectral clustering on large datasets: when doe... -0.211543 -0.091019   \nattributing emotion to static body postures: re...  0.027020 -0.150171   \nadversarial multi-task learning for text classi... -0.011254 -0.117132   \nadam: a method for stochastic optimization         -0.164474 -0.218572   \ndo deep generative models know what they don't ... -0.116699 -0.067629   \nact1 adaptor protein is an immediate and essent... -0.217020  0.010229   \ngradient surgery for multi-task learning           -0.014807 -0.036753   \nauxiliary deep generative models                   -0.100119  0.091307   \ninterleukin-17 contributes to cardiovascular di... -0.374179  0.089261   \nactive learning in the predict-then-optimize fr... -0.299680 -0.013598   \nlearning deep generative models                    -0.222258 -0.050427   \nchurch: a language for generative models           -0.020252  0.000737   \naffective multimodal human-computer interaction    -0.237680 -0.121553   \nbi-modal emotion recognition from expressive fa... -0.037902 -0.123946   \nphylogenetic diversity of animal oral and gastr... -0.068638 -0.160210   \nefficient emotion recognition from speech using... -0.212834  0.009176   \ninfiltrates of activated mast cells at the site...  0.022739  0.032374   \nemotion classification based on biophysical sig... -0.012231  0.034326   \na five-fold expansion of the global rna virome ... -0.183117  0.126551   \nthe genetic sequence, origin, and diagnosis of ...  0.071071  0.065747   \nhow expressive are spectral-temporal graph neur... -0.410183 -0.003351   \nspeech and speaker recognition from raw wavefor... -0.107646 -0.007173   \nemotion analysis in man-machine interaction sys... -0.342051 -0.014625   \nbiomedical signal processing and control           -0.174253  0.110228   \nspeech emotion analysis: exploring the role of ... -0.260448 -0.115763   \nepidemiology, genetic recombination, and pathog... -0.140111  0.111081   \nhighly diverse and unknown viruses may enhance ... -0.196776 -0.110916   \njukebox: a generative model for music               0.061052 -0.080023   \nspeech emotion recognition from spectrograms wi... -0.266297  0.089480   \n\n                                                         2         3    \\\na note on the evaluation of generative models      -0.001868 -0.052441   \nspectral clustering on large datasets: when doe...  0.051769 -0.009679   \nattributing emotion to static body postures: re...  0.110937 -0.013334   \nadversarial multi-task learning for text classi...  0.008287  0.008054   \nadam: a method for stochastic optimization         -0.055986 -0.119140   \ndo deep generative models know what they don't ... -0.212448 -0.066083   \nact1 adaptor protein is an immediate and essent... -0.009581 -0.049192   \ngradient surgery for multi-task learning           -0.185821 -0.068827   \nauxiliary deep generative models                    0.079752  0.003888   \ninterleukin-17 contributes to cardiovascular di... -0.007220 -0.044155   \nactive learning in the predict-then-optimize fr... -0.242172  0.007244   \nlearning deep generative models                     0.056093  0.065098   \nchurch: a language for generative models           -0.114336 -0.095446   \naffective multimodal human-computer interaction     0.064158  0.195141   \nbi-modal emotion recognition from expressive fa...  0.198125  0.068028   \nphylogenetic diversity of animal oral and gastr... -0.005311 -0.018336   \nefficient emotion recognition from speech using...  0.210442 -0.008372   \ninfiltrates of activated mast cells at the site...  0.022658  0.175620   \nemotion classification based on biophysical sig...  0.088927  0.501120   \na five-fold expansion of the global rna virome ... -0.121534 -0.214322   \nthe genetic sequence, origin, and diagnosis of ... -0.108173  0.025268   \nhow expressive are spectral-temporal graph neur...  0.129728 -0.007543   \nspeech and speaker recognition from raw wavefor...  0.077208 -0.041375   \nemotion analysis in man-machine interaction sys...  0.163226  0.011740   \nbiomedical signal processing and control            0.147513  0.069464   \nspeech emotion analysis: exploring the role of ...  0.060921  0.072361   \nepidemiology, genetic recombination, and pathog... -0.318208  0.007446   \nhighly diverse and unknown viruses may enhance ...  0.081952  0.208922   \njukebox: a generative model for music              -0.090736 -0.164185   \nspeech emotion recognition from spectrograms wi...  0.050797  0.019209   \n\n                                                         4         5    \\\na note on the evaluation of generative models       0.027265 -0.000154   \nspectral clustering on large datasets: when doe... -0.067754 -0.038043   \nattributing emotion to static body postures: re... -0.020474  0.097832   \nadversarial multi-task learning for text classi...  0.014083  0.216623   \nadam: a method for stochastic optimization         -0.233879 -0.006420   \ndo deep generative models know what they don't ...  0.141361  0.124095   \nact1 adaptor protein is an immediate and essent...  0.311222  0.107234   \ngradient surgery for multi-task learning           -0.210362  0.165932   \nauxiliary deep generative models                    0.000883  0.066475   \ninterleukin-17 contributes to cardiovascular di...  0.336266  0.055240   \nactive learning in the predict-then-optimize fr... -0.057549  0.252179   \nlearning deep generative models                    -0.283471 -0.119786   \nchurch: a language for generative models           -0.321001 -0.158306   \naffective multimodal human-computer interaction    -0.120497 -0.073834   \nbi-modal emotion recognition from expressive fa... -0.144844 -0.161246   \nphylogenetic diversity of animal oral and gastr...  0.019749 -0.124434   \nefficient emotion recognition from speech using... -0.306474  0.194551   \ninfiltrates of activated mast cells at the site...  0.237818  0.028323   \nemotion classification based on biophysical sig... -0.061734  0.009714   \na five-fold expansion of the global rna virome ...  0.045312  0.063225   \nthe genetic sequence, origin, and diagnosis of ...  0.162468 -0.077258   \nhow expressive are spectral-temporal graph neur...  0.007614  0.201268   \nspeech and speaker recognition from raw wavefor... -0.225799  0.118387   \nemotion analysis in man-machine interaction sys... -0.236230 -0.126122   \nbiomedical signal processing and control           -0.344248  0.240459   \nspeech emotion analysis: exploring the role of ...  0.003197 -0.011250   \nepidemiology, genetic recombination, and pathog...  0.109339 -0.102005   \nhighly diverse and unknown viruses may enhance ...  0.153547  0.085620   \njukebox: a generative model for music              -0.341909  0.082541   \nspeech emotion recognition from spectrograms wi... -0.163504  0.302034   \n\n                                                         6         7    \\\na note on the evaluation of generative models      -0.217419 -0.025462   \nspectral clustering on large datasets: when doe... -0.118742 -0.059393   \nattributing emotion to static body postures: re...  0.173472  0.070862   \nadversarial multi-task learning for text classi... -0.022780 -0.199792   \nadam: a method for stochastic optimization         -0.040818 -0.019091   \ndo deep generative models know what they don't ... -0.117617 -0.059158   \nact1 adaptor protein is an immediate and essent...  0.377248  0.079945   \ngradient surgery for multi-task learning           -0.120382 -0.179489   \nauxiliary deep generative models                   -0.150963  0.120281   \ninterleukin-17 contributes to cardiovascular di...  0.312621  0.204889   \nactive learning in the predict-then-optimize fr...  0.067137  0.030514   \nlearning deep generative models                    -0.106033 -0.169425   \nchurch: a language for generative models           -0.283713 -0.364829   \naffective multimodal human-computer interaction     0.300674  0.030251   \nbi-modal emotion recognition from expressive fa...  0.181320 -0.054464   \nphylogenetic diversity of animal oral and gastr... -0.200042 -0.031274   \nefficient emotion recognition from speech using...  0.077094 -0.096065   \ninfiltrates of activated mast cells at the site... -0.108735  0.153267   \nemotion classification based on biophysical sig...  0.285312 -0.043306   \na five-fold expansion of the global rna virome ... -0.236382  0.264796   \nthe genetic sequence, origin, and diagnosis of ... -0.006693  0.167643   \nhow expressive are spectral-temporal graph neur... -0.139217 -0.094568   \nspeech and speaker recognition from raw wavefor... -0.141102 -0.138133   \nemotion analysis in man-machine interaction sys...  0.199178 -0.067926   \nbiomedical signal processing and control           -0.000388 -0.192025   \nspeech emotion analysis: exploring the role of ...  0.160649  0.110402   \nepidemiology, genetic recombination, and pathog... -0.049281  0.154682   \nhighly diverse and unknown viruses may enhance ... -0.063995  0.022959   \njukebox: a generative model for music              -0.041563 -0.227455   \nspeech emotion recognition from spectrograms wi...  0.084427 -0.117726   \n\n                                                         8         9    ...  \\\na note on the evaluation of generative models      -0.099417  0.021509  ...   \nspectral clustering on large datasets: when doe... -0.112872 -0.146397  ...   \nattributing emotion to static body postures: re...  0.226507  0.093283  ...   \nadversarial multi-task learning for text classi... -0.074386 -0.184818  ...   \nadam: a method for stochastic optimization          0.119539  0.201531  ...   \ndo deep generative models know what they don't ...  0.031601 -0.096388  ...   \nact1 adaptor protein is an immediate and essent...  0.078471 -0.008878  ...   \ngradient surgery for multi-task learning            0.039120  0.149806  ...   \nauxiliary deep generative models                   -0.074516 -0.294434  ...   \ninterleukin-17 contributes to cardiovascular di...  0.100890 -0.008588  ...   \nactive learning in the predict-then-optimize fr... -0.163859 -0.097480  ...   \nlearning deep generative models                    -0.010776  0.137187  ...   \nchurch: a language for generative models            0.144658  0.005382  ...   \naffective multimodal human-computer interaction     0.157747  0.157007  ...   \nbi-modal emotion recognition from expressive fa...  0.176738  0.155010  ...   \nphylogenetic diversity of animal oral and gastr...  0.211168  0.046801  ...   \nefficient emotion recognition from speech using...  0.222753 -0.139826  ...   \ninfiltrates of activated mast cells at the site... -0.000503 -0.073391  ...   \nemotion classification based on biophysical sig...  0.061156 -0.030468  ...   \na five-fold expansion of the global rna virome ...  0.013597  0.280727  ...   \nthe genetic sequence, origin, and diagnosis of ...  0.030059 -0.146180  ...   \nhow expressive are spectral-temporal graph neur... -0.064717 -0.207120  ...   \nspeech and speaker recognition from raw wavefor...  0.129618 -0.196472  ...   \nemotion analysis in man-machine interaction sys... -0.123946 -0.049873  ...   \nbiomedical signal processing and control            0.059371 -0.091020  ...   \nspeech emotion analysis: exploring the role of ...  0.102621  0.034780  ...   \nepidemiology, genetic recombination, and pathog...  0.243224 -0.065193  ...   \nhighly diverse and unknown viruses may enhance ...  0.019880  0.056753  ...   \njukebox: a generative model for music               0.098310 -0.019081  ...   \nspeech emotion recognition from spectrograms wi...  0.036354 -0.007675  ...   \n\n                                                         374       375  \\\na note on the evaluation of generative models       0.040486  0.075056   \nspectral clustering on large datasets: when doe...  0.243307 -0.031499   \nattributing emotion to static body postures: re... -0.092015  0.182329   \nadversarial multi-task learning for text classi...  0.198303  0.247609   \nadam: a method for stochastic optimization          0.368220 -0.217900   \ndo deep generative models know what they don't ...  0.230404  0.056851   \nact1 adaptor protein is an immediate and essent... -0.080643  0.113137   \ngradient surgery for multi-task learning            0.315716  0.177421   \nauxiliary deep generative models                    0.100793 -0.043954   \ninterleukin-17 contributes to cardiovascular di... -0.095176  0.117587   \nactive learning in the predict-then-optimize fr...  0.164473  0.000792   \nlearning deep generative models                     0.119680  0.309623   \nchurch: a language for generative models            0.059846  0.295656   \naffective multimodal human-computer interaction     0.117715  0.074405   \nbi-modal emotion recognition from expressive fa... -0.016990  0.031777   \nphylogenetic diversity of animal oral and gastr... -0.374964  0.045842   \nefficient emotion recognition from speech using...  0.206409  0.015733   \ninfiltrates of activated mast cells at the site... -0.315328  0.048527   \nemotion classification based on biophysical sig... -0.112260  0.062733   \na five-fold expansion of the global rna virome ... -0.299533  0.231675   \nthe genetic sequence, origin, and diagnosis of ... -0.291222  0.141058   \nhow expressive are spectral-temporal graph neur...  0.323498  0.127689   \nspeech and speaker recognition from raw wavefor...  0.215038  0.221371   \nemotion analysis in man-machine interaction sys... -0.066962  0.184284   \nbiomedical signal processing and control            0.110846  0.171465   \nspeech emotion analysis: exploring the role of ...  0.115744  0.108869   \nepidemiology, genetic recombination, and pathog... -0.293126  0.064523   \nhighly diverse and unknown viruses may enhance ... -0.303771  0.057834   \njukebox: a generative model for music               0.326686  0.114147   \nspeech emotion recognition from spectrograms wi...  0.139583  0.145544   \n\n                                                         376       377  \\\na note on the evaluation of generative models       0.013146  0.056772   \nspectral clustering on large datasets: when doe...  0.180494 -0.277817   \nattributing emotion to static body postures: re...  0.178680  0.028688   \nadversarial multi-task learning for text classi...  0.128383 -0.003970   \nadam: a method for stochastic optimization          0.016337 -0.219282   \ndo deep generative models know what they don't ... -0.156073 -0.050162   \nact1 adaptor protein is an immediate and essent... -0.013617  0.162523   \ngradient surgery for multi-task learning            0.051643 -0.003328   \nauxiliary deep generative models                   -0.064581 -0.000687   \ninterleukin-17 contributes to cardiovascular di... -0.119495  0.200736   \nactive learning in the predict-then-optimize fr...  0.154642 -0.098450   \nlearning deep generative models                     0.138099  0.061564   \nchurch: a language for generative models            0.097661  0.200532   \naffective multimodal human-computer interaction     0.102940  0.658100   \nbi-modal emotion recognition from expressive fa...  0.288581  0.079372   \nphylogenetic diversity of animal oral and gastr... -0.075576 -0.042798   \nefficient emotion recognition from speech using... -0.066408  0.207632   \ninfiltrates of activated mast cells at the site...  0.150879  0.068611   \nemotion classification based on biophysical sig...  0.085158  0.590207   \na five-fold expansion of the global rna virome ...  0.204877 -0.120191   \nthe genetic sequence, origin, and diagnosis of ... -0.145358 -0.005457   \nhow expressive are spectral-temporal graph neur... -0.093046 -0.159796   \nspeech and speaker recognition from raw wavefor... -0.097074  0.062158   \nemotion analysis in man-machine interaction sys...  0.097915  0.115291   \nbiomedical signal processing and control           -0.072680  0.324185   \nspeech emotion analysis: exploring the role of ...  0.078513  0.228186   \nepidemiology, genetic recombination, and pathog...  0.107462 -0.146291   \nhighly diverse and unknown viruses may enhance ...  0.107738  0.000647   \njukebox: a generative model for music              -0.023131  0.174258   \nspeech emotion recognition from spectrograms wi...  0.062644  0.262093   \n\n                                                         378       379  \\\na note on the evaluation of generative models       0.087080  0.043438   \nspectral clustering on large datasets: when doe...  0.054701 -0.028978   \nattributing emotion to static body postures: re...  0.075122  0.084355   \nadversarial multi-task learning for text classi...  0.345068  0.105736   \nadam: a method for stochastic optimization          0.003607  0.007275   \ndo deep generative models know what they don't ...  0.035960 -0.079832   \nact1 adaptor protein is an immediate and essent...  0.188115 -0.271989   \ngradient surgery for multi-task learning            0.054881  0.085309   \nauxiliary deep generative models                   -0.021658 -0.053180   \ninterleukin-17 contributes to cardiovascular di...  0.109948 -0.217132   \nactive learning in the predict-then-optimize fr...  0.177495  0.005594   \nlearning deep generative models                     0.048937  0.147484   \nchurch: a language for generative models            0.162598 -0.103312   \naffective multimodal human-computer interaction    -0.286904 -0.065558   \nbi-modal emotion recognition from expressive fa...  0.046022  0.057733   \nphylogenetic diversity of animal oral and gastr...  0.239727  0.235291   \nefficient emotion recognition from speech using...  0.100846  0.155602   \ninfiltrates of activated mast cells at the site... -0.012239 -0.052948   \nemotion classification based on biophysical sig... -0.129694 -0.109371   \na five-fold expansion of the global rna virome ...  0.050099  0.176836   \nthe genetic sequence, origin, and diagnosis of ...  0.259224  0.180605   \nhow expressive are spectral-temporal graph neur... -0.085574 -0.113382   \nspeech and speaker recognition from raw wavefor...  0.171623  0.246033   \nemotion analysis in man-machine interaction sys...  0.302319  0.203180   \nbiomedical signal processing and control            0.053615  0.107069   \nspeech emotion analysis: exploring the role of ...  0.225899  0.043747   \nepidemiology, genetic recombination, and pathog...  0.337017  0.041781   \nhighly diverse and unknown viruses may enhance ... -0.091808  0.020936   \njukebox: a generative model for music               0.357787  0.147165   \nspeech emotion recognition from spectrograms wi...  0.143037  0.020252   \n\n                                                         380       381  \\\na note on the evaluation of generative models      -0.153307 -0.143206   \nspectral clustering on large datasets: when doe...  0.178357  0.064155   \nattributing emotion to static body postures: re...  0.174075  0.148864   \nadversarial multi-task learning for text classi... -0.072052  0.126342   \nadam: a method for stochastic optimization         -0.161104  0.266550   \ndo deep generative models know what they don't ... -0.320558  0.286835   \nact1 adaptor protein is an immediate and essent...  0.150667  0.073293   \ngradient surgery for multi-task learning           -0.018980  0.094931   \nauxiliary deep generative models                   -0.234047  0.091222   \ninterleukin-17 contributes to cardiovascular di...  0.162494  0.038443   \nactive learning in the predict-then-optimize fr... -0.106298  0.247308   \nlearning deep generative models                     0.002957  0.164924   \nchurch: a language for generative models           -0.208877  0.043158   \naffective multimodal human-computer interaction     0.254327  0.390681   \nbi-modal emotion recognition from expressive fa...  0.121501  0.249862   \nphylogenetic diversity of animal oral and gastr...  0.081186 -0.224348   \nefficient emotion recognition from speech using... -0.119655  0.334724   \ninfiltrates of activated mast cells at the site...  0.067608  0.007590   \nemotion classification based on biophysical sig...  0.192386  0.214314   \na five-fold expansion of the global rna virome ... -0.312004 -0.209475   \nthe genetic sequence, origin, and diagnosis of ...  0.127763 -0.083994   \nhow expressive are spectral-temporal graph neur... -0.305407  0.083797   \nspeech and speaker recognition from raw wavefor... -0.205998  0.249700   \nemotion analysis in man-machine interaction sys...  0.128122  0.228311   \nbiomedical signal processing and control           -0.244899  0.217088   \nspeech emotion analysis: exploring the role of ... -0.016776  0.385448   \nepidemiology, genetic recombination, and pathog...  0.131400 -0.049114   \nhighly diverse and unknown viruses may enhance ... -0.173423 -0.286831   \njukebox: a generative model for music              -0.156991  0.067413   \nspeech emotion recognition from spectrograms wi... -0.132160  0.337679   \n\n                                                         382       383  \na note on the evaluation of generative models       0.122879 -0.091170  \nspectral clustering on large datasets: when doe... -0.135752  0.165921  \nattributing emotion to static body postures: re... -0.344563 -0.009461  \nadversarial multi-task learning for text classi... -0.054859 -0.065180  \nadam: a method for stochastic optimization          0.026782 -0.005474  \ndo deep generative models know what they don't ... -0.007298 -0.154617  \nact1 adaptor protein is an immediate and essent...  0.341859 -0.255941  \ngradient surgery for multi-task learning           -0.078689  0.010817  \nauxiliary deep generative models                   -0.107009 -0.086530  \ninterleukin-17 contributes to cardiovascular di...  0.282405 -0.112375  \nactive learning in the predict-then-optimize fr... -0.143843  0.076555  \nlearning deep generative models                    -0.158312 -0.222687  \nchurch: a language for generative models            0.125738  0.013501  \naffective multimodal human-computer interaction    -0.198595 -0.215156  \nbi-modal emotion recognition from expressive fa... -0.032596 -0.195461  \nphylogenetic diversity of animal oral and gastr...  0.245588 -0.131071  \nefficient emotion recognition from speech using... -0.077434 -0.052327  \ninfiltrates of activated mast cells at the site...  0.063753  0.111763  \nemotion classification based on biophysical sig... -0.277618 -0.226808  \na five-fold expansion of the global rna virome ...  0.294482  0.157108  \nthe genetic sequence, origin, and diagnosis of ... -0.102171 -0.098668  \nhow expressive are spectral-temporal graph neur... -0.087220 -0.202950  \nspeech and speaker recognition from raw wavefor...  0.119858 -0.114164  \nemotion analysis in man-machine interaction sys... -0.225032 -0.050328  \nbiomedical signal processing and control           -0.136453 -0.334354  \nspeech emotion analysis: exploring the role of ... -0.164617  0.066685  \nepidemiology, genetic recombination, and pathog... -0.227562 -0.002180  \nhighly diverse and unknown viruses may enhance ...  0.117706  0.037596  \njukebox: a generative model for music               0.179363 -0.125200  \nspeech emotion recognition from spectrograms wi... -0.070738 -0.187084  \n\n[30 rows x 384 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>374</th>\n      <th>375</th>\n      <th>376</th>\n      <th>377</th>\n      <th>378</th>\n      <th>379</th>\n      <th>380</th>\n      <th>381</th>\n      <th>382</th>\n      <th>383</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>a note on the evaluation of generative models</th>\n      <td>-0.131301</td>\n      <td>0.002281</td>\n      <td>-0.001868</td>\n      <td>-0.052441</td>\n      <td>0.027265</td>\n      <td>-0.000154</td>\n      <td>-0.217419</td>\n      <td>-0.025462</td>\n      <td>-0.099417</td>\n      <td>0.021509</td>\n      <td>...</td>\n      <td>0.040486</td>\n      <td>0.075056</td>\n      <td>0.013146</td>\n      <td>0.056772</td>\n      <td>0.087080</td>\n      <td>0.043438</td>\n      <td>-0.153307</td>\n      <td>-0.143206</td>\n      <td>0.122879</td>\n      <td>-0.091170</td>\n    </tr>\n    <tr>\n      <th>spectral clustering on large datasets: when does it work? theory from continuous clustering and density cheeger-buser</th>\n      <td>-0.211543</td>\n      <td>-0.091019</td>\n      <td>0.051769</td>\n      <td>-0.009679</td>\n      <td>-0.067754</td>\n      <td>-0.038043</td>\n      <td>-0.118742</td>\n      <td>-0.059393</td>\n      <td>-0.112872</td>\n      <td>-0.146397</td>\n      <td>...</td>\n      <td>0.243307</td>\n      <td>-0.031499</td>\n      <td>0.180494</td>\n      <td>-0.277817</td>\n      <td>0.054701</td>\n      <td>-0.028978</td>\n      <td>0.178357</td>\n      <td>0.064155</td>\n      <td>-0.135752</td>\n      <td>0.165921</td>\n    </tr>\n    <tr>\n      <th>attributing emotion to static body postures: recognition accuracy, confusions, and viewpoint dependence</th>\n      <td>0.027020</td>\n      <td>-0.150171</td>\n      <td>0.110937</td>\n      <td>-0.013334</td>\n      <td>-0.020474</td>\n      <td>0.097832</td>\n      <td>0.173472</td>\n      <td>0.070862</td>\n      <td>0.226507</td>\n      <td>0.093283</td>\n      <td>...</td>\n      <td>-0.092015</td>\n      <td>0.182329</td>\n      <td>0.178680</td>\n      <td>0.028688</td>\n      <td>0.075122</td>\n      <td>0.084355</td>\n      <td>0.174075</td>\n      <td>0.148864</td>\n      <td>-0.344563</td>\n      <td>-0.009461</td>\n    </tr>\n    <tr>\n      <th>adversarial multi-task learning for text classification</th>\n      <td>-0.011254</td>\n      <td>-0.117132</td>\n      <td>0.008287</td>\n      <td>0.008054</td>\n      <td>0.014083</td>\n      <td>0.216623</td>\n      <td>-0.022780</td>\n      <td>-0.199792</td>\n      <td>-0.074386</td>\n      <td>-0.184818</td>\n      <td>...</td>\n      <td>0.198303</td>\n      <td>0.247609</td>\n      <td>0.128383</td>\n      <td>-0.003970</td>\n      <td>0.345068</td>\n      <td>0.105736</td>\n      <td>-0.072052</td>\n      <td>0.126342</td>\n      <td>-0.054859</td>\n      <td>-0.065180</td>\n    </tr>\n    <tr>\n      <th>adam: a method for stochastic optimization</th>\n      <td>-0.164474</td>\n      <td>-0.218572</td>\n      <td>-0.055986</td>\n      <td>-0.119140</td>\n      <td>-0.233879</td>\n      <td>-0.006420</td>\n      <td>-0.040818</td>\n      <td>-0.019091</td>\n      <td>0.119539</td>\n      <td>0.201531</td>\n      <td>...</td>\n      <td>0.368220</td>\n      <td>-0.217900</td>\n      <td>0.016337</td>\n      <td>-0.219282</td>\n      <td>0.003607</td>\n      <td>0.007275</td>\n      <td>-0.161104</td>\n      <td>0.266550</td>\n      <td>0.026782</td>\n      <td>-0.005474</td>\n    </tr>\n    <tr>\n      <th>do deep generative models know what they don't know?</th>\n      <td>-0.116699</td>\n      <td>-0.067629</td>\n      <td>-0.212448</td>\n      <td>-0.066083</td>\n      <td>0.141361</td>\n      <td>0.124095</td>\n      <td>-0.117617</td>\n      <td>-0.059158</td>\n      <td>0.031601</td>\n      <td>-0.096388</td>\n      <td>...</td>\n      <td>0.230404</td>\n      <td>0.056851</td>\n      <td>-0.156073</td>\n      <td>-0.050162</td>\n      <td>0.035960</td>\n      <td>-0.079832</td>\n      <td>-0.320558</td>\n      <td>0.286835</td>\n      <td>-0.007298</td>\n      <td>-0.154617</td>\n    </tr>\n    <tr>\n      <th>act1 adaptor protein is an immediate and essential signaling component of interleukin-17 receptor *</th>\n      <td>-0.217020</td>\n      <td>0.010229</td>\n      <td>-0.009581</td>\n      <td>-0.049192</td>\n      <td>0.311222</td>\n      <td>0.107234</td>\n      <td>0.377248</td>\n      <td>0.079945</td>\n      <td>0.078471</td>\n      <td>-0.008878</td>\n      <td>...</td>\n      <td>-0.080643</td>\n      <td>0.113137</td>\n      <td>-0.013617</td>\n      <td>0.162523</td>\n      <td>0.188115</td>\n      <td>-0.271989</td>\n      <td>0.150667</td>\n      <td>0.073293</td>\n      <td>0.341859</td>\n      <td>-0.255941</td>\n    </tr>\n    <tr>\n      <th>gradient surgery for multi-task learning</th>\n      <td>-0.014807</td>\n      <td>-0.036753</td>\n      <td>-0.185821</td>\n      <td>-0.068827</td>\n      <td>-0.210362</td>\n      <td>0.165932</td>\n      <td>-0.120382</td>\n      <td>-0.179489</td>\n      <td>0.039120</td>\n      <td>0.149806</td>\n      <td>...</td>\n      <td>0.315716</td>\n      <td>0.177421</td>\n      <td>0.051643</td>\n      <td>-0.003328</td>\n      <td>0.054881</td>\n      <td>0.085309</td>\n      <td>-0.018980</td>\n      <td>0.094931</td>\n      <td>-0.078689</td>\n      <td>0.010817</td>\n    </tr>\n    <tr>\n      <th>auxiliary deep generative models</th>\n      <td>-0.100119</td>\n      <td>0.091307</td>\n      <td>0.079752</td>\n      <td>0.003888</td>\n      <td>0.000883</td>\n      <td>0.066475</td>\n      <td>-0.150963</td>\n      <td>0.120281</td>\n      <td>-0.074516</td>\n      <td>-0.294434</td>\n      <td>...</td>\n      <td>0.100793</td>\n      <td>-0.043954</td>\n      <td>-0.064581</td>\n      <td>-0.000687</td>\n      <td>-0.021658</td>\n      <td>-0.053180</td>\n      <td>-0.234047</td>\n      <td>0.091222</td>\n      <td>-0.107009</td>\n      <td>-0.086530</td>\n    </tr>\n    <tr>\n      <th>interleukin-17 contributes to cardiovascular diseases</th>\n      <td>-0.374179</td>\n      <td>0.089261</td>\n      <td>-0.007220</td>\n      <td>-0.044155</td>\n      <td>0.336266</td>\n      <td>0.055240</td>\n      <td>0.312621</td>\n      <td>0.204889</td>\n      <td>0.100890</td>\n      <td>-0.008588</td>\n      <td>...</td>\n      <td>-0.095176</td>\n      <td>0.117587</td>\n      <td>-0.119495</td>\n      <td>0.200736</td>\n      <td>0.109948</td>\n      <td>-0.217132</td>\n      <td>0.162494</td>\n      <td>0.038443</td>\n      <td>0.282405</td>\n      <td>-0.112375</td>\n    </tr>\n    <tr>\n      <th>active learning in the predict-then-optimize framework: a margin-based approach</th>\n      <td>-0.299680</td>\n      <td>-0.013598</td>\n      <td>-0.242172</td>\n      <td>0.007244</td>\n      <td>-0.057549</td>\n      <td>0.252179</td>\n      <td>0.067137</td>\n      <td>0.030514</td>\n      <td>-0.163859</td>\n      <td>-0.097480</td>\n      <td>...</td>\n      <td>0.164473</td>\n      <td>0.000792</td>\n      <td>0.154642</td>\n      <td>-0.098450</td>\n      <td>0.177495</td>\n      <td>0.005594</td>\n      <td>-0.106298</td>\n      <td>0.247308</td>\n      <td>-0.143843</td>\n      <td>0.076555</td>\n    </tr>\n    <tr>\n      <th>learning deep generative models</th>\n      <td>-0.222258</td>\n      <td>-0.050427</td>\n      <td>0.056093</td>\n      <td>0.065098</td>\n      <td>-0.283471</td>\n      <td>-0.119786</td>\n      <td>-0.106033</td>\n      <td>-0.169425</td>\n      <td>-0.010776</td>\n      <td>0.137187</td>\n      <td>...</td>\n      <td>0.119680</td>\n      <td>0.309623</td>\n      <td>0.138099</td>\n      <td>0.061564</td>\n      <td>0.048937</td>\n      <td>0.147484</td>\n      <td>0.002957</td>\n      <td>0.164924</td>\n      <td>-0.158312</td>\n      <td>-0.222687</td>\n    </tr>\n    <tr>\n      <th>church: a language for generative models</th>\n      <td>-0.020252</td>\n      <td>0.000737</td>\n      <td>-0.114336</td>\n      <td>-0.095446</td>\n      <td>-0.321001</td>\n      <td>-0.158306</td>\n      <td>-0.283713</td>\n      <td>-0.364829</td>\n      <td>0.144658</td>\n      <td>0.005382</td>\n      <td>...</td>\n      <td>0.059846</td>\n      <td>0.295656</td>\n      <td>0.097661</td>\n      <td>0.200532</td>\n      <td>0.162598</td>\n      <td>-0.103312</td>\n      <td>-0.208877</td>\n      <td>0.043158</td>\n      <td>0.125738</td>\n      <td>0.013501</td>\n    </tr>\n    <tr>\n      <th>affective multimodal human-computer interaction</th>\n      <td>-0.237680</td>\n      <td>-0.121553</td>\n      <td>0.064158</td>\n      <td>0.195141</td>\n      <td>-0.120497</td>\n      <td>-0.073834</td>\n      <td>0.300674</td>\n      <td>0.030251</td>\n      <td>0.157747</td>\n      <td>0.157007</td>\n      <td>...</td>\n      <td>0.117715</td>\n      <td>0.074405</td>\n      <td>0.102940</td>\n      <td>0.658100</td>\n      <td>-0.286904</td>\n      <td>-0.065558</td>\n      <td>0.254327</td>\n      <td>0.390681</td>\n      <td>-0.198595</td>\n      <td>-0.215156</td>\n    </tr>\n    <tr>\n      <th>bi-modal emotion recognition from expressive face and body gestures</th>\n      <td>-0.037902</td>\n      <td>-0.123946</td>\n      <td>0.198125</td>\n      <td>0.068028</td>\n      <td>-0.144844</td>\n      <td>-0.161246</td>\n      <td>0.181320</td>\n      <td>-0.054464</td>\n      <td>0.176738</td>\n      <td>0.155010</td>\n      <td>...</td>\n      <td>-0.016990</td>\n      <td>0.031777</td>\n      <td>0.288581</td>\n      <td>0.079372</td>\n      <td>0.046022</td>\n      <td>0.057733</td>\n      <td>0.121501</td>\n      <td>0.249862</td>\n      <td>-0.032596</td>\n      <td>-0.195461</td>\n    </tr>\n    <tr>\n      <th>phylogenetic diversity of animal oral and gastrointestinal viromes useful in surveillance of zoonoses</th>\n      <td>-0.068638</td>\n      <td>-0.160210</td>\n      <td>-0.005311</td>\n      <td>-0.018336</td>\n      <td>0.019749</td>\n      <td>-0.124434</td>\n      <td>-0.200042</td>\n      <td>-0.031274</td>\n      <td>0.211168</td>\n      <td>0.046801</td>\n      <td>...</td>\n      <td>-0.374964</td>\n      <td>0.045842</td>\n      <td>-0.075576</td>\n      <td>-0.042798</td>\n      <td>0.239727</td>\n      <td>0.235291</td>\n      <td>0.081186</td>\n      <td>-0.224348</td>\n      <td>0.245588</td>\n      <td>-0.131071</td>\n    </tr>\n    <tr>\n      <th>efficient emotion recognition from speech using deep learning on spectrograms</th>\n      <td>-0.212834</td>\n      <td>0.009176</td>\n      <td>0.210442</td>\n      <td>-0.008372</td>\n      <td>-0.306474</td>\n      <td>0.194551</td>\n      <td>0.077094</td>\n      <td>-0.096065</td>\n      <td>0.222753</td>\n      <td>-0.139826</td>\n      <td>...</td>\n      <td>0.206409</td>\n      <td>0.015733</td>\n      <td>-0.066408</td>\n      <td>0.207632</td>\n      <td>0.100846</td>\n      <td>0.155602</td>\n      <td>-0.119655</td>\n      <td>0.334724</td>\n      <td>-0.077434</td>\n      <td>-0.052327</td>\n    </tr>\n    <tr>\n      <th>infiltrates of activated mast cells at the site of coronary atheromatous erosion or rupture in myocardial infarction</th>\n      <td>0.022739</td>\n      <td>0.032374</td>\n      <td>0.022658</td>\n      <td>0.175620</td>\n      <td>0.237818</td>\n      <td>0.028323</td>\n      <td>-0.108735</td>\n      <td>0.153267</td>\n      <td>-0.000503</td>\n      <td>-0.073391</td>\n      <td>...</td>\n      <td>-0.315328</td>\n      <td>0.048527</td>\n      <td>0.150879</td>\n      <td>0.068611</td>\n      <td>-0.012239</td>\n      <td>-0.052948</td>\n      <td>0.067608</td>\n      <td>0.007590</td>\n      <td>0.063753</td>\n      <td>0.111763</td>\n    </tr>\n    <tr>\n      <th>emotion classification based on biophysical signals and machine learning techniques</th>\n      <td>-0.012231</td>\n      <td>0.034326</td>\n      <td>0.088927</td>\n      <td>0.501120</td>\n      <td>-0.061734</td>\n      <td>0.009714</td>\n      <td>0.285312</td>\n      <td>-0.043306</td>\n      <td>0.061156</td>\n      <td>-0.030468</td>\n      <td>...</td>\n      <td>-0.112260</td>\n      <td>0.062733</td>\n      <td>0.085158</td>\n      <td>0.590207</td>\n      <td>-0.129694</td>\n      <td>-0.109371</td>\n      <td>0.192386</td>\n      <td>0.214314</td>\n      <td>-0.277618</td>\n      <td>-0.226808</td>\n    </tr>\n    <tr>\n      <th>a five-fold expansion of the global rna virome reveals multiple new clades of rna bacteriophages</th>\n      <td>-0.183117</td>\n      <td>0.126551</td>\n      <td>-0.121534</td>\n      <td>-0.214322</td>\n      <td>0.045312</td>\n      <td>0.063225</td>\n      <td>-0.236382</td>\n      <td>0.264796</td>\n      <td>0.013597</td>\n      <td>0.280727</td>\n      <td>...</td>\n      <td>-0.299533</td>\n      <td>0.231675</td>\n      <td>0.204877</td>\n      <td>-0.120191</td>\n      <td>0.050099</td>\n      <td>0.176836</td>\n      <td>-0.312004</td>\n      <td>-0.209475</td>\n      <td>0.294482</td>\n      <td>0.157108</td>\n    </tr>\n    <tr>\n      <th>the genetic sequence, origin, and diagnosis of sars-cov-2</th>\n      <td>0.071071</td>\n      <td>0.065747</td>\n      <td>-0.108173</td>\n      <td>0.025268</td>\n      <td>0.162468</td>\n      <td>-0.077258</td>\n      <td>-0.006693</td>\n      <td>0.167643</td>\n      <td>0.030059</td>\n      <td>-0.146180</td>\n      <td>...</td>\n      <td>-0.291222</td>\n      <td>0.141058</td>\n      <td>-0.145358</td>\n      <td>-0.005457</td>\n      <td>0.259224</td>\n      <td>0.180605</td>\n      <td>0.127763</td>\n      <td>-0.083994</td>\n      <td>-0.102171</td>\n      <td>-0.098668</td>\n    </tr>\n    <tr>\n      <th>how expressive are spectral-temporal graph neural networks for time series forecasting?</th>\n      <td>-0.410183</td>\n      <td>-0.003351</td>\n      <td>0.129728</td>\n      <td>-0.007543</td>\n      <td>0.007614</td>\n      <td>0.201268</td>\n      <td>-0.139217</td>\n      <td>-0.094568</td>\n      <td>-0.064717</td>\n      <td>-0.207120</td>\n      <td>...</td>\n      <td>0.323498</td>\n      <td>0.127689</td>\n      <td>-0.093046</td>\n      <td>-0.159796</td>\n      <td>-0.085574</td>\n      <td>-0.113382</td>\n      <td>-0.305407</td>\n      <td>0.083797</td>\n      <td>-0.087220</td>\n      <td>-0.202950</td>\n    </tr>\n    <tr>\n      <th>speech and speaker recognition from raw waveform with sincnet</th>\n      <td>-0.107646</td>\n      <td>-0.007173</td>\n      <td>0.077208</td>\n      <td>-0.041375</td>\n      <td>-0.225799</td>\n      <td>0.118387</td>\n      <td>-0.141102</td>\n      <td>-0.138133</td>\n      <td>0.129618</td>\n      <td>-0.196472</td>\n      <td>...</td>\n      <td>0.215038</td>\n      <td>0.221371</td>\n      <td>-0.097074</td>\n      <td>0.062158</td>\n      <td>0.171623</td>\n      <td>0.246033</td>\n      <td>-0.205998</td>\n      <td>0.249700</td>\n      <td>0.119858</td>\n      <td>-0.114164</td>\n    </tr>\n    <tr>\n      <th>emotion analysis in man-machine interaction systems</th>\n      <td>-0.342051</td>\n      <td>-0.014625</td>\n      <td>0.163226</td>\n      <td>0.011740</td>\n      <td>-0.236230</td>\n      <td>-0.126122</td>\n      <td>0.199178</td>\n      <td>-0.067926</td>\n      <td>-0.123946</td>\n      <td>-0.049873</td>\n      <td>...</td>\n      <td>-0.066962</td>\n      <td>0.184284</td>\n      <td>0.097915</td>\n      <td>0.115291</td>\n      <td>0.302319</td>\n      <td>0.203180</td>\n      <td>0.128122</td>\n      <td>0.228311</td>\n      <td>-0.225032</td>\n      <td>-0.050328</td>\n    </tr>\n    <tr>\n      <th>biomedical signal processing and control</th>\n      <td>-0.174253</td>\n      <td>0.110228</td>\n      <td>0.147513</td>\n      <td>0.069464</td>\n      <td>-0.344248</td>\n      <td>0.240459</td>\n      <td>-0.000388</td>\n      <td>-0.192025</td>\n      <td>0.059371</td>\n      <td>-0.091020</td>\n      <td>...</td>\n      <td>0.110846</td>\n      <td>0.171465</td>\n      <td>-0.072680</td>\n      <td>0.324185</td>\n      <td>0.053615</td>\n      <td>0.107069</td>\n      <td>-0.244899</td>\n      <td>0.217088</td>\n      <td>-0.136453</td>\n      <td>-0.334354</td>\n    </tr>\n    <tr>\n      <th>speech emotion analysis: exploring the role of context</th>\n      <td>-0.260448</td>\n      <td>-0.115763</td>\n      <td>0.060921</td>\n      <td>0.072361</td>\n      <td>0.003197</td>\n      <td>-0.011250</td>\n      <td>0.160649</td>\n      <td>0.110402</td>\n      <td>0.102621</td>\n      <td>0.034780</td>\n      <td>...</td>\n      <td>0.115744</td>\n      <td>0.108869</td>\n      <td>0.078513</td>\n      <td>0.228186</td>\n      <td>0.225899</td>\n      <td>0.043747</td>\n      <td>-0.016776</td>\n      <td>0.385448</td>\n      <td>-0.164617</td>\n      <td>0.066685</td>\n    </tr>\n    <tr>\n      <th>epidemiology, genetic recombination, and pathogenesis of coronaviruses</th>\n      <td>-0.140111</td>\n      <td>0.111081</td>\n      <td>-0.318208</td>\n      <td>0.007446</td>\n      <td>0.109339</td>\n      <td>-0.102005</td>\n      <td>-0.049281</td>\n      <td>0.154682</td>\n      <td>0.243224</td>\n      <td>-0.065193</td>\n      <td>...</td>\n      <td>-0.293126</td>\n      <td>0.064523</td>\n      <td>0.107462</td>\n      <td>-0.146291</td>\n      <td>0.337017</td>\n      <td>0.041781</td>\n      <td>0.131400</td>\n      <td>-0.049114</td>\n      <td>-0.227562</td>\n      <td>-0.002180</td>\n    </tr>\n    <tr>\n      <th>highly diverse and unknown viruses may enhance antarctic endoliths' adaptability</th>\n      <td>-0.196776</td>\n      <td>-0.110916</td>\n      <td>0.081952</td>\n      <td>0.208922</td>\n      <td>0.153547</td>\n      <td>0.085620</td>\n      <td>-0.063995</td>\n      <td>0.022959</td>\n      <td>0.019880</td>\n      <td>0.056753</td>\n      <td>...</td>\n      <td>-0.303771</td>\n      <td>0.057834</td>\n      <td>0.107738</td>\n      <td>0.000647</td>\n      <td>-0.091808</td>\n      <td>0.020936</td>\n      <td>-0.173423</td>\n      <td>-0.286831</td>\n      <td>0.117706</td>\n      <td>0.037596</td>\n    </tr>\n    <tr>\n      <th>jukebox: a generative model for music</th>\n      <td>0.061052</td>\n      <td>-0.080023</td>\n      <td>-0.090736</td>\n      <td>-0.164185</td>\n      <td>-0.341909</td>\n      <td>0.082541</td>\n      <td>-0.041563</td>\n      <td>-0.227455</td>\n      <td>0.098310</td>\n      <td>-0.019081</td>\n      <td>...</td>\n      <td>0.326686</td>\n      <td>0.114147</td>\n      <td>-0.023131</td>\n      <td>0.174258</td>\n      <td>0.357787</td>\n      <td>0.147165</td>\n      <td>-0.156991</td>\n      <td>0.067413</td>\n      <td>0.179363</td>\n      <td>-0.125200</td>\n    </tr>\n    <tr>\n      <th>speech emotion recognition from spectrograms with deep convolutional neural network</th>\n      <td>-0.266297</td>\n      <td>0.089480</td>\n      <td>0.050797</td>\n      <td>0.019209</td>\n      <td>-0.163504</td>\n      <td>0.302034</td>\n      <td>0.084427</td>\n      <td>-0.117726</td>\n      <td>0.036354</td>\n      <td>-0.007675</td>\n      <td>...</td>\n      <td>0.139583</td>\n      <td>0.145544</td>\n      <td>0.062644</td>\n      <td>0.262093</td>\n      <td>0.143037</td>\n      <td>0.020252</td>\n      <td>-0.132160</td>\n      <td>0.337679</td>\n      <td>-0.070738</td>\n      <td>-0.187084</td>\n    </tr>\n  </tbody>\n</table>\n<p>30 rows × 384 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_papers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T08:11:19.068950927Z",
     "start_time": "2023-05-13T08:11:19.031438250Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                         0         1    \\\nprovable guarantees for nonlinear feature learn... -0.082117  0.041908   \nan assessment of the human sortilin1 protein ne... -0.243293 -0.268495   \nporcine and human aortic valve endothelial and ... -0.001412 -0.125823   \nmulti-tier client selection for mobile federate... -0.031395  0.147354   \nnubo: a transparent python package for bayesian... -0.405352  0.048752   \ncardiovascular parameters in capitive blue-fron...  0.332830  0.186398   \ndeep multi-view subspace clustering with anchor... -0.015752 -0.025043   \nmultimodal integration -a statistical view         -0.235947  0.105067   \nbreakthrough: a first-in-class virtual simulato... -0.257704 -0.105994   \ncascaded cross-attention networks for data-effi... -0.154733  0.125601   \n\n                                                         2         3    \\\nprovable guarantees for nonlinear feature learn... -0.047545 -0.017843   \nan assessment of the human sortilin1 protein ne... -0.020671 -0.036869   \nporcine and human aortic valve endothelial and ... -0.085345  0.006269   \nmulti-tier client selection for mobile federate... -0.352972 -0.035094   \nnubo: a transparent python package for bayesian... -0.253816 -0.190668   \ncardiovascular parameters in capitive blue-fron... -0.017902 -0.044864   \ndeep multi-view subspace clustering with anchor... -0.045793 -0.132882   \nmultimodal integration -a statistical view          0.084915 -0.142468   \nbreakthrough: a first-in-class virtual simulato... -0.169664  0.188049   \ncascaded cross-attention networks for data-effi...  0.005631 -0.242891   \n\n                                                         4         5    \\\nprovable guarantees for nonlinear feature learn... -0.115768  0.108033   \nan assessment of the human sortilin1 protein ne...  0.106239  0.073969   \nporcine and human aortic valve endothelial and ... -0.102429 -0.111160   \nmulti-tier client selection for mobile federate...  0.425945  0.139995   \nnubo: a transparent python package for bayesian...  0.101280 -0.095346   \ncardiovascular parameters in capitive blue-fron... -0.156249 -0.093512   \ndeep multi-view subspace clustering with anchor... -0.137407  0.108172   \nmultimodal integration -a statistical view         -0.072994  0.070532   \nbreakthrough: a first-in-class virtual simulato... -0.013976  0.061377   \ncascaded cross-attention networks for data-effi...  0.059250 -0.101585   \n\n                                                         6         7    \\\nprovable guarantees for nonlinear feature learn... -0.127243 -0.103105   \nan assessment of the human sortilin1 protein ne... -0.002579  0.138554   \nporcine and human aortic valve endothelial and ... -0.050610  0.211069   \nmulti-tier client selection for mobile federate... -0.061197  0.126299   \nnubo: a transparent python package for bayesian...  0.082369  0.150243   \ncardiovascular parameters in capitive blue-fron...  0.055265 -0.023497   \ndeep multi-view subspace clustering with anchor... -0.425583 -0.085501   \nmultimodal integration -a statistical view         -0.023575  0.109995   \nbreakthrough: a first-in-class virtual simulato... -0.063839  0.356896   \ncascaded cross-attention networks for data-effi... -0.196746 -0.234586   \n\n                                                         8         9    ...  \\\nprovable guarantees for nonlinear feature learn... -0.120648 -0.257781  ...   \nan assessment of the human sortilin1 protein ne...  0.108629 -0.120708  ...   \nporcine and human aortic valve endothelial and ...  0.348672 -0.047409  ...   \nmulti-tier client selection for mobile federate...  0.084645  0.087236  ...   \nnubo: a transparent python package for bayesian... -0.208206  0.217534  ...   \ncardiovascular parameters in capitive blue-fron...  0.037588  0.161685  ...   \ndeep multi-view subspace clustering with anchor... -0.159145 -0.087801  ...   \nmultimodal integration -a statistical view          0.070256 -0.052924  ...   \nbreakthrough: a first-in-class virtual simulato...  0.378765 -0.009596  ...   \ncascaded cross-attention networks for data-effi... -0.025566 -0.109451  ...   \n\n                                                         374       375  \\\nprovable guarantees for nonlinear feature learn...  0.205132  0.191714   \nan assessment of the human sortilin1 protein ne... -0.318970 -0.142825   \nporcine and human aortic valve endothelial and ... -0.047278  0.121263   \nmulti-tier client selection for mobile federate...  0.216316 -0.156348   \nnubo: a transparent python package for bayesian...  0.073650  0.043185   \ncardiovascular parameters in capitive blue-fron... -0.370759  0.261011   \ndeep multi-view subspace clustering with anchor...  0.056323 -0.026788   \nmultimodal integration -a statistical view          0.152015  0.189288   \nbreakthrough: a first-in-class virtual simulato... -0.145519  0.076209   \ncascaded cross-attention networks for data-effi...  0.163367  0.151588   \n\n                                                         376       377  \\\nprovable guarantees for nonlinear feature learn... -0.080990 -0.087909   \nan assessment of the human sortilin1 protein ne... -0.042980  0.093280   \nporcine and human aortic valve endothelial and ... -0.006314  0.013009   \nmulti-tier client selection for mobile federate...  0.105378 -0.079847   \nnubo: a transparent python package for bayesian... -0.104434 -0.316946   \ncardiovascular parameters in capitive blue-fron...  0.157867 -0.195408   \ndeep multi-view subspace clustering with anchor...  0.131460  0.019156   \nmultimodal integration -a statistical view          0.059861 -0.085412   \nbreakthrough: a first-in-class virtual simulato... -0.055622 -0.070074   \ncascaded cross-attention networks for data-effi...  0.249048 -0.240682   \n\n                                                         378       379  \\\nprovable guarantees for nonlinear feature learn... -0.029269  0.013877   \nan assessment of the human sortilin1 protein ne... -0.036528 -0.098719   \nporcine and human aortic valve endothelial and ... -0.065745 -0.127206   \nmulti-tier client selection for mobile federate... -0.062678  0.149147   \nnubo: a transparent python package for bayesian...  0.129225  0.297025   \ncardiovascular parameters in capitive blue-fron... -0.074799 -0.086149   \ndeep multi-view subspace clustering with anchor...  0.003505  0.150168   \nmultimodal integration -a statistical view          0.146442  0.034173   \nbreakthrough: a first-in-class virtual simulato... -0.158146 -0.162314   \ncascaded cross-attention networks for data-effi...  0.373892  0.253640   \n\n                                                         380       381  \\\nprovable guarantees for nonlinear feature learn... -0.317632  0.085361   \nan assessment of the human sortilin1 protein ne...  0.078982  0.179944   \nporcine and human aortic valve endothelial and ... -0.239658  0.145553   \nmulti-tier client selection for mobile federate... -0.274124  0.191511   \nnubo: a transparent python package for bayesian... -0.352027  0.158195   \ncardiovascular parameters in capitive blue-fron...  0.290939  0.323250   \ndeep multi-view subspace clustering with anchor... -0.061166 -0.110449   \nmultimodal integration -a statistical view         -0.053101  0.300379   \nbreakthrough: a first-in-class virtual simulato...  0.123842  0.048102   \ncascaded cross-attention networks for data-effi... -0.069899 -0.012610   \n\n                                                         382       383  \nprovable guarantees for nonlinear feature learn... -0.089079 -0.117870  \nan assessment of the human sortilin1 protein ne...  0.359369  0.204902  \nporcine and human aortic valve endothelial and ...  0.214032  0.004931  \nmulti-tier client selection for mobile federate...  0.044713  0.082585  \nnubo: a transparent python package for bayesian... -0.114724  0.376048  \ncardiovascular parameters in capitive blue-fron... -0.117381  0.022721  \ndeep multi-view subspace clustering with anchor... -0.262170 -0.003181  \nmultimodal integration -a statistical view         -0.110512  0.046540  \nbreakthrough: a first-in-class virtual simulato...  0.083019  0.146946  \ncascaded cross-attention networks for data-effi... -0.083634  0.093548  \n\n[10 rows x 384 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>374</th>\n      <th>375</th>\n      <th>376</th>\n      <th>377</th>\n      <th>378</th>\n      <th>379</th>\n      <th>380</th>\n      <th>381</th>\n      <th>382</th>\n      <th>383</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>provable guarantees for nonlinear feature learning in three-layer neural networks</th>\n      <td>-0.082117</td>\n      <td>0.041908</td>\n      <td>-0.047545</td>\n      <td>-0.017843</td>\n      <td>-0.115768</td>\n      <td>0.108033</td>\n      <td>-0.127243</td>\n      <td>-0.103105</td>\n      <td>-0.120648</td>\n      <td>-0.257781</td>\n      <td>...</td>\n      <td>0.205132</td>\n      <td>0.191714</td>\n      <td>-0.080990</td>\n      <td>-0.087909</td>\n      <td>-0.029269</td>\n      <td>0.013877</td>\n      <td>-0.317632</td>\n      <td>0.085361</td>\n      <td>-0.089079</td>\n      <td>-0.117870</td>\n    </tr>\n    <tr>\n      <th>an assessment of the human sortilin1 protein network, its expression and targetability using small molecules</th>\n      <td>-0.243293</td>\n      <td>-0.268495</td>\n      <td>-0.020671</td>\n      <td>-0.036869</td>\n      <td>0.106239</td>\n      <td>0.073969</td>\n      <td>-0.002579</td>\n      <td>0.138554</td>\n      <td>0.108629</td>\n      <td>-0.120708</td>\n      <td>...</td>\n      <td>-0.318970</td>\n      <td>-0.142825</td>\n      <td>-0.042980</td>\n      <td>0.093280</td>\n      <td>-0.036528</td>\n      <td>-0.098719</td>\n      <td>0.078982</td>\n      <td>0.179944</td>\n      <td>0.359369</td>\n      <td>0.204902</td>\n    </tr>\n    <tr>\n      <th>porcine and human aortic valve endothelial and interstitial cell isolation and characterization</th>\n      <td>-0.001412</td>\n      <td>-0.125823</td>\n      <td>-0.085345</td>\n      <td>0.006269</td>\n      <td>-0.102429</td>\n      <td>-0.111160</td>\n      <td>-0.050610</td>\n      <td>0.211069</td>\n      <td>0.348672</td>\n      <td>-0.047409</td>\n      <td>...</td>\n      <td>-0.047278</td>\n      <td>0.121263</td>\n      <td>-0.006314</td>\n      <td>0.013009</td>\n      <td>-0.065745</td>\n      <td>-0.127206</td>\n      <td>-0.239658</td>\n      <td>0.145553</td>\n      <td>0.214032</td>\n      <td>0.004931</td>\n    </tr>\n    <tr>\n      <th>multi-tier client selection for mobile federated learning networks</th>\n      <td>-0.031395</td>\n      <td>0.147354</td>\n      <td>-0.352972</td>\n      <td>-0.035094</td>\n      <td>0.425945</td>\n      <td>0.139995</td>\n      <td>-0.061197</td>\n      <td>0.126299</td>\n      <td>0.084645</td>\n      <td>0.087236</td>\n      <td>...</td>\n      <td>0.216316</td>\n      <td>-0.156348</td>\n      <td>0.105378</td>\n      <td>-0.079847</td>\n      <td>-0.062678</td>\n      <td>0.149147</td>\n      <td>-0.274124</td>\n      <td>0.191511</td>\n      <td>0.044713</td>\n      <td>0.082585</td>\n    </tr>\n    <tr>\n      <th>nubo: a transparent python package for bayesian optimisation</th>\n      <td>-0.405352</td>\n      <td>0.048752</td>\n      <td>-0.253816</td>\n      <td>-0.190668</td>\n      <td>0.101280</td>\n      <td>-0.095346</td>\n      <td>0.082369</td>\n      <td>0.150243</td>\n      <td>-0.208206</td>\n      <td>0.217534</td>\n      <td>...</td>\n      <td>0.073650</td>\n      <td>0.043185</td>\n      <td>-0.104434</td>\n      <td>-0.316946</td>\n      <td>0.129225</td>\n      <td>0.297025</td>\n      <td>-0.352027</td>\n      <td>0.158195</td>\n      <td>-0.114724</td>\n      <td>0.376048</td>\n    </tr>\n    <tr>\n      <th>cardiovascular parameters in capitive blue-fronted amazon parrots (amazona aestiva, linnaeus, 1758) with varying body condition scores</th>\n      <td>0.332830</td>\n      <td>0.186398</td>\n      <td>-0.017902</td>\n      <td>-0.044864</td>\n      <td>-0.156249</td>\n      <td>-0.093512</td>\n      <td>0.055265</td>\n      <td>-0.023497</td>\n      <td>0.037588</td>\n      <td>0.161685</td>\n      <td>...</td>\n      <td>-0.370759</td>\n      <td>0.261011</td>\n      <td>0.157867</td>\n      <td>-0.195408</td>\n      <td>-0.074799</td>\n      <td>-0.086149</td>\n      <td>0.290939</td>\n      <td>0.323250</td>\n      <td>-0.117381</td>\n      <td>0.022721</td>\n    </tr>\n    <tr>\n      <th>deep multi-view subspace clustering with anchor graph</th>\n      <td>-0.015752</td>\n      <td>-0.025043</td>\n      <td>-0.045793</td>\n      <td>-0.132882</td>\n      <td>-0.137407</td>\n      <td>0.108172</td>\n      <td>-0.425583</td>\n      <td>-0.085501</td>\n      <td>-0.159145</td>\n      <td>-0.087801</td>\n      <td>...</td>\n      <td>0.056323</td>\n      <td>-0.026788</td>\n      <td>0.131460</td>\n      <td>0.019156</td>\n      <td>0.003505</td>\n      <td>0.150168</td>\n      <td>-0.061166</td>\n      <td>-0.110449</td>\n      <td>-0.262170</td>\n      <td>-0.003181</td>\n    </tr>\n    <tr>\n      <th>multimodal integration -a statistical view</th>\n      <td>-0.235947</td>\n      <td>0.105067</td>\n      <td>0.084915</td>\n      <td>-0.142468</td>\n      <td>-0.072994</td>\n      <td>0.070532</td>\n      <td>-0.023575</td>\n      <td>0.109995</td>\n      <td>0.070256</td>\n      <td>-0.052924</td>\n      <td>...</td>\n      <td>0.152015</td>\n      <td>0.189288</td>\n      <td>0.059861</td>\n      <td>-0.085412</td>\n      <td>0.146442</td>\n      <td>0.034173</td>\n      <td>-0.053101</td>\n      <td>0.300379</td>\n      <td>-0.110512</td>\n      <td>0.046540</td>\n    </tr>\n    <tr>\n      <th>breakthrough: a first-in-class virtual simulator for dose optimization of ace inhibitors in veterinary cardiology</th>\n      <td>-0.257704</td>\n      <td>-0.105994</td>\n      <td>-0.169664</td>\n      <td>0.188049</td>\n      <td>-0.013976</td>\n      <td>0.061377</td>\n      <td>-0.063839</td>\n      <td>0.356896</td>\n      <td>0.378765</td>\n      <td>-0.009596</td>\n      <td>...</td>\n      <td>-0.145519</td>\n      <td>0.076209</td>\n      <td>-0.055622</td>\n      <td>-0.070074</td>\n      <td>-0.158146</td>\n      <td>-0.162314</td>\n      <td>0.123842</td>\n      <td>0.048102</td>\n      <td>0.083019</td>\n      <td>0.146946</td>\n    </tr>\n    <tr>\n      <th>cascaded cross-attention networks for data-efficient whole-slide image classification using transformers</th>\n      <td>-0.154733</td>\n      <td>0.125601</td>\n      <td>0.005631</td>\n      <td>-0.242891</td>\n      <td>0.059250</td>\n      <td>-0.101585</td>\n      <td>-0.196746</td>\n      <td>-0.234586</td>\n      <td>-0.025566</td>\n      <td>-0.109451</td>\n      <td>...</td>\n      <td>0.163367</td>\n      <td>0.151588</td>\n      <td>0.249048</td>\n      <td>-0.240682</td>\n      <td>0.373892</td>\n      <td>0.253640</td>\n      <td>-0.069899</td>\n      <td>-0.012610</td>\n      <td>-0.083634</td>\n      <td>0.093548</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 384 columns</p>\n</div>"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_encoded_papers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T21:54:17.210864222Z",
     "start_time": "2023-05-12T21:54:17.208905700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "a note on the evaluation of generative models                                                                           -1\nspectral clustering on large datasets: when does it work? theory from continuous clustering and density cheeger-buser   -1\nattributing emotion to static body postures: recognition accuracy, confusions, and viewpoint dependence                 -1\nadversarial multi-task learning for text classification                                                                 -1\nadam: a method for stochastic optimization                                                                              -1\ndo deep generative models know what they don't know?                                                                    -1\nact1 adaptor protein is an immediate and essential signaling component of interleukin-17 receptor *                      0\ngradient surgery for multi-task learning                                                                                -1\nauxiliary deep generative models                                                                                        -1\ninterleukin-17 contributes to cardiovascular diseases                                                                    0\nactive learning in the predict-then-optimize framework: a margin-based approach                                         -1\nlearning deep generative models                                                                                         -1\nchurch: a language for generative models                                                                                -1\naffective multimodal human-computer interaction                                                                         -1\nbi-modal emotion recognition from expressive face and body gestures                                                     -1\nphylogenetic diversity of animal oral and gastrointestinal viromes useful in surveillance of zoonoses                   -1\nefficient emotion recognition from speech using deep learning on spectrograms                                           -1\ninfiltrates of activated mast cells at the site of coronary atheromatous erosion or rupture in myocardial infarction    -1\nemotion classification based on biophysical signals and machine learning techniques                                     -1\na five-fold expansion of the global rna virome reveals multiple new clades of rna bacteriophages                        -1\nthe genetic sequence, origin, and diagnosis of sars-cov-2                                                               -1\nhow expressive are spectral-temporal graph neural networks for time series forecasting?                                 -1\nspeech and speaker recognition from raw waveform with sincnet                                                           -1\nemotion analysis in man-machine interaction systems                                                                     -1\nbiomedical signal processing and control                                                                                -1\nspeech emotion analysis: exploring the role of context                                                                  -1\nepidemiology, genetic recombination, and pathogenesis of coronaviruses                                                  -1\nhighly diverse and unknown viruses may enhance antarctic endoliths' adaptability                                        -1\njukebox: a generative model for music                                                                                   -1\nspeech emotion recognition from spectrograms with deep convolutional neural network                                     -1\ndtype: int64"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "spcluster = DBSCAN(eps=0.15, min_samples=2, metric='cosine')\n",
    "labels = spcluster.fit_predict(encoded_papers)\n",
    "pd.Series(labels, index=encoded_papers.index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T21:37:24.848272668Z",
     "start_time": "2023-05-12T21:37:24.843260147Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.17516641, 0.9483440986850478, 3.037260955602544)"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "sil_train = silhouette_score(encoded_papers, labels)\n",
    "davies_train = davies_bouldin_score(encoded_papers, labels)\n",
    "cal_train = calinski_harabasz_score(encoded_papers, labels)\n",
    "sil_train, davies_train, cal_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T21:37:26.923735745Z",
     "start_time": "2023-05-12T21:37:26.895107253Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "provable guarantees for nonlinear feature learning in three-layer neural networks                                                        -1\nan assessment of the human sortilin1 protein network, its expression and targetability using small molecules                             -1\nporcine and human aortic valve endothelial and interstitial cell isolation and characterization                                          -1\nmulti-tier client selection for mobile federated learning networks                                                                       -1\nnubo: a transparent python package for bayesian optimisation                                                                             -1\ncardiovascular parameters in capitive blue-fronted amazon parrots (amazona aestiva, linnaeus, 1758) with varying body condition scores   -1\ndeep multi-view subspace clustering with anchor graph                                                                                    -1\nmultimodal integration -a statistical view                                                                                               -1\nbreakthrough: a first-in-class virtual simulator for dose optimization of ace inhibitors in veterinary cardiology                        -1\ncascaded cross-attention networks for data-efficient whole-slide image classification using transformers                                 -1\ndtype: int64"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "spcluster = DBSCAN(eps=0.15, min_samples=2, metric='cosine')\n",
    "labels = spcluster.fit_predict(val_encoded_papers)\n",
    "pd.Series(labels, index=val_encoded_papers.index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T21:55:56.378581890Z",
     "start_time": "2023-05-12T21:55:56.366124497Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[94], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m silhouette_score, davies_bouldin_score, calinski_harabasz_score\n\u001B[0;32m----> 3\u001B[0m sil_train \u001B[38;5;241m=\u001B[39m \u001B[43msilhouette_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mval_encoded_papers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m davies_train \u001B[38;5;241m=\u001B[39m davies_bouldin_score(val_encoded_papers, labels)\n\u001B[1;32m      5\u001B[0m cal_train \u001B[38;5;241m=\u001B[39m calinski_harabasz_score(val_encoded_papers, labels)\n",
      "File \u001B[0;32m~/anaconda3/envs/opensciencegroup/lib/python3.9/site-packages/sklearn/metrics/cluster/_unsupervised.py:117\u001B[0m, in \u001B[0;36msilhouette_score\u001B[0;34m(X, labels, metric, sample_size, random_state, **kwds)\u001B[0m\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    116\u001B[0m         X, labels \u001B[38;5;241m=\u001B[39m X[indices], labels[indices]\n\u001B[0;32m--> 117\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mmean(\u001B[43msilhouette_samples\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/anaconda3/envs/opensciencegroup/lib/python3.9/site-packages/sklearn/metrics/cluster/_unsupervised.py:227\u001B[0m, in \u001B[0;36msilhouette_samples\u001B[0;34m(X, labels, metric, **kwds)\u001B[0m\n\u001B[1;32m    225\u001B[0m n_samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(labels)\n\u001B[1;32m    226\u001B[0m label_freqs \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mbincount(labels)\n\u001B[0;32m--> 227\u001B[0m \u001B[43mcheck_number_of_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclasses_\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_samples\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    229\u001B[0m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetric\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m metric\n\u001B[1;32m    230\u001B[0m reduce_func \u001B[38;5;241m=\u001B[39m functools\u001B[38;5;241m.\u001B[39mpartial(\n\u001B[1;32m    231\u001B[0m     _silhouette_reduce, labels\u001B[38;5;241m=\u001B[39mlabels, label_freqs\u001B[38;5;241m=\u001B[39mlabel_freqs\n\u001B[1;32m    232\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/opensciencegroup/lib/python3.9/site-packages/sklearn/metrics/cluster/_unsupervised.py:33\u001B[0m, in \u001B[0;36mcheck_number_of_labels\u001B[0;34m(n_labels, n_samples)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Check that number of labels are valid.\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \n\u001B[1;32m     24\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;124;03m    Number of samples.\u001B[39;00m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m<\u001B[39m n_labels \u001B[38;5;241m<\u001B[39m n_samples:\n\u001B[0;32m---> 33\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     34\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of labels is \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. Valid values are 2 to n_samples - 1 (inclusive)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     35\u001B[0m         \u001B[38;5;241m%\u001B[39m n_labels\n\u001B[1;32m     36\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "sil_train = silhouette_score(val_encoded_papers, labels)\n",
    "davies_train = davies_bouldin_score(val_encoded_papers, labels)\n",
    "cal_train = calinski_harabasz_score(val_encoded_papers, labels)\n",
    "sil_train, davies_train, cal_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T21:57:53.123435692Z",
     "start_time": "2023-05-12T21:57:53.097104973Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Esto lo dice todo :)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "clustering = AgglomerativeClustering(n_clusters=2, affinity='cosine', linkage='complete')\n",
    "labels = clustering.fit_predict(encoded_papers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T07:48:40.978609049Z",
     "start_time": "2023-05-13T07:48:40.384207948Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "assined_papers = pd.Series(labels, index=encoded_papers.index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T07:49:43.943545039Z",
     "start_time": "2023-05-13T07:49:43.931074646Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.188751, 2.052638468670523, 5.44873122951165)"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "sil_train = silhouette_score(encoded_papers, labels)\n",
    "davies_train = davies_bouldin_score(encoded_papers, labels)\n",
    "cal_train = calinski_harabasz_score(encoded_papers, labels)\n",
    "sil_train, davies_train, cal_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T21:37:56.186258815Z",
     "start_time": "2023-05-12T21:37:56.080746223Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "provable guarantees for nonlinear feature learning in three-layer neural networks                                                         1\nan assessment of the human sortilin1 protein network, its expression and targetability using small molecules                              0\nporcine and human aortic valve endothelial and interstitial cell isolation and characterization                                           0\nmulti-tier client selection for mobile federated learning networks                                                                        1\nnubo: a transparent python package for bayesian optimisation                                                                              1\ncardiovascular parameters in capitive blue-fronted amazon parrots (amazona aestiva, linnaeus, 1758) with varying body condition scores    0\ndeep multi-view subspace clustering with anchor graph                                                                                     1\nmultimodal integration -a statistical view                                                                                                1\nbreakthrough: a first-in-class virtual simulator for dose optimization of ace inhibitors in veterinary cardiology                         0\ncascaded cross-attention networks for data-efficient whole-slide image classification using transformers                                  1\ndtype: int64"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "clustering = AgglomerativeClustering(n_clusters=2, affinity='cosine', linkage='complete')\n",
    "labels = clustering.fit_predict(val_encoded_papers)\n",
    "pd.Series(labels, index=val_encoded_papers.index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T21:54:27.202417769Z",
     "start_time": "2023-05-12T21:54:27.200079891Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.11765595, 1.8036050420727296, 2.3230615272762227)"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "sil_train = silhouette_score(val_encoded_papers, labels)\n",
    "davies_train = davies_bouldin_score(val_encoded_papers, labels)\n",
    "cal_train = calinski_harabasz_score(val_encoded_papers, labels)\n",
    "sil_train, davies_train, cal_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T21:55:16.504567183Z",
     "start_time": "2023-05-12T21:55:16.497978262Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mejores resultados obtenidos con AgglomerativeClustering y dos clusters. Tiene sentido dado que nuestro conjunto de papers se compone por papers de biología y papers de ingeniería informática. Aunque existen subtemas como el speech recognition, cardiovascular deseases o virus, resulta lógico que la mayor separabilidad se obtenga con estos dos clusters. Aun así, observamos un coeficiente de silueta relativamente bajo.\n",
    "\n",
    "Si asignáramos etiquetas reales a los papers, habríamos obtenido un 100% de accuracy en ambos conjuntos de datos."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/dani/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/dani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text into individual words\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words from the token list\n",
    "    filtered_tokens = [word for word in tokens if not word.lower() in stop_words]\n",
    "    # Join the remaining tokens back into a single string\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "df = pd.DataFrame([{'Title': paper.title, \"abstract\": preprocess_text(paper.abstract), 'label': assined_papers.loc[paper.title] } for paper in paper_space.get_xml_papers().values()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T08:10:21.553723530Z",
     "start_time": "2023-05-13T08:10:21.506115984Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               Title  \\\n0      a note on the evaluation of generative models   \n1  spectral clustering on large datasets: when do...   \n2  attributing emotion to static body postures: r...   \n3  adversarial multi-task learning for text class...   \n4         adam: a method for stochastic optimization   \n\n                                            abstract  label  \n0  Probabilistic generative models used compressi...      1  \n1  Spectral clustering one popular clustering alg...      1  \n2  total 176 computer-generated mannequin figures...      1  \n3  Neural network models shown promising opportun...      1  \n4  introduce Adam , algorithm first-order gradien...      1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>abstract</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a note on the evaluation of generative models</td>\n      <td>Probabilistic generative models used compressi...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>spectral clustering on large datasets: when do...</td>\n      <td>Spectral clustering one popular clustering alg...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>attributing emotion to static body postures: r...</td>\n      <td>total 176 computer-generated mannequin figures...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>adversarial multi-task learning for text class...</td>\n      <td>Neural network models shown promising opportun...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>adam: a method for stochastic optimization</td>\n      <td>introduce Adam , algorithm first-order gradien...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T08:10:23.328008806Z",
     "start_time": "2023-05-13T08:10:23.323467665Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "tokens = vectorizer.fit_transform(df['abstract'])\n",
    "tokens.index = df['Title']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T09:10:33.747560576Z",
     "start_time": "2023-05-13T09:10:33.742076641Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "0       (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n1       (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n2       (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n3       (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n4       (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n5       (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n6       (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n7       (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n8       (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n9       (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n10      (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n11      (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n12      (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n13      (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n14      (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n15      (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n16      (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n17      (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n18      (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n19      (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n20      (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n21      (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n22      (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n23      (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n24      (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n25      (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n26      (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n27      (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n28      (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\n29      (0, 1213)\\t1\\n  (0, 712)\\t3\\n  (0, 1015)\\t6\\...\nName: tokenized, dtype: object"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tokenized"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T09:10:26.381287767Z",
     "start_time": "2023-05-13T09:10:26.340598486Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "['spectral', 'data', 'clustering', 'density', 'inputs', 'drawn', 'models', 'distribution', 'graph', 'sets']\n",
      "\n",
      "Topic 1:\n",
      "['learning', 'task', 'multi', 'models', 'tasks', 'spo', 'approach', 'data', 'gradient', 'loss']\n",
      "\n",
      "Topic 2:\n",
      "['model', 'using', 'audio', 'singing', 'raw', 'make', 'modeling', 'combined', 'high', 'show']\n",
      "\n",
      "Topic 3:\n",
      "['il', '17', 'receptor', 'deep', 'signaling', 'act1', 'many', 'high', 'family', 'including']\n",
      "\n",
      "Topic 4:\n",
      "['cov', 'human', 'respiratory', 'virus', 'viruses', 'outbreaks', 'emotion', 'humans', 'dogs', 'animals']\n",
      "\n",
      "Topic 5:\n",
      "['speech', 'network', 'cells', 'cnn', 'neural', 'lstm', 'recognition', 'networks', 'deep', 'mast']\n",
      "\n",
      "Topic 6:\n",
      "['generative', 'postures', 'deep', 'emotions', 'variables', 'models', 'auxiliary', 'anger', 'state', 'performance']\n",
      "\n",
      "Topic 7:\n",
      "['based', 'sars', 'coronavirus', 'cov', 'church', 'temporal', 'methods', 'stochastic', 'non', 'adam']\n",
      "\n",
      "Topic 8:\n",
      "['communities', 'viral', 'catalog', 'largely', 'spatial', 'diversity', 'predicted', 'microbial', 'ecology', 'antarctic']\n",
      "\n",
      "Topic 9:\n",
      "['based', 'analysis', 'database', 'recognition', 'body', 'face', 'use', 'two', 'information', 'human']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dani/anaconda3/envs/opensciencegroup/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "num_topics = 10\n",
    "lda_model = LatentDirichletAllocation(n_components=num_topics, max_iter=100, learning_method='online')\n",
    "lda_model.fit(tokens)\n",
    "\n",
    "# Print the top words for each topic\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "for topic_idx, topic in enumerate(lda_model.components_):\n",
    "    print(f\"Topic {topic_idx}:\")\n",
    "    top_words_idx = topic.argsort()[:-11:-1]\n",
    "    top_words = [feature_names[i] for i in top_words_idx]\n",
    "    print(top_words)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T09:10:36.818347520Z",
     "start_time": "2023-05-13T09:10:35.519391173Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[6.89700874e-04, 6.89655203e-04, 6.89701568e-04, 6.89688147e-04,\n        6.89705689e-04, 6.89696944e-04, 6.89688351e-04, 9.93792779e-01,\n        6.89721654e-04, 6.89662658e-04]])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.transform(tokens[10])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T08:36:29.550551891Z",
     "start_time": "2023-05-13T08:36:29.547455964Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "n_topics = 10\n",
    "\n",
    "gensim_model = gensim.models.ldamodel.LdaModel(\n",
    "    corpus=None,\n",
    "    id2word={i: word for i, word in enumerate(vectorizer.get_feature_names_out())},\n",
    "    num_topics=n_topics,\n",
    "    alpha='auto',\n",
    "    eta=lda_model.components_ / lda_model.components_.sum(axis=1)[:, np.newaxis],  # Use the topic-word matrix as input for the Gensim model\n",
    "    iterations=100,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T09:10:53.071589905Z",
     "start_time": "2023-05-13T09:10:53.067364578Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence score: -0.62\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.models import LdaMulticore\n",
    "preprocessed_documents = []\n",
    "for document in df.abstract:\n",
    "    tokens = vectorizer.get_feature_names_out()\n",
    "    preprocessed_documents.append(tokens)\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(preprocessed_documents)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in preprocessed_documents]\n",
    "\n",
    "lda_model = gensim.models.LdaModel(corpus=corpus, num_topics=2, id2word=dictionary, passes=10)\n",
    "coherence_model = gensim.models.CoherenceModel(model=lda_model, texts=preprocessed_documents, dictionary=dictionary, coherence='c_npmi')\n",
    "coherence_score = coherence_model.get_coherence()\n",
    "print(f\"Coherence score: {coherence_score:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T09:10:56.777006227Z",
     "start_time": "2023-05-13T09:10:54.927174840Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "\"Part of this work was done when the first author worked in Advanced Analytics Institute (AAI), University of Technology, Sydney as a visiting scholar. Jianfeng Zhao, Xia Mao, and Lijiang Chen's work in this paper was supported in part by the National Natural Science Foundation of China under Grant No. 61603013. This article recently received funding from the Fundamental Research Funds for the Central Universities (Grant No. YWF-18-BJ-Y-181).\""
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(paper_space.get_xml_papers().values())[24].acknowledgements.text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T09:49:05.010935102Z",
     "start_time": "2023-05-13T09:49:05.009087990Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For NER, we tried various models, but the best results were obtained with the following model:\n",
    "Babelscape/wikineural-multilingual-ner\n",
    "\n",
    "which was best able to recognize foreign names, for every other entity it performed similarly to the other models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/wikineural-multilingual-ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Babelscape/wikineural-multilingual-ner\")\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T10:27:11.433927787Z",
     "start_time": "2023-05-13T10:27:09.600536355Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "text = list(paper_space.get_xml_papers().values())[24].acknowledgements.text\n",
    "ner_results = nlp(text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T10:27:14.987532797Z",
     "start_time": "2023-05-13T10:27:11.435087257Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"entity\": \"B-ORG\",\n",
      "    \"score\": \"0.99798715\",\n",
      "    \"index\": 13,\n",
      "    \"word\": \"Advanced\",\n",
      "    \"start\": 59,\n",
      "    \"end\": 67\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-ORG\",\n",
      "    \"score\": \"0.9962837\",\n",
      "    \"index\": 14,\n",
      "    \"word\": \"Ana\",\n",
      "    \"start\": 68,\n",
      "    \"end\": 71\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-ORG\",\n",
      "    \"score\": \"0.9973973\",\n",
      "    \"index\": 15,\n",
      "    \"word\": \"##ly\",\n",
      "    \"start\": 71,\n",
      "    \"end\": 73\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-ORG\",\n",
      "    \"score\": \"0.99747133\",\n",
      "    \"index\": 16,\n",
      "    \"word\": \"##tics\",\n",
      "    \"start\": 73,\n",
      "    \"end\": 77\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-ORG\",\n",
      "    \"score\": \"0.9977435\",\n",
      "    \"index\": 17,\n",
      "    \"word\": \"Institute\",\n",
      "    \"start\": 78,\n",
      "    \"end\": 87\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"B-ORG\",\n",
      "    \"score\": \"0.90609896\",\n",
      "    \"index\": 19,\n",
      "    \"word\": \"AA\",\n",
      "    \"start\": 89,\n",
      "    \"end\": 91\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-ORG\",\n",
      "    \"score\": \"0.8466319\",\n",
      "    \"index\": 20,\n",
      "    \"word\": \"##I\",\n",
      "    \"start\": 91,\n",
      "    \"end\": 92\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"B-ORG\",\n",
      "    \"score\": \"0.9973616\",\n",
      "    \"index\": 23,\n",
      "    \"word\": \"University\",\n",
      "    \"start\": 95,\n",
      "    \"end\": 105\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-ORG\",\n",
      "    \"score\": \"0.99739194\",\n",
      "    \"index\": 24,\n",
      "    \"word\": \"of\",\n",
      "    \"start\": 106,\n",
      "    \"end\": 108\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-ORG\",\n",
      "    \"score\": \"0.9974075\",\n",
      "    \"index\": 25,\n",
      "    \"word\": \"Technology\",\n",
      "    \"start\": 109,\n",
      "    \"end\": 119\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"B-LOC\",\n",
      "    \"score\": \"0.91954446\",\n",
      "    \"index\": 27,\n",
      "    \"word\": \"Sydney\",\n",
      "    \"start\": 121,\n",
      "    \"end\": 127\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"B-PER\",\n",
      "    \"score\": \"0.9996728\",\n",
      "    \"index\": 33,\n",
      "    \"word\": \"Ji\",\n",
      "    \"start\": 151,\n",
      "    \"end\": 153\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-PER\",\n",
      "    \"score\": \"0.9764715\",\n",
      "    \"index\": 34,\n",
      "    \"word\": \"##an\",\n",
      "    \"start\": 153,\n",
      "    \"end\": 155\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-PER\",\n",
      "    \"score\": \"0.9972574\",\n",
      "    \"index\": 35,\n",
      "    \"word\": \"##fen\",\n",
      "    \"start\": 155,\n",
      "    \"end\": 158\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-PER\",\n",
      "    \"score\": \"0.99732506\",\n",
      "    \"index\": 36,\n",
      "    \"word\": \"##g\",\n",
      "    \"start\": 158,\n",
      "    \"end\": 159\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-PER\",\n",
      "    \"score\": \"0.9996105\",\n",
      "    \"index\": 37,\n",
      "    \"word\": \"Zhao\",\n",
      "    \"start\": 160,\n",
      "    \"end\": 164\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"B-PER\",\n",
      "    \"score\": \"0.999694\",\n",
      "    \"index\": 39,\n",
      "    \"word\": \"Xi\",\n",
      "    \"start\": 166,\n",
      "    \"end\": 168\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-PER\",\n",
      "    \"score\": \"0.9934331\",\n",
      "    \"index\": 40,\n",
      "    \"word\": \"##a\",\n",
      "    \"start\": 168,\n",
      "    \"end\": 169\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-PER\",\n",
      "    \"score\": \"0.99967813\",\n",
      "    \"index\": 41,\n",
      "    \"word\": \"Mao\",\n",
      "    \"start\": 170,\n",
      "    \"end\": 173\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"B-PER\",\n",
      "    \"score\": \"0.9992901\",\n",
      "    \"index\": 44,\n",
      "    \"word\": \"Li\",\n",
      "    \"start\": 179,\n",
      "    \"end\": 181\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-PER\",\n",
      "    \"score\": \"0.8227962\",\n",
      "    \"index\": 45,\n",
      "    \"word\": \"##jian\",\n",
      "    \"start\": 181,\n",
      "    \"end\": 185\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-PER\",\n",
      "    \"score\": \"0.9936919\",\n",
      "    \"index\": 46,\n",
      "    \"word\": \"##g\",\n",
      "    \"start\": 185,\n",
      "    \"end\": 186\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-PER\",\n",
      "    \"score\": \"0.99914956\",\n",
      "    \"index\": 47,\n",
      "    \"word\": \"Chen\",\n",
      "    \"start\": 187,\n",
      "    \"end\": 191\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"B-ORG\",\n",
      "    \"score\": \"0.99603844\",\n",
      "    \"index\": 60,\n",
      "    \"word\": \"National\",\n",
      "    \"start\": 242,\n",
      "    \"end\": 250\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-ORG\",\n",
      "    \"score\": \"0.99566674\",\n",
      "    \"index\": 61,\n",
      "    \"word\": \"Natural\",\n",
      "    \"start\": 251,\n",
      "    \"end\": 258\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-ORG\",\n",
      "    \"score\": \"0.996766\",\n",
      "    \"index\": 62,\n",
      "    \"word\": \"Science\",\n",
      "    \"start\": 259,\n",
      "    \"end\": 266\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-ORG\",\n",
      "    \"score\": \"0.99636215\",\n",
      "    \"index\": 63,\n",
      "    \"word\": \"Foundation\",\n",
      "    \"start\": 267,\n",
      "    \"end\": 277\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-ORG\",\n",
      "    \"score\": \"0.98774475\",\n",
      "    \"index\": 64,\n",
      "    \"word\": \"of\",\n",
      "    \"start\": 278,\n",
      "    \"end\": 280\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-ORG\",\n",
      "    \"score\": \"0.9805039\",\n",
      "    \"index\": 65,\n",
      "    \"word\": \"China\",\n",
      "    \"start\": 281,\n",
      "    \"end\": 286\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"B-ORG\",\n",
      "    \"score\": \"0.9968245\",\n",
      "    \"index\": 82,\n",
      "    \"word\": \"Fund\",\n",
      "    \"start\": 361,\n",
      "    \"end\": 365\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-ORG\",\n",
      "    \"score\": \"0.9959157\",\n",
      "    \"index\": 83,\n",
      "    \"word\": \"##amental\",\n",
      "    \"start\": 365,\n",
      "    \"end\": 372\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-ORG\",\n",
      "    \"score\": \"0.99682754\",\n",
      "    \"index\": 84,\n",
      "    \"word\": \"Research\",\n",
      "    \"start\": 373,\n",
      "    \"end\": 381\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-ORG\",\n",
      "    \"score\": \"0.9977642\",\n",
      "    \"index\": 85,\n",
      "    \"word\": \"Fund\",\n",
      "    \"start\": 382,\n",
      "    \"end\": 386\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-ORG\",\n",
      "    \"score\": \"0.99780756\",\n",
      "    \"index\": 86,\n",
      "    \"word\": \"##s\",\n",
      "    \"start\": 386,\n",
      "    \"end\": 387\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-ORG\",\n",
      "    \"score\": \"0.99764854\",\n",
      "    \"index\": 87,\n",
      "    \"word\": \"for\",\n",
      "    \"start\": 388,\n",
      "    \"end\": 391\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-ORG\",\n",
      "    \"score\": \"0.996786\",\n",
      "    \"index\": 88,\n",
      "    \"word\": \"the\",\n",
      "    \"start\": 392,\n",
      "    \"end\": 395\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-ORG\",\n",
      "    \"score\": \"0.9967039\",\n",
      "    \"index\": 89,\n",
      "    \"word\": \"Central\",\n",
      "    \"start\": 396,\n",
      "    \"end\": 403\n",
      "  },\n",
      "  {\n",
      "    \"entity\": \"I-ORG\",\n",
      "    \"score\": \"0.9959579\",\n",
      "    \"index\": 90,\n",
      "    \"word\": \"Universities\",\n",
      "    \"start\": 404,\n",
      "    \"end\": 416\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(ner_results, indent=2, default=str))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T10:27:55.225178776Z",
     "start_time": "2023-05-13T10:27:55.218800539Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'entity': 'ORG', 'text': 'Advanced Analytics Institute'},\n {'entity': 'ORG', 'text': 'AAI'},\n {'entity': 'ORG', 'text': 'University of Technology'},\n {'entity': 'PER', 'text': 'Jianfeng Zhao'},\n {'entity': 'PER', 'text': 'Xia Mao'},\n {'entity': 'PER', 'text': 'Lijiang Chen'},\n {'entity': 'ORG', 'text': 'National Natural Science Foundation of China'},\n {'entity': 'ORG',\n  'text': 'Fundamental Research Funds for the Central Universities'}]"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_entities(entities, text):\n",
    "    # initialize variables\n",
    "    org_start = None\n",
    "    org_end = None\n",
    "    people_start = None\n",
    "    people_end = None\n",
    "    new_entities = []\n",
    "\n",
    "    for i, entity in enumerate(entities):\n",
    "        # check if entity is an organization\n",
    "        if entity['entity'] == 'B-ORG':\n",
    "            org_start = entity['start']\n",
    "            org_end = entity['end']\n",
    "        elif entity['entity'] == 'I-ORG':\n",
    "            org_end = entity['end']\n",
    "        # check if entity is a person\n",
    "        elif entity['entity'] == 'B-PER':\n",
    "            people_start = entity['start']\n",
    "            people_end = entity['end']\n",
    "        elif entity['entity'] == 'I-PER':\n",
    "            people_end = entity['end']\n",
    "\n",
    "\n",
    "        if org_start is not None and org_end is not None:\n",
    "            if i == len(entities) - 1 or entities[i + 1]['entity'] != 'I-ORG':\n",
    "                new_entities.append({'entity': 'ORG', \"text\": text[org_start:org_end]})\n",
    "                org_start = None\n",
    "        if people_start is not None and people_end is not None:\n",
    "            if i == len(entities) - 1 or entities[i + 1]['entity'] != 'I-PER':\n",
    "                new_entities.append({'entity': 'PER', \"text\": text[people_start:people_end]})\n",
    "                people_start = None\n",
    "\n",
    "    return new_entities\n",
    "procesed = process_entities(ner_results, text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T11:08:46.545331241Z",
     "start_time": "2023-05-13T11:08:46.539628660Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "('spectral, clustering',\n 'spectral clustering on large datasets: when does it work? theory from continuous clustering and density cheeger-buser',\n 'Spectral clustering is one of the most popular clustering algorithms that has stood the test of time. It is simple to describe, can be implemented using standard linear algebra, and often finds better clusters than traditional clustering algorithms like k-means and k-centers. The foundational algorithm for two-way spectral clustering, by Shi and Malik, creates a geometric graph from data and finds a spectral cut of the graph.In modern machine learning, many data sets are modeled as a large number of points drawn from a probability density function. Little is known about when spectral clustering works in this setting -and when it doesn\\'t. Past researchers justified spectral clustering by appealing to the graph Cheeger inequality (which states that the spectral cut of a graph approximates the \"Normalized Cut\"), but this justification is known to break down on large data sets.We provide theoretically-informed intuition about spectral clustering on large data sets drawn from probability densities, by proving when a continuous form of spectral clustering considered by past researchers (the unweighted spectral cut) finds good clusters of the underlying density itself. Our work suggests that Shi-Malik spectral clustering works well on data drawn from mixtures of Laplace distributions, and works poorly on data drawn from certain other densities, such as a density we call the \\'square-root trough\\'.Our core theorem proves that weighted spectral cuts have low weighted isoperimetry for all probability densities. Our key tool is a new Cheeger-Buser inequality for all probability densities, including discontinuous ones.')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_list = list(paper_space.get_xml_papers().values())\n",
    "paper_list[1].topic, paper_list[1].title, paper_list[1].abstract"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T13:38:16.033255178Z",
     "start_time": "2023-05-13T13:38:16.031142815Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "['Jascha Sohl-Dickstein', 'Ivo Danihelka', 'Andriy Mnih', 'Leon Gatys']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{author.forename} {author.surname}' for author in paper_list[0].acknowledgements.acknowledges_people]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-13T13:39:52.050294809Z",
     "start_time": "2023-05-13T13:39:52.006645519Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
